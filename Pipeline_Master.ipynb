{"cells":[{"cell_type":"markdown","metadata":{"id":"EqWhU3QReHky"},"source":["# Set up the notebook"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3315,"status":"ok","timestamp":1691253241686,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"QCoUctW3K7-Y","outputId":"2bf422e9-0f72-4ebd-dbf3-cae40f40614d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Based on the selected mode (Active Learning) the following values will be used in CONFIG_DICT {'lr_warmup': False, 'lr_decay': True, 'epochs': 10, 'learning_rate': 3e-05} \n","Don't forget to reinitialize CONFIG_DICT!\n","Mounted at /content/drive\n"]}],"source":["# @title Setting up variables\n","job_config = {}\n","# BASE_PATH = '/Users/morgunov/batista/Summer/pipeline/'\n","BASE_PATH = '/content/drive/MyDrive/Generative_ML/current_data/' #@param {type:\"string\"}\n","PROTEIN_NAME = 'HNH.pdb' # @param {type:\"string\"}\n","RANDOM_SEED = 42\n","MODE = 'Active Learning' #@param [\"Pretraining\", \"Active Learning\"]\n","RANDOM_SAMPLING = True #@param {type:\"boolean\"}\n","# @markdown select the name of the smiles-containing column in the training dataframe. use CAPS if pretraining on MOSES\n","SMILES_KEY = \"smiles\" #@param [\"smiles\", \"SMILES\"]\n","# @markdown following variables are only relevant when doing pretraining\n","TRAIN_FNAME = \"moses_and_binding_no_rare_tokens_train.csv.gz\" #@param [\"moses_and_binding_no_rare_tokens_train.csv.gz\", \"moses_train.csv.gz\"] {allow-input: true}\n","VAL_FNAME = \"moses_and_binding_no_rare_tokens_test.csv.gz\" #@param [\"moses_and_binding_no_rare_tokens_test.csv.gz\", \"moses_test.csv.gz\"] {allow-input: true}\n","TRAIN_CKPT_NAME = 'model1_random_al1' # @param {type:\"string\"}\n","CURRENT_CYCLE_PREFIX = \"model1_random_al1\" #@param {type:\"string\"}\n","\n","if MODE == 'Pretraining':\n","    job_config.update({'lr_warmup': True, 'lr_decay': True, 'epochs': 30, 'learning_rate': 3e-4,})\n","elif MODE == 'Active Learning':\n","    job_config.update({'lr_warmup': False, 'lr_decay': True, 'epochs': 10, 'learning_rate': 3e-5,})\n","else:\n","    raise KeyError(f'requested {MODE} but only Pretraining and Active Learning are supported')\n","print(f'Based on the selected mode ({MODE}) the following values will be used in CONFIG_DICT', job_config, \"\\nDon't forget to reinitialize CONFIG_DICT!\")\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","executionInfo":{"elapsed":1775,"status":"ok","timestamp":1691253243458,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"5WVLrvpbdpiQ"},"outputs":[],"source":["#@title Set up paths\n","import torch\n","import os\n","PRETRAINING_PATH = BASE_PATH + '1. Pretraining/'\n","GENERATION_PATH = BASE_PATH + '2. Generation/'\n","SAMPLING_PATH = BASE_PATH + '3. Sampling/'\n","DIFFDOCK_PATH = BASE_PATH + '4. DiffDock/'\n","SCORING_PATH = BASE_PATH + '5. Scoring/'\n","AL_PATH = BASE_PATH + '6. ActiveLearning/'\n","\n","PROTEIN_PATH = DIFFDOCK_PATH + 'proteins/' + PROTEIN_NAME\n","\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n","REGEX_PATTERN = \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|@@|\\?|>|!|~|\\*|\\$|\\%[0-9]{2}|[0-9])\""]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","executionInfo":{"elapsed":8,"status":"ok","timestamp":1691253243458,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"QmNIhQEJK7-b"},"outputs":[],"source":["#@title initialize CONFIG_DICT\n","CONFIG_DICT = {\n","    \"device\": DEVICE,\n","    \"att_bias\": False,\n","    \"gpt_bias\": True,\n","    \"att_drop_rate\": 0.1,\n","    \"gpt_drop_rate\": 0.1,\n","    \"n_layer\": 8,\n","    \"n_head\": 8,\n","    \"n_embed\": 256,\n","    \"ff_mult\": 4, # multiplier for Feed Forward number of hidden units inside multihead,\n","    \"doGELU\": True, # else ReLU\n","    \"attention_times\": [],\n","    \"do_flash\": True,\n","    \"smiles_key\": SMILES_KEY,\n","    \"wandb_project\": f'BetaPipeline',\n","    \"slice_data\": False, #False for all data\n","    \"batch_size\": 512, #512,\n","    \"betas\": (0.965, 0.99), #(0.9, 0.95)\n","    \"rho\": 0.04, # For SophiaG\n","    \"weight_decay\": 0.1,\n","    \"num_workers\": 0 # number of worker processes to use for loading data\n","}\n","CONFIG_DICT.update(job_config)"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1691253243458,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"wENHAYSOnHOC","outputId":"27f2b049-51a4-477e-8547-f10888cdca90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model will be trained on\n"," 1. Pretraining/datasets/moses_and_binding_no_rare_tokens_train.csv.gz\n","... and validated on\n"," 1. Pretraining/datasets/moses_and_binding_no_rare_tokens_test.csv.gz\n","... dataset descriptors will be saved to\n"," 6. ActiveLearning/dataset_descriptors/model1_baseline_random_threshold11.yaml\n","... model weights will be saved to\n"," 6. ActiveLearning/model_weights/model1_random_al1.pt\n","... wandb run will be named model1_random_al1\n"]}],"source":["#@title Run this cell to ensure the variables below are set the way you want them to be!\n","pretrain_config = {\n","    \"train_path\": f\"{PRETRAINING_PATH}datasets/{TRAIN_FNAME}\",\n","    \"val_path\": f\"{PRETRAINING_PATH}datasets/{VAL_FNAME}\",\n","    \"wandb_runname\": TRAIN_CKPT_NAME,\n","    }\n","\n","# @markdown the following setting is relevant only when loading AL descriptors\n","DATASET_DESC_FNAME = \"model1_baseline_random_threshold11\" #@param [\"model1_baseline_threshold11_softmax_sub\", \"model1_softsub_al1_threshold11_softmax_sub\", \"model1_baseline_random_threshold11\"]\n","\n","if MODE == 'Pretraining':\n","    pretrain_config.update({\n","        \"save_ckpt_path\": f\"{PRETRAINING_PATH}model_weights/{TRAIN_CKPT_NAME}.pt\",\n","        \"desc_path\": f\"{PRETRAINING_PATH}dataset_descriptors/{TRAIN_FNAME.split('.')[0][:-6]}.yaml\",\n","        })\n","elif MODE == 'Active Learning':\n","    pretrain_config.update({\n","        \"save_ckpt_path\": f\"{AL_PATH}model_weights/{TRAIN_CKPT_NAME}.pt\",\n","        \"desc_path\": f\"{AL_PATH}dataset_descriptors/{DATASET_DESC_FNAME}.yaml\"\n","        })\n","\n","\n","print('Model will be trained on\\n', '/'.join(pretrain_config['train_path'].split('/')[6:]))\n","print('... and validated on\\n', '/'.join(pretrain_config['val_path'].split('/')[6:]))\n","print('... dataset descriptors will be saved to\\n', '/'.join(pretrain_config['desc_path'].split('/')[6:]))\n","print('... model weights will be saved to\\n', '/'.join(pretrain_config['save_ckpt_path'].split('/')[6:]))\n","print('... wandb run will be named', TRAIN_CKPT_NAME)\n","CONFIG_DICT.update(pretrain_config)"]},{"cell_type":"markdown","metadata":{"id":"94C4_8BipUaL"},"source":["# GPT"]},{"cell_type":"markdown","metadata":{"id":"jzRj6bGQpUaM"},"source":["## Imports & Installations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19111,"status":"ok","timestamp":1691154367636,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"QoqxuL44K7-d","outputId":"047fe535-c5a2-44da-87fd-fba329904d9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rdkit\n","  Downloading rdkit-2023.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.22.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n","Installing collected packages: rdkit\n","Successfully installed rdkit-2023.3.2\n","Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (1.22.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n","Collecting wandb\n","  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting pathtools (from wandb)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=5c474ec502b44a591da52a1d5d0e61cbcaa754fd473351fde52954024efd2276\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.32 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.8\n","Cloning into 'Sophia'...\n","remote: Enumerating objects: 139, done.\u001b[K\n","remote: Counting objects: 100% (19/19), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 139 (delta 11), reused 13 (delta 10), pack-reused 120\u001b[K\n","Receiving objects: 100% (139/139), 280.53 KiB | 16.50 MiB/s, done.\n","Resolving deltas: 100% (83/83), done.\n"]}],"source":["# install necessary packages\n","!pip install rdkit\n","!pip install pandas==1.5.3\n","!pip install wandb\n","\n","# clone Sophia optimizer GitHub repository\n","!git clone https://github.com/Liuhong99/Sophia.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zVkT-uNwAUsD"},"outputs":[],"source":["# import necessary packages\n","import numpy as np\n","import os\n","import re\n","import logging\n","import wandb\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data.dataloader import DataLoader\n","import torch.optim as optim\n","from torch.cuda.amp import GradScaler\n","from tqdm import tqdm\n","from rdkit import Chem\n","from Sophia.sophia import SophiaG\n","import yaml\n","import pandas as pd\n","\n","# set random seed for reproducibility\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed_all(RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{"id":"7pfZIi6qpUaQ"},"source":["## Definitions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ceh8AwjpK7-e"},"outputs":[],"source":["class GPTConfig:\n","    def __init__(self, vocab_size=None, block_size=None, **kwargs):\n","        self.vocab_size = vocab_size\n","        self.block_size = block_size\n","        for k,v in kwargs.items():\n","            setattr(self, k, v)\n","\n","    def export_attributes(self, export_path):\n","        with open(export_path, 'w') as f:\n","            yaml.dump(vars(self), f)\n","\n","    def load_attributes(self, load_path):\n","        with open(load_path, 'r') as f:\n","            config_dict = yaml.load(f, Loader=yaml.SafeLoader)\n","        self.__dict__.update(config_dict)"]},{"cell_type":"markdown","metadata":{"id":"78g7xtxZK7-e"},"source":["### Dataset loading & sampling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3MhywaNlpUaQ"},"outputs":[],"source":["@torch.no_grad()\n","def sample(model, x, steps, temperature=1.0):\n","    block_size = model.get_block_size() # define size of context window used for input conditioning\n","    model.eval()\n","    for k in range(steps):\n","        x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # limit conditioning input to the most recent block_size elements\n","        logits, _= model(x_cond) # give input to model and get logits (unnormalized scores or probabilities)\n","        logits = logits[:, -1, :] / temperature # extract the logits for the next token in the sequence\n","        probs = F.softmax(logits, dim=-1)\n","        ix = torch.multinomial(probs, 1)\n","        x = torch.cat((x, ix), dim=1) # concatenate the chosen token index with the existing sequence\n","    return x\n","\n","def check_novelty(gen_smiles, train_smiles):\n","    if len(gen_smiles) == 0:\n","        novel_ratio = 0\n","    else:\n","        duplicates = [1 for mol in gen_smiles if mol in train_smiles]\n","        novel = len(gen_smiles) - sum(duplicates)\n","        novel_ratio = novel*100/len(gen_smiles)\n","    return novel_ratio\n","\n","def canonic_smiles(smiles_or_mol):\n","    mol = get_mol(smiles_or_mol)\n","    if mol is None:\n","        return None\n","    return Chem.MolToSmiles(mol)\n","\n","\n","class SMILESDataset(Dataset):\n","\n","    def __init__(self, data=None, chars=None, block_size=None, len_data = None):\n","        if chars is None:\n","            self.desc_only = True\n","            return\n","        self.desc_only = False\n","        self.vocab = set(chars)\n","        self.vocab_size = len(chars)\n","        self.stoi = {ch:i for i,ch in enumerate(chars)}\n","        # self.stoi['<'] = -100\n","        self.itos = {i:s for s,i in self.stoi.items()}\n","        # self.itos = {i:ch for i,ch in enumerate(chars)}\n","\n","        self.block_size = block_size\n","        self.data = data\n","        self.len_data = len_data\n","\n","    def export_desc_attributes(self, export_path):\n","        attr_dict = {\n","            \"desc_only\": self.desc_only,\n","            \"vocab_size\": self.vocab_size,\n","            \"block_size\": self.block_size,\n","            \"stoi\": self.stoi,\n","            \"itos\": self.itos,\n","            \"len_data\": self.len_data\n","        }\n","        with open(export_path, 'w') as f:\n","            yaml.dump(attr_dict, f)\n","\n","    def load_desc_attributes(self, load_path):\n","        with open(load_path, 'r') as f:\n","            attr_dict = yaml.load(f, Loader=yaml.SafeLoader)\n","        self.__dict__.update(attr_dict)\n","\n","    def __len__(self):\n","        assert not self.desc_only, \"Dataset is not initialized\"\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        assert not self.desc_only, \"Dataset is not initialized\"\n","        smiles = self.data[idx].strip()\n","        # define regular expressin pattern used to identify characters in the SMILES strings\n","        regex = re.compile(REGEX_PATTERN)\n","        smiles_matches = regex.findall(smiles)\n","\n","        # smiles = str('!') + smiles\n","        # smiles += str('<')*(self.block_size - len(smiles_matches)) # pad SMILES string by appending '<' to the end until self.block_size is achieved\n","\n","        if len(smiles_matches) > self.block_size+1: # if the number of matches found by the regular expression pattern applied to the SMILES string exceeds self.block_size:\n","            smiles = smiles[:self.block_size+1]\n","\n","        embedded_smile = [self.stoi[s] for s in smiles_matches]\n","        x = torch.tensor(embedded_smile[:-1], dtype=torch.long)\n","        y = torch.tensor(embedded_smile[1:], dtype=torch.long)\n","        return x, y\n"]},{"cell_type":"markdown","metadata":{"id":"iTFNFFNGpUaR"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7QbYJpQ3pUaR"},"outputs":[],"source":["class SelfAttention(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        assert config.n_embed % config.n_head == 0\n","        self.config = config\n","\n","        self.query = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n","        self.key = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n","        self.value = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n","\n","        self.attn_drop = nn.Dropout(config.att_drop_rate)\n","        self.resid_drop = nn.Dropout(config.att_drop_rate)\n","\n","        self.proj = nn.Linear(config.n_embed, config.n_embed)\n","        self.n_head = config.n_head\n","\n","        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size, config.block_size))\n","                                .view(1, 1, config.block_size, config.block_size))\n","\n","    def forward(self, x, layer_past=None):\n","        B, T, C = x.size()\n","        # apply attention functions to get tensors with dimensions (B, n_head, T, head_size)\n","        q = self.query(x).view(B, T, self.n_head, C // self.n_head)\n","        k = self.key(x).view(B, T, self.n_head, C // self.n_head)\n","        v = self.value(x).view(B, T, self.n_head, C // self.n_head)\n","        if self.config.do_flash:\n","            q = q.transpose(1, 2)\n","            k = k.transpose(1, 2)\n","            v = v.transpose(1, 2)\n","            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, dropout_p=self.config.att_drop_rate if self.training else 0, is_causal=True)\n","            y = y.transpose(1, 2)\n","        else:\n","            # (B h T s) @ (B h s T) -> (B h T T)\n","            att = torch.einsum('bths,bihs->bhti', q, k) / np.sqrt(k.size(-1))\n","            att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n","            att = F.softmax(att, dim=-1)\n","            # (B h T T) @ (B h T s) -> (B h T s)\n","            y = torch.einsum('bhtq,bqhs->bths', att, v)\n","            self.att_weights = att\n","        self.attended = y\n","        y = y.contiguous().view(B, T, C)\n","        y = self.resid_drop(self.proj(y))\n","        self.out = y\n","        return y\n","\n","class Block(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        self.ln1 = nn.LayerNorm(config.n_embed)\n","        self.ln2 = nn.LayerNorm(config.n_embed)\n","        self.attn = SelfAttention(config)\n","        self.mlp = nn.Sequential(nn.Linear(config.n_embed, config.ff_mult*config.n_embed), nn.GELU() if config.doGELU else nn.ReLU(),\n","            nn.Linear(config.ff_mult*config.n_embed, config.n_embed), nn.Dropout(config.att_drop_rate))\n","\n","    def forward(self, x):\n","        y = self.attn(self.ln1(x))\n","        x = x + y # perform a residual connection by summing input and attention output\n","        x = x + self.mlp(self.ln2(x)) # apply layer normalization and then MLP, create a residual connection with input\n","        return x\n","\n","class GPT(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embed)\n","        self.type_emb = nn.Embedding(2, config.n_embed)\n","        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embed))\n","\n","        self.drop = nn.Dropout(config.gpt_drop_rate)\n","        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n","\n","        self.ln_f = nn.LayerNorm(config.n_embed)\n","        self.head = nn.Linear(config.n_embed, config.vocab_size, bias=config.gpt_bias)\n","        self.block_size = config.block_size # define the context size\n","        self.apply(self._init_weights) # initialize weights and apply to all relevant modules in the model\n","\n","    def get_block_size(self):\n","        return self.block_size\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, (nn.Linear, nn.Embedding)):\n","            module.weight.data.normal_(mean=0.0, std=0.02)\n","            if isinstance(module, nn.Linear) and module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def configure_optimizers(self, train_config):\n","        decay, no_decay = set(), set()\n","        no_decay = set()\n","\n","        whitelist_weight_modules = (torch.nn.Linear)\n","        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n","        # for named module of the model:\n","        for mn, m in self.named_modules():\n","            # for named parameter of each module:\n","            for pn, p in m.named_parameters():\n","                # construct full parameter name by concatenating module name and parameter name, separated by a dot\n","                fpn = '%s.%s' % (mn, pn) if mn else pn\n","                if pn.endswith('bias') or ('bias' in pn):\n","                    no_decay.add(fpn)\n","                elif (pn.endswith('weight') or ('weight' in pn)) and isinstance(m, whitelist_weight_modules):\n","                    decay.add(fpn)\n","                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n","                    no_decay.add(fpn)\n","        no_decay.add('pos_emb')\n","        param_dict = {pn:p for pn, p in self.named_parameters()}\n","        assert len(decay & no_decay) == 0\n","        # assert that all parameters from both sets have been correctly separated\n","        assert len(param_dict.keys() - (decay | no_decay)) == 0\n","        optim_groups = [{\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n","                        {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0}]\n","        optimizer = SophiaG(optim_groups, lr=train_config.learning_rate, betas=train_config.betas, rho=train_config.rho, weight_decay=train_config.weight_decay)\n","        return optimizer\n","\n","    def forward(self, idx, targets=None, prop = None, scaffold = None):\n","        b, t = idx.size()\n","\n","        assert t <= self.block_size\n","\n","        token_embeddings = self.tok_emb(idx) # pass input tensor through token embedding layer\n","        # select a subset of the position embedding matrix based on the length of the input sequence\n","        position_embeddings = self.pos_emb[:, :t, :]\n","        # pass a tensor of ones of shape (b, t) through the type embedding layer,\n","        # maps a binary type indicator to a learnable embedding vector, all type indicators\n","        # are set to 1, indicating same type for all tokens in input sequence\n","        type_embeddings = self.type_emb(torch.ones((b,t), dtype=torch.long, device=idx.device))\n","        x = self.drop(token_embeddings + position_embeddings + type_embeddings)\n","\n","        for layer in self.blocks:\n","            x = layer(x)\n","        x = self.ln_f(x)\n","        logits = self.head(x)\n","        loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.view(-1), ignore_index=self.config.loss_ignore_index) if targets is not None else None\n","        # loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.view(-1)) if targets is not None else None\n","        return logits, loss"]},{"cell_type":"markdown","metadata":{"id":"zWbFS84KpUaS"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mrnqKEZwpUaS"},"outputs":[],"source":["class Trainer:\n","\n","    def __init__(self, model, train_dataset, test_dataset=None):\n","        self.model = model\n","        self.train_dataset = train_dataset\n","        self.test_dataset = test_dataset\n","        self.config = model.config\n","        self.stoi = train_dataset.stoi\n","        self.itos = train_dataset.itos\n","\n","    def train(self, wandb):\n","        model, config = self.model, self.config\n","        optimizer = model.configure_optimizers(config)\n","        scaler = GradScaler() # define variable used for gradient scaling in mixed-precision training\n","        self.tokens = 0 # initialize a counter used for learning rate decay\n","\n","        def run_epoch(split):\n","            is_train = split == 'train'\n","            model.train(is_train)\n","            data = self.train_dataset if is_train else self.test_dataset\n","            loader = DataLoader(data, shuffle=True, pin_memory=True, batch_size=config.batch_size, num_workers=config.num_workers)\n","            losses = []\n","            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n","            # for batch index, batch in progress bar:\n","            for it, (x, y) in pbar:\n","                # move the input data tensor, target data tensor, property tensor, and scaffold tensor to GPU\n","                x, y = x.to(config.device), y.to(config.device)\n","                # allow model to use lower-precision computations for improved memory usage\n","                if config.device == 'cuda':\n","                    with torch.cuda.amp.autocast():\n","                        with torch.set_grad_enabled(is_train):\n","                            logits, loss = model(x, y)\n","                            loss = loss.mean()\n","                            losses.append(loss.item())\n","                else:\n","                    with torch.cpu.amp.autocast():\n","                        with torch.set_grad_enabled(is_train):\n","                            logits, loss = model(x, y)\n","                            loss = loss.mean()\n","                            losses.append(loss.item())\n","\n","                if is_train:\n","                    model.zero_grad()\n","                    scaler.scale(loss).backward()\n","                    scaler.unscale_(optimizer) # unscale the gradients of the optimizer's parameters to their original values\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip gradients of model parameters to prevent them from exploding, setting maximum gradient norm to be 1.0\n","                    scaler.step(optimizer) # update the optimizer's parameters based on calculated gradients\n","                    scaler.update() # update the scale factor of the gradient scaler\n","                    if config.lr_decay:\n","                        self.tokens += (y >= 0).sum() # increment the number of processed tokens by the count of valid tokens (not padding or special tokens)\n","                        if config.lr_warmup and self.tokens < config.warmup_tokens:\n","                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens)) # perform a linear warm-up\n","                        else:\n","                            baseline = config.warmup_tokens if config.lr_warmup else 0\n","                            # calculate the progress of training in terms of the number of tokens processed\n","                            progress = float(self.tokens - baseline) / float(max(1, config.final_tokens - baseline))\n","                            # calculate the scaling factor for the learning rate (between 0.1 and 1.0)\n","                            # to gradually reduce learning rate as training progresses\n","                            lr_mult = max(0.1, 0.5 * (1.0 + np.cos(np.pi * progress)))\n","                        lr = config.learning_rate * lr_mult # multiply the base learning rate by the scaling factor to obtain the updated learning rate\n","                        for param_group in optimizer.param_groups:\n","                            param_group['lr'] = lr\n","                    else:\n","                        lr = config.learning_rate\n","                    if wandb is not None: # log training progress using Weights & Biases\n","                        wandb.log({'step_train_loss': loss, 'train_step': it + epoch*len(loader), 'learning_rate': lr})\n","                    # update the description of the progress bar with epoch, iteration, and training loss\n","                    pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n","            return float(np.mean(losses))\n","\n","        # initialize best loss as infinity\n","        best_loss = float('inf')\n","        for epoch in range(config.epochs):\n","            print(f'{epoch=}')\n","            train_loss = run_epoch('train')\n","            log_dict = {'epoch_train_loss': train_loss, 'epoch': epoch + 1}\n","            if self.test_dataset is not None:\n","                test_loss = run_epoch('test')\n","                log_dict['epoch_valid_loss'] = test_loss\n","            if wandb is not None:\n","                wandb.log(log_dict)\n","            good_model = False\n","            if self.test_dataset is None:\n","                good_model = True\n","            else:\n","                if test_loss < best_loss:\n","                    best_loss = test_loss\n","                    good_model = True\n","            if good_model:\n","                torch.save(self.model.state_dict(), self.config.save_ckpt_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OuGEvPXDpUaT"},"outputs":[],"source":["def load_data(config_dict, mode='pretrain', forced_block_size=None, forced_vocab=None):\n","    if mode == 'pretrain':\n","        if 'gz' in config_dict[\"train_path\"]:\n","            compression = 'gzip'\n","        else:\n","            compression = None\n","        if (cut:=config_dict[\"slice_data\"]):\n","            train_data = pd.read_csv(config_dict[\"train_path\"], compression=compression)[:cut]\n","            val_data = pd.read_csv(config_dict[\"val_path\"], compression=compression)[:cut]\n","        else:\n","            train_data = pd.read_csv(config_dict[\"train_path\"], compression=compression)\n","            val_data = pd.read_csv(config_dict[\"val_path\"], compression=compression)\n","        iterators = (train_data[config_dict['smiles_key']].values, val_data[config_dict['smiles_key']].values)\n","        assert len(train_data) == len(train_data[config_dict['smiles_key']].values), \"There's no reason why this shouldn't be true\"\n","    elif mode == 'al':\n","        print(f\"Loading AL dataset from\", '/'.join(config_dict[\"al_path\"].split('/')[6:]))\n","        al_data = pd.read_csv(config_dict[\"al_path\"])\n","        iterators = (al_data[config_dict['smiles_key']].values, )\n","    else:\n","        raise KeyError(f\"Only pretraining and active learning are currently supported\")\n","\n","    # smiles = train_data[config_dict['smiles_key']]\n","    # vsmiles = val_data[config_dict['smiles_key']]\n","\n","    # compile pattern into a regular expression object that can be used for matching operations\n","    regex = re.compile(REGEX_PATTERN)\n","    char_set = {'<', '!', '~'} # context={'<'}\n","    # char_set = {'<', '!'} # context={'<'}\n","\n","    max_len = 0\n","    for iterator in iterators:\n","        for i in iterator:\n","            chars = regex.findall(i.strip())\n","            max_len = max(max_len, len(chars))\n","            for char in chars:\n","                char_set.add(char)\n","\n","    chars = sorted(list(char_set))\n","    max_len += 1    #accounting for the start token, which hasn't been added yet\n","    if forced_block_size is not None:\n","        assert mode == 'al', \"Cannot force a block size in pretraining\"\n","        max_len = forced_block_size\n","    if forced_vocab is not None:\n","        assert mode == 'al', \"Cannot force a vocabulary in pretraining\"\n","        chars = sorted(list(forced_vocab))\n","\n","    datasets = []\n","    for iterator in iterators:\n","        padded = ['!' + i + '~' + '<'*(max_len - 1 - len(regex.findall(i.strip()))) for i in iterator]\n","        dataset = SMILESDataset(data=padded, chars=chars, block_size=max_len, len_data=len(iterator))\n","        datasets.append(dataset)\n","    dataset.export_desc_attributes(config_dict[\"desc_path\"])\n","    return datasets\n","\n","    # smiles = ['!' + i + '~' + '<'*(max_len - 1 - len(regex.findall(i.strip()))) for i in smiles]\n","    # vsmiles = ['!' + i + '~' + '<'*(max_len - 1 - len(regex.findall(i.strip()))) for i in vsmiles]\n","\n","    # train_dataset = SMILESDataset(data=smiles, chars=chars, block_size=max_len, len_data=len(train_data))\n","    # valid_dataset = SMILESDataset(data=vsmiles, chars=chars, block_size=max_len, len_data=len(val_data))\n","    # train_dataset.export_desc_attributes(config_dict[\"desc_path\"])\n","    # return train_dataset, valid_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zH-gwID9pUaT"},"outputs":[],"source":["def train_GPT(train_dataset, config_dict, valid_dataset=None, load_ckpt=False):\n","  \"\"\"\n","  OUTPUTS:\n","  1) checkpoint of trained model parameters\n","  2) Weights & Biases logged run\n","  \"\"\"\n","\n","  mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n","                    warmup_tokens=0.1*train_dataset.len_data*train_dataset.block_size,\n","                    final_tokens=config_dict[\"epochs\"]*train_dataset.len_data*train_dataset.block_size,\n","                    loss_ignore_index=train_dataset.stoi['<'],\n","                    **config_dict)\n","  model = GPT(mconf)\n","  if load_ckpt:\n","    model.load_state_dict(torch.load(config_dict['load_ckpt_path']))\n","  model.to(config_dict[\"device\"])\n","  torch.compile(model)\n","  trainer = Trainer(model, train_dataset, valid_dataset)\n","\n","  %env WANDB_EXECUTABLE=python3\n","  wandb.init(project=config_dict[\"wandb_project\"], name=config_dict[\"wandb_runname\"])\n","  trainer.train(wandb=wandb)\n","  return model, trainer, wandb"]},{"cell_type":"markdown","metadata":{"id":"JS3N-2qgK7-h"},"source":["## Pretraining"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mWOb6fsKpUaU"},"outputs":[],"source":["train_dataset, val_dataset = load_data(CONFIG_DICT) # takes ~1 min\n","print(train_dataset.vocab_size, train_dataset.block_size)\n","# (190, 131) for combined\n","# (26, 55) for MOSES\n","# (27, 55) MOSES + end token\n","# (45, 131) MOSES + bindingdb + end token"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uvCDiyssBbZl"},"outputs":[],"source":["model = train_GPT(\n","                train_dataset = train_dataset,\n","                valid_dataset = val_dataset,\n","                config_dict = CONFIG_DICT\n","        )\n","#GK wandb API Key: c99c9a01523f93287716691fa3360b1f4566e115\n","#RB wandb API Key: 4d3d628c6b5a4b3554c7a89ea50df8a4a6be0f85\n","#AM wandb API key: 5be14d5930441de4707f6a58e4f7c2e229dab1d1"]},{"cell_type":"markdown","metadata":{"id":"PR2QZRicBmed"},"source":["# Inference (Generation)"]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1691253247332,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"GfGDEj6prEep","outputId":"82e71491-0d7a-4273-9f12-30c89e95dea3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generation will use the following dataset descriptors\n"," 6. ActiveLearning/dataset_descriptors/model1_baseline_random_threshold11.yaml\n","... and following model weights\n"," 6. ActiveLearning/model_weights/model1_random_al1.pt\n","... and molecules will be saved to\n"," 2. Generation/smiles/model1_random_al1_temp1.0_processed.csv\n","... already scored molecules will be read from\n"," []\n","... AL training sets will be read from\n"," []\n"]}],"source":["# @title Run this cell and check all parameters!\n","CONTEXT = \"!\" # @param {type:\"string\"}\n","TEMPERATURE = 1.0 #@param {type:\"slider\", min:0, max:2, step:0.1}\n","VAL_FNAME = \"moses_and_binding_no_rare_tokens_test.csv.gz\"\n","LOAD_CKPT_NAME = \"model1_random_al1.pt\" #@param [\"GPT_pretrain_07_14_23:39_1end_ignore_moses+bindingdb.pt\", \"model1_random_al1.pt\"] {allow-input: true}\n","NUM_TO_GENERATE = 100_000 #@param\n","PREVIOUSLY_SCORED_MOLS = [] # [\"model1_baseline.csv\", \"model1_softsub_al1.csv\"] #@param #\"model1_softsub_al2.csv\"\n","PREVIOUS_AL_TRAIN_SETS = [] #[\"model1_baseline_threshold11_softmax_sub.csv\", 'model1_softsub_al1_threshold11_softmax_sub.csv',] #@param #'model1_softsub_al2_threshold11_softmax_sub.csv'\n","# @markdown Please use the following naming scheme: \"model1_al{round of AL}\"\n","# GENERATION_FNAME = \"model1_al1\" #@param {type:\"string\"}\n","#\n","if MODE == 'Pretraining':\n","    LOAD_CKPT_PATH = f\"{PRETRAINING_PATH}model_weights/{LOAD_CKPT_NAME}\"\n","elif MODE == 'Active Learning':\n","    LOAD_CKPT_PATH = f\"{AL_PATH}model_weights/{LOAD_CKPT_NAME}\"\n","else:\n","    raise KeyError(f'requested {MODE} but only Pretraining and Active Learning are supported')\n","\n","inference_parameters = {\n","    \"batch_size\": 64,\n","    \"gen_size\": NUM_TO_GENERATE,\n","    \"generation_context\": CONTEXT,\n","    \"load_ckpt_path\": LOAD_CKPT_PATH,\n","}\n","CONFIG_DICT.update({\n","    \"generation_path\": f\"{GENERATION_PATH}smiles/{CURRENT_CYCLE_PREFIX}\",\n","    \"diffdock_scored_path_list\": [f\"{SCORING_PATH}scored_dataframes/{i}\" for i in PREVIOUSLY_SCORED_MOLS],\n","    \"al_trainsets_path_list\": [f\"{AL_PATH}training_sets/{i}\" for i in PREVIOUS_AL_TRAIN_SETS],\n","    \"inference_temp\": TEMPERATURE,})\n","print(\"Generation will use the following dataset descriptors\\n\", '/'.join(CONFIG_DICT['desc_path'].split('/')[6:]))\n","print(\"... and following model weights\\n\", '/'.join(inference_parameters['load_ckpt_path'].split('/')[6:]))\n","print(\"... and molecules will be saved to\\n\", '/'.join(CONFIG_DICT['generation_path'].split('/')[6:])+ f\"_temp{TEMPERATURE}_processed\" +'.csv')\n","print(\"... already scored molecules will be read from\\n\", ['/'.join(i.split('/')[6:]) for i in CONFIG_DICT['diffdock_scored_path_list']])\n","print(\"... AL training sets will be read from\\n\", ['/'.join(i.split('/')[6:]) for i in CONFIG_DICT['al_trainsets_path_list']])"]},{"cell_type":"markdown","metadata":{"id":"Updv9u2YWKJs"},"source":["## Code"]},{"cell_type":"markdown","metadata":{"id":"v1l2xv3wqvp0"},"source":["### Definitions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rEXbs9mvuSDW"},"outputs":[],"source":["def export_metrics_to_workbook(metrics, fname):\n","    metric_to_col = {\n","        'generated': 'B',\n","        'valid': 'C',\n","        'unique': 'D',\n","        'validity': 'E',\n","        '% unique (rel. to generated)': 'F',\n","        '% unique (rel. to valid)': 'G',\n","        '% novelty (rel. to train set)': 'H',\n","        '% novelty (rel. to train+AL sets)': 'I',\n","        '% repetitions (from AL0 training set)': 'J',\n","        '% repetitions (from AL1 training set)': 'K',\n","        '% repetitions (from AL2 training set)': 'L',\n","        '% repetitions (from AL3 training set)': 'M',\n","        '% repetitions (from AL4 training set)': 'N',\n","        '% repetitions (from AL5 training set)': 'O',\n","        '% repetitions (from AL6 training set)': 'P',\n","        '% repetitions (from AL7 training set)': 'Q',\n","        '% repetitions (from scored from round 0)': 'R',\n","        '% repetitions (from scored from round 1)': 'S',\n","        '% repetitions (from scored from round 2)': 'T',\n","        '% repetitions (from scored from round 3)': 'U',\n","        '% repetitions (from scored from round 4)': 'V',\n","        '% repetitions (from scored from round 5)': 'W',\n","        '% repetitions (from scored from round 6)': 'X',\n","        '% repetitions (from scored from round 7)': 'Y',\n","        '% fraction of AL0 training set in generated': 'Z',\n","        '% fraction of AL1 training set in generated': 'AA',\n","        '% fraction of AL2 training set in generated': 'AB',\n","        '% fraction of AL3 training set in generated': 'AC',\n","        '% fraction of AL4 training set in generated': 'AD',\n","        '% fraction of AL5 training set in generated': 'AE',\n","        '% fraction of AL6 training set in generated': 'AF',\n","        '% fraction of AL7 training set in generated': 'AG',\n","        '% fraction of scored from round 0 in generated': 'AH',\n","        '% fraction of scored from round 1 in generated': 'AI',\n","        '% fraction of scored from round 2 in generated': 'AJ',\n","        '% fraction of scored from round 3 in generated': 'AK',\n","        '% fraction of scored from round 4 in generated': 'AL',\n","        '% fraction of scored from round 5 in generated': 'AM',\n","        '% fraction of scored from round 6 in generated': 'AN',\n","        '% fraction of scored from round 7 in generated': 'AO'}\n","    # Load an excel workbook, open sheet \"generated_logbook\", find the first nonempty row and append the metrics to that row\n","    from openpyxl import load_workbook\n","    wb = load_workbook(filename = f\"{BASE_PATH}Generative_ML Logbook.xlsx\")\n","    for i, sheet in enumerate(('generated_logbook_abs', 'generated_logbook_rel')):\n","        ws = wb[sheet]\n","        row = 3\n","        while ws[f'A{row}'].value is not None:\n","            row += 1\n","        ws[f'A{row}'] = fname\n","        for metric, value in metrics.items():\n","            if isinstance(value, str) and '=' in value:\n","                if i == 0:\n","                    value = value.split(' = ')[0].split(' * ')[1]\n","                else:\n","                    value = value.split(' = ')[1]\n","            ws[f'{metric_to_col[metric]}{row}'] = value\n","    wb.save(filename = f\"{BASE_PATH}Generative_ML Logbook.xlsx\")\n","\n","from rdkit import Chem\n","\n","def get_mol(smile_string):\n","    mol = Chem.MolFromSmiles(smile_string)\n","    if mol is None:\n","        return None\n","    try:\n","        Chem.SanitizeMol(mol)\n","    except ValueError:\n","        return None\n","    return mol\n","\n","def check_novelty(generated, train_list, sig_digs=3, multiplier=100, denominator=None, subtracted=True, show_work=False):\n","    total_train = set()\n","    for train in train_list:\n","        total_train = total_train | train\n","    repeated = generated & total_train\n","    if denominator is None:\n","        denominator = len(generated)\n","    if subtracted:\n","        if show_work:\n","            out = np.round(multiplier*(1-len(repeated)/denominator), sig_digs)\n","            return f\"{multiplier}*(1-{len(repeated)}/{denominator}) = {out}\"\n","        else:\n","            return np.round(multiplier*(1-len(repeated)/denominator), sig_digs)\n","    else:\n","        if show_work:\n","            out = np.round(multiplier*len(repeated)/denominator, sig_digs)\n","            return f\"{multiplier} * {len(repeated)}/{denominator} = {out}\"\n","        else:\n","            return np.round(multiplier*len(repeated)/denominator, sig_digs)\n","\n","def dump_dic_to_text(dic, path, header=None):\n","    with open(path, 'w') as f:\n","        if header is not None:\n","            f.write(f\"{header}\\n\")\n","        for key, value in dic.items():\n","            f.write(f'{key}: {value}\\n')\n","\n","def generate_SMILES(config_dict, inference_parameters):\n","    regex = re.compile(REGEX_PATTERN)\n","    dataset = SMILESDataset()\n","    dataset.load_desc_attributes(config_dict[\"desc_path\"])\n","\n","    mconf = GPTConfig(dataset.vocab_size, dataset.block_size, **config_dict)\n","    model = GPT(mconf).to(config_dict[\"device\"])\n","    model.load_state_dict(torch.load(inference_parameters[\"load_ckpt_path\"], map_location=torch.device(config_dict[\"device\"])))\n","    model.to(config_dict[\"device\"])\n","    torch.compile(model)\n","\n","    # load parameters into the model\n","    block_size = model.get_block_size()\n","    assert (block_size == dataset.block_size), \"Warning: model block size and dataset block size are different\"\n","    molecules_list, molecules_set = [], set()\n","    completions = []\n","    pbar = tqdm()\n","    while True:\n","        pbar.update()\n","        pbar.set_description(f\"generated {len(molecules_set)} unique molecules\")\n","        # create an input tensor by converting 'context' to a tensor of token indices, repeat this batch times along the batch dimension\n","        x = (torch.tensor([dataset.stoi[s] for s in regex.findall(inference_parameters[\"generation_context\"])], dtype=torch.long,)[None, ...]\n","            .repeat(inference_parameters[\"batch_size\"], 1).to(config_dict[\"device\"]))\n","        y = sample(model, x, block_size, temperature=config_dict[\"inference_temp\"])\n","        for gen_mol in y:\n","            completion = \"\".join([dataset.itos[int(i)] for i in gen_mol])  # convert generated molecule from list of integers to list of strings and concatenate to one string\n","            completions.append(completion)\n","            if completion[0] == '!' and completion[1] == '~':\n","                completion = '!' + completion[2:]\n","            if \"~\" not in completion: continue\n","            mol_string = completion[1 : completion.index(\"~\")]\n","            mol = get_mol(mol_string)  # convert the string representation of the molecule to an rdkit Mol object\n","            if mol is not None:\n","                molecules_list.append(Chem.MolToSmiles(mol))\n","                molecules_set.add(Chem.MolToSmiles(mol))\n","        if len(molecules_set) >= inference_parameters[\"gen_size\"]:\n","            break\n","    pbar.close()\n","\n","    completions_df = pd.DataFrame({\"smiles\": completions})\n","    completions_df.to_csv(config_dict[\"generation_path\"]+ f\"_temp{config_dict['inference_temp']}_completions.csv\")\n","    molecules_df = pd.DataFrame({\"smiles\": list(molecules_set)})\n","    molecules_df.to_csv(config_dict[\"generation_path\"]+ f\"_temp{config_dict['inference_temp']}_processed.csv\")\n","    characterize_generated_molecules(config_dict, molecules_list)\n","\n","def characterize_generated_molecules(config_dict, molecules_list=None):\n","    completions = pd.read_csv(config_dict[\"generation_path\"]+ f\"_temp{config_dict['inference_temp']}_completions.csv\")['smiles']\n","    molecules_set = set(pd.read_csv(config_dict[\"generation_path\"]+ f\"_temp{config_dict['inference_temp']}_processed.csv\")['smiles'])\n","    if molecules_list is None:\n","        molecules_list = []\n","        for completion in tqdm(completions, total=len(completions)):\n","            if completion[0] == '!' and completion[1] == '~':\n","                completion = '!' + completion[2:]\n","            if \"~\" not in completion: continue\n","            mol_string = completion[1 : completion.index(\"~\")]\n","            mol = get_mol(mol_string)  # convert the string representation of the molecule to an rdkit Mol object\n","            if mol is not None:\n","                molecules_list.append(Chem.MolToSmiles(mol))\n","\n","    assert molecules_set == set(molecules_list), \"Warning: set(molecules_list) and molecules_set are different\"\n","    train_data = set(pd.read_csv(config_dict[\"train_path\"])[config_dict[\"smiles_key\"]])\n","    scored_sets = {i: set(pd.read_csv(path)['smiles']) for i, path in enumerate(config_dict['diffdock_scored_path_list'])}\n","    al_sets = {i: set(pd.read_csv(path)['smiles']) for i, path in enumerate(config_dict['al_trainsets_path_list'])}\n","\n","    multiplier = 100\n","    metrics = {\n","        \"generated\": len(completions), \"valid\": len(molecules_list), \"unique\": len(molecules_set),\n","        \"validity\": np.round(multiplier*len(molecules_list)/len(completions), 3),\n","        \"% unique (rel. to generated)\": np.round(multiplier*len(molecules_set)/len(completions), 3),\n","        \"% unique (rel. to valid)\": np.round(multiplier*len(molecules_set)/len(molecules_list), 3),\n","        \"% novelty (rel. to train set)\": check_novelty(molecules_set, (train_data,), multiplier=multiplier),\n","        \"% novelty (rel. to train+AL sets)\": check_novelty(molecules_set, (train_data, *list(al_sets.values())), multiplier=multiplier),\n","    }\n","    for al_round, al_set in al_sets.items():\n","        metrics[f\"% repetitions (from AL{al_round} training set)\"] = check_novelty(molecules_set, (al_set,), subtracted=False, multiplier=multiplier, show_work=True)\n","    for score_round, score_set in scored_sets.items():\n","        metrics[f\"% repetitions (from scored from round {score_round})\"] = check_novelty(molecules_set, (score_set,), subtracted=False, multiplier=multiplier, show_work=True)\n","    for al_round, al_set in al_sets.items():\n","        metrics[f\"% fraction of AL{al_round} training set in generated\"] = check_novelty(molecules_set, (al_set,), subtracted=False, multiplier=multiplier, denominator=len(al_set), show_work=True)\n","    for score_round, score_set in scored_sets.items():\n","        metrics[f\"% fraction of scored from round {score_round} in generated\"] = check_novelty(molecules_set, (score_set,), subtracted=False, multiplier=multiplier, denominator=len(score_set), show_work=True)\n","    dump_dic_to_text(metrics, config_dict[\"generation_path\"]+ f\"_temp{config_dict['inference_temp']}_metrics.txt\")\n","    export_metrics_to_workbook(metrics, config_dict[\"generation_path\"].split('/')[-1])"]},{"cell_type":"markdown","metadata":{"id":"lo6dY-UstJbu"},"source":["### Runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uO6ReKqdBt85"},"outputs":[],"source":["# run function to generate SMILES strings\n","generate_SMILES(config_dict=CONFIG_DICT, inference_parameters=inference_parameters)"]},{"cell_type":"markdown","metadata":{"id":"RmPym8y6p18t"},"source":["# Sampling molecules for DiffDock calculations"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1691253251212,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"NHrQY-oT0gAd","outputId":"51dcfc48-dc0e-4901-dcde-cf424dc1f642","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated molecules will be read from\n"," 2. Generation/smiles/model1_random_al1_temp1.0_processed.csv\n","... and descriptors will be saved to\n"," 3. Sampling/descriptors/model1_random_al1_temp1.0.pkl\n","... pca weights will be read from to\n"," 3. Sampling/pca_weights/scaler_pca_moses+bindingdb.pkl\n","... kmeans objects will be saved to\n"," 3. Sampling/kmeans_objects/model1_random_al1_k100means.pkl\n","... clusterings will be saved to\n"," 3. Sampling/clusterings/model1_random_al1_cluster_to_mols.pkl\n","... samples for diffdock will be saved to\n"," 4. DiffDock/sampled_mols/model1_random_al1_samples.csv\n"]}],"source":["# @title Run this cell and make sure all the paths are correct!\n","PCA_FNAME = \"scaler_pca_moses+bindingdb.pkl\" # @param {type: \"string\"}\n","N_CLUSTERS = 100 #@param {type:\"integer\"}\n","SAMPLES_PER_CLUSTER = 10 #@param {type:\"integer\"}\n","sampling_config = {\n","    \"path_to_completions\": CONFIG_DICT[\"generation_path\"]+f\"_temp{CONFIG_DICT['inference_temp']}_completions.csv\",\n","    \"path_to_predicted\": CONFIG_DICT[\"generation_path\"]+f\"_temp{CONFIG_DICT['inference_temp']}_processed.csv\",\n","    \"path_to_descriptors\": SAMPLING_PATH + \"descriptors/\" + CONFIG_DICT[\"generation_path\"].split('/')[-1] +f\"_temp{CONFIG_DICT['inference_temp']}.pkl\",\n","    \"path_to_pca\": f\"{SAMPLING_PATH}pca_weights/{PCA_FNAME}\",\n","    \"kmeans_save_path\": f\"{SAMPLING_PATH}kmeans_objects/{CURRENT_CYCLE_PREFIX}_k{N_CLUSTERS}means.pkl\",\n","    \"clusters_save_path\": f\"{SAMPLING_PATH}clusterings/{CURRENT_CYCLE_PREFIX}_cluster_to_mols.pkl\",\n","    \"samples_save_path\": f\"{SAMPLING_PATH}clusterings/{CURRENT_CYCLE_PREFIX}_cluster_to_samples.pkl\",\n","    \"diffdock_save_path\": f\"{DIFFDOCK_PATH}sampled_mols/{CURRENT_CYCLE_PREFIX}_samples.csv\",\n","    \"n_clusters\": N_CLUSTERS,\n","    \"diffdock_scored_path_list\": CONFIG_DICT[\"diffdock_scored_path_list\"]\n","}\n","print(\"Generated molecules will be read from\\n\", '/'.join(sampling_config['path_to_predicted'].split('/')[6:]))\n","print(\"... and descriptors will be saved to\\n\", '/'.join(sampling_config['path_to_descriptors'].split('/')[6:]))\n","print(\"... pca weights will be read from to\\n\", '/'.join(sampling_config['path_to_pca'].split('/')[6:]))\n","print(\"... kmeans objects will be saved to\\n\", '/'.join(sampling_config['kmeans_save_path'].split('/')[6:]))\n","print(\"... clusterings will be saved to\\n\", '/'.join(sampling_config['clusters_save_path'].split('/')[6:]))\n","print(\"... samples for diffdock will be saved to\\n\", '/'.join(sampling_config['diffdock_save_path'].split('/')[6:]))"]},{"cell_type":"markdown","metadata":{"id":"Mdcw_UmAV8FK"},"source":["## Code"]},{"cell_type":"markdown","metadata":{"id":"7iB0S7xSK7-i"},"source":["### Imports & Definitions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10966,"status":"ok","timestamp":1690600864118,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"g5iCVkclJXWf","outputId":"5b7668b5-e832-4795-c176-065d9936e069"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Collecting rdkit\n","  Downloading rdkit-2023.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.22.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n","Installing collected packages: rdkit\n","Successfully installed rdkit-2023.3.2\n"]}],"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","!pip install rdkit\n","\n","import rdkit.Chem\n","import rdkit.Chem.Descriptors\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import pickle\n","from sklearn.cluster import KMeans\n","np.random.seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hPBcXwkBIZIL"},"outputs":[],"source":["def descriptors_for_gpt_predictions(config):\n","    gpt_mols = pd.read_csv(config['path_to_predicted'])\n","    smiles_set = set(gpt_mols['smiles'].to_list())\n","    for scored_file in config['diffdock_scored_path_list']:\n","        for smile in pd.read_csv(scored_file)['smiles'].values:\n","            assert isinstance(smile, str), f\"{smile} is not a string\"\n","            smiles_set.add(smile)\n","    keySet = None\n","    keyToData = {}\n","    pbar = tqdm(smiles_set, total=len(smiles_set))\n","    for smile in pbar:\n","        mol = rdkit.Chem.MolFromSmiles(smile)\n","        if not mol: continue\n","        mol_data = rdkit.Chem.Descriptors.CalcMolDescriptors(mol)\n","        if keySet is None:\n","            keySet = set(mol_data.keys())\n","        for key in keySet:\n","            keyToData.setdefault(key, []).append(mol_data[key])\n","        keyToData.setdefault('smiles', []).append(smile)\n","    gpt_df = pd.DataFrame(keyToData)\n","    gpt_df.to_pickle(config['path_to_descriptors'])\n","    return gpt_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2Te1IDeJnao"},"outputs":[],"source":["def project_into_pca_space(config):\n","    scaler, pca = pickle.load(open(config[\"path_to_pca\"], 'rb'))\n","    gptMols = pd.read_pickle(config[\"path_to_descriptors\"])\n","    return pca.transform(scaler.transform(gptMols[scaler.get_feature_names_out()]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XGAgRrOKPo3"},"outputs":[],"source":["def _cluster_mols_experimental_loss(mols, n_clusters, n_iter):\n","    min_loss, best_kmeans = float('inf'), None\n","    for _ in range(n_iter):\n","        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', init='k-means++').fit(mols)\n","        if kmeans.inertia_ < min_loss:\n","            min_loss = kmeans.inertia_\n","            best_kmeans = kmeans\n","    return best_kmeans\n","\n","def _cluster_mols_experimental_variance(mols, n_clusters, n_iter):\n","    max_variance, best_kmeans = float('-inf'), None\n","    for _ in range(n_iter):\n","        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', init='k-means++').fit(mols)\n","        counts = np.unique(kmeans.labels_, return_counts=True)[1]\n","        if (variance:=np.var(counts)) > max_variance:\n","            max_variance = variance\n","            best_kmeans = kmeans\n","    return best_kmeans\n","\n","def _cluster_mols_experimental_mixed(mols, n_clusters, n_iter, mixed_objective_loss_quantile):\n","    inertias = []\n","    variances = []\n","    km_objs = []\n","    for _ in range(n_iter):\n","        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', init='k-means++').fit(mols)\n","        inertias.append(kmeans.inertia_)\n","        counts = np.unique(kmeans.labels_, return_counts=True)[1]\n","        variances.append(np.var(counts))\n","        km_objs.append(kmeans)\n","    loss_var_kmeans_triples = sorted(zip(inertias, variances, km_objs), key=lambda x: x[0])\n","    lowest_n = loss_var_kmeans_triples[:int(len(loss_var_kmeans_triples) * mixed_objective_loss_quantile)]\n","    sorted_by_variance = sorted(lowest_n, key=lambda x: x[1])\n","    return sorted_by_variance[0][2]\n","\n","def _cluster_mols_experimental(mols, n_clusters, save_path, n_iter=1, objective='loss', mixed_objective_loss_quantile=0.1):\n","    if n_iter == 1:\n","        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', init='k-means++').fit(mols)\n","    elif objective == 'loss':\n","        kmeans = _cluster_mols_experimental_loss(mols, n_clusters, n_iter)\n","    elif objective == 'variance':\n","        kmeans = _cluster_mols_experimental_variance(mols, n_clusters, n_iter)\n","    elif objective == 'mixed':\n","        kmeans = _cluster_mols_experimental_mixed(mols, n_clusters, n_iter, mixed_objective_loss_quantile)\n","    else:\n","        raise ValueError(f'Unknown objective {objective}')\n","\n","    pickle.dump(kmeans, open(save_path, 'wb'))\n","    return kmeans"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l24k__P4KPhk"},"outputs":[],"source":["def cluster_and_sample(mols, config, n_clusters, n_samples, ensure_correctness=False, path_to_pca=None, load_kmeans=False):\n","    \"\"\"\n","        Clusters a given list of molecules, samples from each cluster, and saves the resulting data to specified files.\n","\n","        This function performs K-Means clustering on the input list of molecules and then samples a specified number of molecules\n","        from each cluster. The function ensures that the number of samples requested from each cluster doesn't exceed the total number\n","        of available molecules. The clustered data and sampled data are saved to specified file paths using pickle.\n","\n","        Parameters\n","        ----------\n","        mols : array-like or sparse matrix, shape (n_samples, n_features)\n","            The input samples where n_samples is the number of samples and n_features is the number of features.\n","\n","        n_clusters : int\n","            The number of clusters to form as well as the number of centroids to generate.\n","\n","        n_samples : int\n","            The number of samples to draw from each cluster.\n","\n","        ensure_correctness : bool, optional (default=False)\n","            If True, performs additional correctness checks, such as comparing SMILES string derived features to features in mols array.\n","            This requires 'path_to_pca' to be set.\n","\n","        path_to_pca : str, optional (default=None)\n","            If ensure_correctness is True, this should be the path to a PCA model used to transform the molecules' descriptors.\n","\n","        Returns\n","        -------\n","        cluster_to_samples : dict\n","            A dictionary where the keys are cluster labels and the values are lists of sampled SMILES strings from each cluster.\n","\n","        Raises\n","        ------\n","        AssertionError\n","            If the number of requested samples exceeds the total number of molecules provided.\n","            If ensure_correctness is True but path_to_pca is None.\n","            If the number of labels returned by the KMeans algorithm differs from the number of molecules.\n","            If features calculated from a smile string differ from features in the mols array.\n","            If the total number of sampled molecules doesn't equal to n_clusters * n_samples.\n","\n","    \"\"\"\n","    assert n_clusters * n_samples <= len(mols), f\"{n_clusters=} * {n_samples=} = {n_clusters*n_samples} requested but only {len(mols)} molecules provided\"\n","    if ensure_correctness:\n","        assert path_to_pca is not None, \"path_to_pca must be provided to ensure correctness\"\n","        scaler, pca = pickle.load(open(path_to_pca, 'rb'))\n","    if load_kmeans:\n","        kmeans = pickle.load(open(config['kmeans_save_path'], 'rb'))\n","    else:\n","        kmeans = _cluster_mols_experimental(mols=mols, n_iter=100, n_clusters=n_clusters, save_path=config[\"kmeans_save_path\"], objective='mixed', mixed_objective_loss_quantile=0.05)\n","    mols_smiles = pd.read_pickle(config[\"path_to_descriptors\"])['smiles']\n","    assert len(kmeans.labels_) == len(mols_smiles), \"Number of labels differs from number of molecules\"\n","    scored_smiles = set()\n","    for scored_file in config['diffdock_scored_path_list']:\n","        for smile in pd.read_csv(scored_file)['smiles'].values:\n","            scored_smiles.add(smile)\n","    cluster_to_mols = {}\n","    for mol, label, smile in zip(mols, kmeans.labels_, mols_smiles):\n","        if smile in scored_smiles: continue\n","        cluster_to_mols.setdefault(label, []).append(smile)\n","        if ensure_correctness: # recalculate descriptors from a smile string and compare to the descriptors in the array\n","            smile_features = pca.transform(scaler.transform(pd.DataFrame({k: [v] for k, v in rdkit.Chem.Descriptors.CalcMolDescriptors(rdkit.Chem.MolFromSmiles(smile)).items()})[scaler.get_feature_names_out()]))\n","            assert np.allclose(smile_features[0], mol), \"Features calculated from a smile string differ from features in the array\"\n","    # return cluster_to_mols\n","    # What happens below is sampling from each cluster. All the extra code is to ensure that the number of samples requested from each cluster\n","    # doesn't exceed the total number of available molecules. This is done by calculating the average number of molecules per cluster and then\n","    # calculating the number of extra molecules that need to be sampled from each cluster. The extra molecules are then distributed among the\n","    # clusters uniformly. If the number of extra molecules is greater than the number of molecules in a cluster, all\n","    # molecules from that cluster are sampled.\n","    avg_len = np.mean([len(v) for v in cluster_to_mols.values()])\n","    cluster_to_samples = {}\n","    extra_mols = (100 - len(cluster_to_mols))*10\n","    left_to_sample = n_clusters*n_samples\n","    cluster_to_len = {cluster:len(mols) for cluster, mols in cluster_to_mols.items()}\n","    for i, (cluster, _) in enumerate(sorted(cluster_to_len.items(), key=lambda x: x[1], reverse=False)):\n","        smiles = cluster_to_mols[cluster]\n","    # for i, (cluster, smiles) in enumerate(cluster_to_mols.items()):\n","        if extra_mols > 0:\n","            cur_extra = int(1+extra_mols/(len(cluster_to_mols) - i) * len(smiles)/avg_len)\n","            cur_samples = n_samples + cur_extra\n","            extra_mols -= cur_extra\n","        else:\n","            cur_samples = n_samples\n","        if cur_samples > left_to_sample:\n","            cur_samples = left_to_sample\n","        # print(f\"{cur_samples=}, {left_to_sample=}\")\n","        if len(smiles) > cur_samples:\n","            cluster_to_samples[cluster] = np.random.choice(smiles, cur_samples, replace=False)\n","            left_to_sample -= cur_samples\n","        else:\n","            cluster_to_samples[cluster] = smiles\n","            left_to_sample -= len(smiles)\n","            extra_mols += cur_samples - len(smiles)\n","\n","    assert (n_sampled:=sum(len(vals) for vals in cluster_to_samples.values())) == n_clusters*n_samples, f\"Sampled {n_sampled} but were requested {n_clusters*n_samples}\"\n","    pickle.dump(cluster_to_mols, open(config[\"clusters_save_path\"], 'wb'))\n","    pickle.dump(cluster_to_samples, open(config[\"samples_save_path\"], 'wb'))\n","    keyToData = {}\n","    for cluster, mols in cluster_to_samples.items():\n","        for mol in mols:\n","            keyToData.setdefault('smiles', []).append(mol)\n","            keyToData.setdefault('cluster_id', []).append(cluster)\n","    pd.DataFrame(keyToData).to_csv(config[\"diffdock_save_path\"])\n","    return cluster_to_samples"]},{"cell_type":"markdown","metadata":{"id":"5PpgMw_bK7-k"},"source":["### Runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"executionInfo":{"elapsed":1474009,"status":"ok","timestamp":1690602351163,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"SjuPYQTsK7-k","outputId":"cec44256-7e2f-43c5-97a5-dd26e71ae7c7"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 94632/94632 [24:21<00:00, 64.76it/s]\n"]},{"data":{"text/html":["\n","\n","  <div id=\"df-ed39eb51-8a08-4df4-bd05-d6d9e54b3a14\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SlogP_VSA12</th>\n","      <th>fr_ketone_Topliss</th>\n","      <th>NumHDonors</th>\n","      <th>fr_bicyclic</th>\n","      <th>fr_ketone</th>\n","      <th>fr_Ar_COO</th>\n","      <th>SlogP_VSA9</th>\n","      <th>NumHeteroatoms</th>\n","      <th>fr_para_hydroxylation</th>\n","      <th>fr_tetrazole</th>\n","      <th>...</th>\n","      <th>fr_thiocyan</th>\n","      <th>fr_NH2</th>\n","      <th>MaxAbsEStateIndex</th>\n","      <th>LabuteASA</th>\n","      <th>fr_C_O</th>\n","      <th>SMR_VSA10</th>\n","      <th>fr_alkyl_halide</th>\n","      <th>fr_thiophene</th>\n","      <th>SMR_VSA4</th>\n","      <th>smiles</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11.336786</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12.680660</td>\n","      <td>146.658822</td>\n","      <td>2</td>\n","      <td>39.055152</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12.781339</td>\n","      <td>Cc1ccc(C(N)=O)cc1NC(=O)c1sc2ncn(C)c(=O)c2c1C</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12.089724</td>\n","      <td>128.037138</td>\n","      <td>2</td>\n","      <td>11.876485</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>COc1cc(OC)c(OC)cc1CC(=O)NC1CCOC1=O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23.979758</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12.114835</td>\n","      <td>180.132383</td>\n","      <td>2</td>\n","      <td>57.565445</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>COc1cc(/C=C2\\SC(=S)NC2=O)ccc1OCC(=O)Nc1cccc([N...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13.910500</td>\n","      <td>275.278133</td>\n","      <td>3</td>\n","      <td>38.523820</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5.917906</td>\n","      <td>CC(C)CC(NC(=O)[C@H](Cc1ccccc1)NS(=O)(=O)Cc1ccc...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>23.201880</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6.354641</td>\n","      <td>175.532773</td>\n","      <td>0</td>\n","      <td>39.792191</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>Clc1cccc(N2CCN(CCCCOc3ccc4[nH]ccc4c3)CC2)c1Cl</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>94627</th>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5.821957</td>\n","      <td>200.276543</td>\n","      <td>0</td>\n","      <td>16.851264</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>CC(Nc1nc2cc(-c3nnc(-c4ccco4)o3)ccc2nc1-c1ccccc...</td>\n","    </tr>\n","    <tr>\n","      <th>94628</th>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14.428836</td>\n","      <td>289.627883</td>\n","      <td>2</td>\n","      <td>27.587162</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>Cc1ccc(S(=O)(=O)N(CC(=O)N(Cc2ccc(C3CCCCC3)cc2)...</td>\n","    </tr>\n","    <tr>\n","      <th>94629</th>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13.490291</td>\n","      <td>228.741675</td>\n","      <td>5</td>\n","      <td>40.500949</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5.917906</td>\n","      <td>[CH]C(=O)NC(CC)CNC(=O)[C@H](CC(C)C)NC(=O)[C@H]...</td>\n","    </tr>\n","    <tr>\n","      <th>94630</th>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13.108621</td>\n","      <td>218.930931</td>\n","      <td>1</td>\n","      <td>5.907180</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5.917906</td>\n","      <td>CC(C)(C)c1ccc2c3c1O[C@H]1[C@H](NC(=O)CCc4ncc[n...</td>\n","    </tr>\n","    <tr>\n","      <th>94631</th>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14.063188</td>\n","      <td>216.976119</td>\n","      <td>2</td>\n","      <td>17.756157</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>CCc1nc(N2CC3(CCN(C(C)=O)CC3)N(Cc3cccc(OC)c3C)C...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>94632 rows × 210 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed39eb51-8a08-4df4-bd05-d6d9e54b3a14')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-200f3ad0-d3d0-4db7-b2f8-38a43738f359\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-200f3ad0-d3d0-4db7-b2f8-38a43738f359')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-200f3ad0-d3d0-4db7-b2f8-38a43738f359 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ed39eb51-8a08-4df4-bd05-d6d9e54b3a14 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ed39eb51-8a08-4df4-bd05-d6d9e54b3a14');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"],"text/plain":["       SlogP_VSA12  fr_ketone_Topliss  NumHDonors  fr_bicyclic  fr_ketone  \\\n","0        11.336786                  0           2            1          0   \n","1         0.000000                  0           1            0          0   \n","2        23.979758                  0           2            0          0   \n","3         0.000000                  1           4            1          1   \n","4        23.201880                  0           1            1          0   \n","...            ...                ...         ...          ...        ...   \n","94627     0.000000                  0           1            1          0   \n","94628     0.000000                  0           2            0          0   \n","94629     0.000000                  0           5            1          0   \n","94630     0.000000                  0           3            0          0   \n","94631     0.000000                  0           1            0          0   \n","\n","       fr_Ar_COO  SlogP_VSA9  NumHeteroatoms  fr_para_hydroxylation  \\\n","0              0         0.0               8                      0   \n","1              0         0.0               7                      0   \n","2              0         0.0              11                      0   \n","3              0         0.0              11                      1   \n","4              0         0.0               6                      0   \n","...          ...         ...             ...                    ...   \n","94627          0         0.0               8                      0   \n","94628          1         0.0               9                      0   \n","94629          0         0.0              11                      1   \n","94630          0         0.0               7                      0   \n","94631          0         0.0               9                      0   \n","\n","       fr_tetrazole  ...  fr_thiocyan  fr_NH2  MaxAbsEStateIndex   LabuteASA  \\\n","0                 0  ...            0       1          12.680660  146.658822   \n","1                 0  ...            0       0          12.089724  128.037138   \n","2                 0  ...            0       0          12.114835  180.132383   \n","3                 0  ...            0       0          13.910500  275.278133   \n","4                 0  ...            0       0           6.354641  175.532773   \n","...             ...  ...          ...     ...                ...         ...   \n","94627             0  ...            0       0           5.821957  200.276543   \n","94628             0  ...            0       0          14.428836  289.627883   \n","94629             0  ...            0       0          13.490291  228.741675   \n","94630             0  ...            0       0          13.108621  218.930931   \n","94631             0  ...            0       0          14.063188  216.976119   \n","\n","       fr_C_O  SMR_VSA10  fr_alkyl_halide  fr_thiophene   SMR_VSA4  \\\n","0           2  39.055152                0             1  12.781339   \n","1           2  11.876485                0             0   0.000000   \n","2           2  57.565445                0             0   0.000000   \n","3           3  38.523820                0             0   5.917906   \n","4           0  39.792191                0             0   0.000000   \n","...       ...        ...              ...           ...        ...   \n","94627       0  16.851264                0             0   0.000000   \n","94628       2  27.587162                0             0   0.000000   \n","94629       5  40.500949                0             0   5.917906   \n","94630       1   5.907180                0             0   5.917906   \n","94631       2  17.756157                0             0   0.000000   \n","\n","                                                  smiles  \n","0           Cc1ccc(C(N)=O)cc1NC(=O)c1sc2ncn(C)c(=O)c2c1C  \n","1                     COc1cc(OC)c(OC)cc1CC(=O)NC1CCOC1=O  \n","2      COc1cc(/C=C2\\SC(=S)NC2=O)ccc1OCC(=O)Nc1cccc([N...  \n","3      CC(C)CC(NC(=O)[C@H](Cc1ccccc1)NS(=O)(=O)Cc1ccc...  \n","4          Clc1cccc(N2CCN(CCCCOc3ccc4[nH]ccc4c3)CC2)c1Cl  \n","...                                                  ...  \n","94627  CC(Nc1nc2cc(-c3nnc(-c4ccco4)o3)ccc2nc1-c1ccccc...  \n","94628  Cc1ccc(S(=O)(=O)N(CC(=O)N(Cc2ccc(C3CCCCC3)cc2)...  \n","94629  [CH]C(=O)NC(CC)CNC(=O)[C@H](CC(C)C)NC(=O)[C@H]...  \n","94630  CC(C)(C)c1ccc2c3c1O[C@H]1[C@H](NC(=O)CCc4ncc[n...  \n","94631  CCc1nc(N2CC3(CCN(C(C)=O)CC3)N(Cc3cccc(OC)c3C)C...  \n","\n","[94632 rows x 210 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["descriptors_for_gpt_predictions(sampling_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljwR2w2CK7-k"},"outputs":[],"source":["pca_transformed = project_into_pca_space(sampling_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8oEobsQ_K7-l"},"outputs":[],"source":["cluster_and_sample(mols=pca_transformed, config=sampling_config, n_clusters=N_CLUSTERS, n_samples=SAMPLES_PER_CLUSTER, ensure_correctness=False, load_kmeans=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nYRjUHcXWBKO"},"outputs":[],"source":["sizes = np.array([len(elt) for elt in o.values()])\n","sizes.min(), sizes.max(), sizes.mean(), np.percentile(sizes, [25, 50, 75])"]},{"cell_type":"markdown","metadata":{"id":"Z2CppWYWE5SI"},"source":["# Random Sampling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3853,"status":"ok","timestamp":1691156366085,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"UYZCKl-XE8Ge","outputId":"f84a5401-ad63-4cee-f9df-dd081816903b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading molecules from /content/drive/MyDrive/Generative_ML/current_data/2. Generation/smiles/model1_random_al1_temp1.0_processed.csv\n"]}],"source":["import pandas as pd\n","def sample_randomly(config, n=1000):\n","    print(f\"Loading molecules from {config['path_to_predicted']}\")\n","    gpt_mols = pd.read_csv(config['path_to_predicted'])\n","    sampled = gpt_mols.sample(n=1000, replace=False, random_state=RANDOM_SEED)['smiles'].to_list()\n","    sampled_df = pd.DataFrame({\"smiles\": sampled, \"cluster_id\": 1})\n","    sampled_df.to_csv(config['diffdock_save_path'])\n","\n","\n","sample_randomly(sampling_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_pKAYb1F6N8"},"outputs":[],"source":["sampling_config[\"diffdock_save_path\"] = \"/content/drive/MyDrive/Generative_ML/current_data/4. DiffDock/sampled_mols/model1_baseline_random_samples.csv\""]},{"cell_type":"markdown","metadata":{"id":"jzLWORD_OwCw"},"source":["# Docking pose generation (DiffDock)"]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3219,"status":"ok","timestamp":1691253257192,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"cIF0b2xeTlBM","outputId":"38f800de-c483-40df-ceb1-9ad12b244b4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Molecules will be read from\n"," 4. DiffDock/sampled_mols/model1_random_al1_samples.csv\n","... and best poses will be written to\n"," 4. DiffDock/poses/model1_random_al1/\n","... already scored molecules will be read from\n"," []\n"]}],"source":["# @title Run this cell to ensure proper paths are selected!\n","DIFFDOCK_RESULTS_PATH = f\"{DIFFDOCK_PATH}poses/{CURRENT_CYCLE_PREFIX}/\"\n","PREVIOUSLY_SCORED_MOLS = [] #.append(\"jul28archive/model1_softsub_al2.csv\")\n","CONFIG_DICT[\"diffdock_scored_path_list\"] = [f\"{SCORING_PATH}scored_dataframes/{i}\" for i in PREVIOUSLY_SCORED_MOLS]\n","\n","if not os.path.exists(DIFFDOCK_RESULTS_PATH):\n","    os.mkdir(DIFFDOCK_RESULTS_PATH)\n","print(\"Molecules will be read from\\n\", \"/\".join(sampling_config[\"diffdock_save_path\"].split('/')[6:]))\n","print(\"... and best poses will be written to\\n\", \"/\".join(DIFFDOCK_RESULTS_PATH.split('/')[6:]))\n","print(\"... already scored molecules will be read from\\n\", ['/'.join(i.split('/')[6:]) for i in CONFIG_DICT['diffdock_scored_path_list']])"]},{"cell_type":"markdown","metadata":{"id":"B-JpaIyJVwYw"},"source":["## Code"]},{"cell_type":"markdown","metadata":{"id":"zBgupbjAPYu7"},"source":["### Set up notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113407,"status":"ok","timestamp":1691156511273,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"GMwALd1zQBQ3","outputId":"d87972c5-237c-4eec-b523-7a005d3378d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pkgtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/37.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h2.0.1+cu118\n","\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Cloning into 'DiffDock'...\n","remote: Enumerating objects: 305, done.\u001b[K\n","remote: Counting objects: 100% (158/158), done.\u001b[K\n","remote: Compressing objects: 100% (52/52), done.\u001b[K\n","remote: Total 305 (delta 127), reused 106 (delta 106), pack-reused 147\u001b[K\n","Receiving objects: 100% (305/305), 232.37 MiB | 20.55 MiB/s, done.\n","Resolving deltas: 100% (156/156), done.\n","Note: switching to 'a6c5275'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by switching back to a branch.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -c with the switch command. Example:\n","\n","  git switch -c <new-branch-name>\n","\n","Or undo this operation with:\n","\n","  git switch -\n","\n","Turn off this advice by setting config variable advice.detachedHead to false\n","\n","HEAD is now at a6c5275 remove debugging raise in the inference file\n","Cloning into 'esm'...\n","remote: Enumerating objects: 1511, done.\u001b[K\n","remote: Counting objects: 100% (151/151), done.\u001b[K\n","remote: Compressing objects: 100% (113/113), done.\u001b[K\n","remote: Total 1511 (delta 42), reused 127 (delta 36), pack-reused 1360\u001b[K\n","Receiving objects: 100% (1511/1511), 11.26 MiB | 19.00 MiB/s, done.\n","Resolving deltas: 100% (896/896), done.\n","Note: switching to 'ca8a710'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by switching back to a branch.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -c with the switch command. Example:\n","\n","  git switch -c <new-branch-name>\n","\n","Or undo this operation with:\n","\n","  git switch -\n","\n","Turn off this advice by setting config variable advice.detachedHead to false\n","\n","HEAD is now at ca8a710 Update version.py (#310)\n","Obtaining file:///content/DiffDock/esm\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: fair-esm\n","  Building editable for fair-esm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fair-esm: filename=fair_esm-1.0.3-0.editable-py3-none-any.whl size=12990 sha256=d23b9a4bf3ed5cbbd4f302caf04e9f1dfc799e0bc305a447ed83c0bfbe099f00\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-11te_qrz/wheels/bf/8b/04/6b90c35ea3993beffa65ab00888579756ea7088fbba4613e85\n","Successfully built fair-esm\n","Installing collected packages: fair-esm\n","Successfully installed fair-esm-1.0.3\n"]}],"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","try:\n","    import biopandas\n","except:\n","    !pip install pyg==0.7.1 --quiet\n","    !pip install pyyaml==6.0 --quiet\n","    !pip install scipy==1.7.3 --quiet\n","    !pip install networkx==2.6.3 --quiet\n","    !pip install biopython==1.79 --quiet\n","    !pip install rdkit-pypi==2022.03.5 --quiet\n","    !pip install e3nn==0.5.0 --quiet\n","    !pip install spyrmsd==0.5.2 --quiet\n","    !pip install pandas==1.5.3 --quiet\n","    !pip install biopandas==0.4.1 --quiet\n","\n","import torch\n","print(torch.__version__)\n","\n","try:\n","    import torch_geometric\n","except ModuleNotFoundError:\n","    !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n","    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n","    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n","    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n","    !pip install git+https://github.com/pyg-team/pytorch_geometric.git  --quiet # @ 15573f4674b2a37b1b9adc967df69ef6eee573ea\n","\n","from rdkit import Chem\n","import shutil\n","import os\n","import pandas as pd\n","from tqdm import tqdm\n","\n","if not os.path.exists(\"/content/DiffDock\"):\n","    os.chdir('/content')\n","    !git clone https://github.com/gcorso/DiffDock.git\n","    os.chdir('/content/DiffDock')\n","    !git checkout a6c5275 # remove/update for more up to date code\n","\n","# clone ESM repository\n","if not os.path.exists(\"/content/DiffDock/esm\"):\n","    os.chdir('/content/DiffDock')\n","    !git clone https://github.com/facebookresearch/esm\n","    os.chdir('/content/DiffDock/esm')\n","    !git checkout ca8a710\n","    !sudo pip install -e .\n","    os.chdir('/content/DiffDock')\n"]},{"cell_type":"markdown","metadata":{"id":"j8-Pj-x1K7-l"},"source":["### Definitions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m68TViE-NqDN"},"outputs":[],"source":["def load_scored_mols(scored_path_list):\n","    scored_mols = {}\n","    for scored_path in scored_path_list:\n","        # iterate through every row in the scored dataframe\n","        for i, row in pd.read_csv(scored_path).iterrows():\n","            if row['smiles'] in scored_mols:\n","                assert scored_mols[row['smiles']] == row['score'], f\"{row['smiles']} scored {row['score']} but was already scored {scored_mols[row['smiles']]}\"\n","            scored_mols[row['smiles']] = row['score']\n","    return scored_mols\n","\n","def count_new_samples(sampled_path, scored_set):\n","    sampled_mols = set(pd.read_csv(sampling_config['diffdock_save_path'])['smiles'])\n","    repeated = len(sampled_mols & scored_set)\n","    print(f\"scored directory contains {len(scored_set)} unique molecules\")\n","    print(f\"{repeated} out of {len(sampled_mols)} sampled molecules were already scored\")\n","\n","def get_top_poses(ligands_csv, protein_pdb_path, scored_set):\n","    data = pd.read_csv(ligands_csv)\n","    ligand_files = []\n","\n","    os.environ['HOME'] = 'esm/model_weights'\n","    os.environ['PYTHONPATH'] = f'{os.environ.get(\"PYTHONPATH\", \"\")}:/content/DiffDock/esm'\n","    pbar = tqdm(range(len(data)), total=len(data))\n","    for i in pbar:  # change 1 to len(data) for processing all ligands\n","        # print(str((i / len(data)) * 100)[:5], ' %')\n","        smiles = data['smiles'][i]\n","        if smiles in scored_set: continue\n","        rdkit_mol = Chem.MolFromSmiles(smiles)\n","\n","        if rdkit_mol is not None:\n","            with open('/content/input_protein_ligand.csv', 'w') as out:\n","                out.write('protein_path,ligand\\n')\n","                out.write(f'{protein_pdb_path},{smiles}\\n')\n","\n","            # Clear out old results if running multiple times\n","            shutil.rmtree('/content/DiffDock/results', ignore_errors=True)\n","\n","            # ESM Embedding Preparation\n","            os.chdir('/content/DiffDock')\n","            !python /content/DiffDock/datasets/esm_embedding_preparation.py --protein_ligand_csv /content/input_protein_ligand.csv --out_file /content/DiffDock/data/prepared_for_esm.fasta\n","\n","            # ESM Extraction\n","            !python /content/DiffDock/esm/scripts/extract.py esm2_t33_650M_UR50D /content/DiffDock/data/prepared_for_esm.fasta /content/DiffDock/data/esm2_output --repr_layers 33 --include per_tok --truncation_seq_length 30000\n","\n","            # Inference\n","            !python /content/DiffDock/inference.py --protein_ligand_csv /content/input_protein_ligand.csv --out_dir /content/DiffDock/results/user_predictions_small --inference_steps 20 --samples_per_complex 10 --batch_size 6\n","\n","            # Move results\n","            for root, dirs, files in os.walk('/content/DiffDock/results/user_predictions_small'):\n","                for file in files:\n","                    if file.startswith('rank1_confidence'):\n","                        shutil.move(os.path.join(root, file), os.path.join(DIFFDOCK_RESULTS_PATH, f'complex{i}.sdf'))\n","                        ligand_files.append(f'{DIFFDOCK_RESULTS_PATH}complex{i}.sdf')\n","    return ligand_files"]},{"cell_type":"markdown","metadata":{"id":"42dkxj7rRd1z"},"source":["### Run DiffDock to get top poses"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1691156511506,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"pqawtxj2Rzer","outputId":"d6aeb8b7-619f-4dd6-efe8-b531050bdc55"},"outputs":[{"name":"stdout","output_type":"stream","text":["scored directory contains 0 unique molecules\n","0 out of 1000 sampled molecules were already scored\n"]}],"source":["count_new_samples(sampling_config['diffdock_save_path'], load_scored_mols(CONFIG_DICT['diffdock_scored_path_list']).keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3cfcaA3OR0Wy"},"outputs":[],"source":["# get top DiffDock poses\n","top_diffdock_poses = get_top_poses(sampling_config['diffdock_save_path'], PROTEIN_PATH, load_scored_mols(CONFIG_DICT['diffdock_scored_path_list']))"]},{"cell_type":"markdown","metadata":{"id":"veWeIgUNtYxK"},"source":["# Scoring poses with prolif"]},{"cell_type":"code","execution_count":9,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1691253264009,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"-DA_sA4OmymV","outputId":"100ecac9-2a2b-45cd-ad04-50046b72e021"},"outputs":[{"output_type":"stream","name":"stdout","text":["Molecules will be read from\n"," 4. DiffDock/sampled_mols/model1_random_al1_samples.csv\n","... and best poses will be read from\n"," 4. DiffDock/poses/model1_random_al1/\n","... scored molecules will be saved to\n"," 5. Scoring/scored_dataframes/model1_random_al1.csv\n","... good ligands will be selected based on threshold: 11\n","... and saved to\n"," 5. Scoring/scored_dataframes/model1_random_al1_threshold11.csv\n"]}],"source":["# @title Run this cell to ensure the paths are correct!\n","GOOD_LIGAND_SELECTION_MODE = \"Threshold\" #@param [\"Threshold\", \"Percentile\"]\n","# @markdown only one of the variables below is relevant (depending on selection above)\n","GOOD_LIGANDS_THRESHOLD = 11 #@param {type:\"integer\"}\n","GOOD_LIGANDS_PERCENTILE = 50 #@param {type:\"integer\"}\n","\n","scoring_config = {}\n","if GOOD_LIGAND_SELECTION_MODE == \"Threshold\":\n","    GOOD_LIGANDS_PERCENTILE = None\n","    scoring_config[\"path_to_good_ligands\"] = f\"{SCORING_PATH}scored_dataframes/{CURRENT_CYCLE_PREFIX}_threshold{GOOD_LIGANDS_THRESHOLD}.csv\"\n","    scoring_config[\"suffix\"] = f\"_threshold{GOOD_LIGANDS_THRESHOLD}\"\n","elif GOOD_LIGAND_SELECTION_MODE == \"Percentile\":\n","    GOOD_LIGANDS_THRESHOLD = None\n","    scoring_config[\"path_to_good_ligands\"] = f\"{SCORING_PATH}scored_dataframes/{CURRENT_CYCLE_PREFIX}_percentile{GOOD_LIGANDS_PERCENTILE}.csv\"\n","    scoring_config[\"al_suffix\"] = f\"_percentile{GOOD_LIGANDS_PERCENTILE}\"\n","else:\n","    raise KeyError(\"Only threshold and percentile based approaches are supported\")\n","\n","scoring_config[\"path_to_scored\"] = f\"{SCORING_PATH}scored_dataframes/{CURRENT_CYCLE_PREFIX}.csv\"\n","print(\"Molecules will be read from\\n\", \"/\".join(sampling_config[\"diffdock_save_path\"].split('/')[6:]))\n","print(\"... and best poses will be read from\\n\", \"/\".join(DIFFDOCK_RESULTS_PATH.split('/')[6:]))\n","print(\"... scored molecules will be saved to\\n\", \"/\".join(scoring_config[\"path_to_scored\"].split('/')[6:]))\n","print(\"... good ligands will be selected based on\", f\"{GOOD_LIGANDS_PERCENTILE}th percentile\" if GOOD_LIGANDS_PERCENTILE is not None else f\"threshold: {GOOD_LIGANDS_THRESHOLD}\")\n","print(\"... and saved to\\n\", \"/\".join(scoring_config[\"path_to_good_ligands\"].split('/')[6:]))"]},{"cell_type":"markdown","metadata":{"id":"s1evrZcDXi2u"},"source":["## Code"]},{"cell_type":"markdown","metadata":{"id":"Tamyd6Hstkpl"},"source":["### Set up notebook"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10138,"status":"ok","timestamp":1691253197583,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"gjg__oTktYHh","outputId":"36153d2f-1b1a-4e13-b379-4fba0473e53b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m✨🍰✨ Everything looks OK!\n","\n","                  __    __    __    __\n","                 /  \\  /  \\  /  \\  /  \\\n","                /    \\/    \\/    \\/    \\\n","███████████████/  /██/  /██/  /██/  /████████████████████████\n","              /  / \\   / \\   / \\   / \\  \\____\n","             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n","            / _/                       \\_____/  `\n","            |/\n","        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n","        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n","        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n","        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n","        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n","        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n","\n","        mamba (1.4.1) supported by @QuantStack\n","\n","        GitHub:  https://github.com/mamba-org/mamba\n","        Twitter: https://twitter.com/QuantStack\n","\n","█████████████████████████████████████████████████████████████\n","\n","\n","Looking for: ['pymol-open-source']\n","\n","conda-forge/linux-64                                        Using cache\n","conda-forge/noarch                                          Using cache\n","\n","Pinned packages:\n","  - python 3.10.*\n","  - python 3.10.*\n","  - python_abi 3.10.* *cp310*\n","  - cudatoolkit 11.8.*\n","\n","\n","Transaction\n","\n","  Prefix: /usr/local\n","\n","  All requested packages already installed\n","\n","\u001b[?25l\u001b[2K\u001b[0G\u001b[?25hRequirement already satisfied: prolif in /usr/local/lib/python3.10/site-packages (1.1.0)\n","Requirement already satisfied: mdanalysis>=2.2.0 in /usr/local/lib/python3.10/site-packages (from prolif) (2.5.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/site-packages (from prolif) (1.25.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from prolif) (4.65.0)\n","Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/site-packages (from prolif) (2.0.3)\n","Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.10/site-packages (from prolif) (1.11.1)\n","Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (1.81)\n","Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (3.7.2)\n","Requirement already satisfied: GridDataFormats>=0.4.0 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (1.0.1)\n","Requirement already satisfied: fasteners in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (0.18)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (3.2.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (3.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (23.1)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (1.3.1)\n","Requirement already satisfied: gsd>=1.9.3 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (3.1.1)\n","Requirement already satisfied: mmtf-python>=1.0.0 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (1.1.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0.0->prolif) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0.0->prolif) (2023.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0.0->prolif) (2.8.2)\n","Requirement already satisfied: mrcfile in /usr/local/lib/python3.10/site-packages (from GridDataFormats>=0.4.0->mdanalysis>=2.2.0->prolif) (1.4.3)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (4.42.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (10.0.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (0.11.0)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (1.1.0)\n","Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/site-packages (from mmtf-python>=1.0.0->mdanalysis>=2.2.0->prolif) (1.0.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->prolif) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: rdkit in /usr/local/lib/python3.10/site-packages (2023.3.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from rdkit) (10.0.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mMounted at /content/drive\n"]}],"source":["!pip install -q condacolab\n","import condacolab\n","condacolab.install()\n","import condacolab\n","\n","!mamba install pymol-open-source --yes\n","\n","!pip install prolif\n","!pip install rdkit\n","\n","from pymol import cmd\n","import prolif\n","from prolif.plotting.network import LigNetwork\n","from rdkit import Chem\n","from IPython.display import Image\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.stats import gaussian_kde\n","from tqdm import tqdm\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"nTDMdNdimsus"},"source":["### Definitions"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1691253672319,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"G_HXZNoHAJ-Y","outputId":"482fa572-1270-48c4-ffa4-71501b39a9cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["11.0\n"]}],"source":["interaction_scores = {\n","    'Hydrophobic': 2.5,\n","    'HBDonor': 3.5,\n","    'HBAcceptor': 3.5,\n","    'Anionic': 7.5,\n","    'Cationic': 7.5,\n","    'CationPi': 2.5,\n","    'PiCation': 2.5,\n","    'VdWContact': 1.0,\n","    'XBAcceptor': 3.0,\n","    'XBDonor': 3.0,\n","    'FaceToFace': 3.0,\n","    'EdgeToFace': 1.0,\n","    'MetalDonor': 3.0,\n","    'MetalAcceptor': 3.0,\n","}\n","# interaction_scores = {\n","#     'Hydrophobic': 1,\n","#     'HBDonor': 1,\n","#     'HBAcceptor': 1,\n","#     'Anionic': 1,\n","#     'Cationic': 1,\n","#     'CationPi': 1,\n","#     'PiCation': 1,\n","#     'VdWContact': 1,\n","#     'XBAcceptor': 1,\n","#     'XBDonor': 1,\n","#     'FaceToFace': 1,\n","#     'EdgeToFace': 1,\n","#     'MetalDonor': 1,\n","#     'MetalAcceptor': 1}\n","print(interaction_scores['HBDonor']*2 + interaction_scores['VdWContact']*3 + interaction_scores['EdgeToFace']*1)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"xhu7U2OSps1z","executionInfo":{"status":"ok","timestamp":1691253672320,"user_tz":240,"elapsed":7,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"}}},"outputs":[],"source":["def get_contacts(protein, ligand):\n","  cmd.delete('all')\n","  cmd.load(protein, 'protein')\n","  cmd.h_add('protein')\n","  cmd.remove('sol')\n","  cmd.save('/content/protein.pdb')\n","\n","  prot = prolif.Molecule(Chem.MolFromPDBFile('/content/protein.pdb', removeHs=False))\n","  lig = Chem.SDMolSupplier(ligand, removeHs=False)\n","  lig = prolif.Molecule.from_rdkit(lig[0])\n","\n","  fp = prolif.Fingerprint(interactions=list(interaction_scores.keys()))\n","  fp.run_from_iterable([lig], prot, progress=False)\n","  try:\n","    df = fp.to_dataframe(return_atoms=True)\n","    df_stacked = df.stack(level=[0, 1, 2])\n","    df_reset = df_stacked.to_frame().reset_index()\n","    df_reset.columns = ['Frame', 'ligand', 'protein', 'interaction', 'value']\n","    df_reset['score'] = df_reset['interaction'].apply(lambda x: interaction_scores[x])\n","    return df_reset['score'].sum()\n","  except:\n","    print('Complex has no meaningful protein-ligand connections')\n","    return int(0)\n","\n","def score_ligands(ligand_poses_dir, protein_path):\n","    ligand_list = [ligand_poses_dir + lig for lig in os.listdir(ligand_poses_dir) if lig.endswith('.sdf')]\n","    # count = 0\n","    ligand_scores = {}\n","    pbar = tqdm(ligand_list, total=len(ligand_list))\n","    # for lig in ligand_list:\n","    for lig in pbar:\n","        if lig.split('/')[-1].split('.')[0] not in ligand_scores:\n","            score = get_contacts(PROTEIN_PATH, lig)\n","            ligand_scores[lig.split('/')[-1].split('.')[0]] = score\n","            # count += 1\n","            # if int(count%(len(ligand_list)/100)) == 0:\n","                # print(int(count/len(ligand_list)*100), '% done')\n","    return ligand_scores"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"FJIQQXxkm3Pu","executionInfo":{"status":"ok","timestamp":1691253672320,"user_tz":240,"elapsed":6,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"}}},"outputs":[],"source":["def load_scored_mols(scored_path_list):\n","    scored_mols = {}\n","    for scored_path in scored_path_list:\n","        # iterate through every row in the scored dataframe\n","        for i, row in pd.read_csv(scored_path).iterrows():\n","            if row['smiles'] in scored_mols:\n","                assert scored_mols[row['smiles']] == row['score'], f\"{row['smiles']} scored {row['score']} but was already scored {scored_mols[row['smiles']]}\"\n","            scored_mols[row['smiles']] = row['score']\n","    return scored_mols\n","\n","def plot_ligand_scores(ligand_scores):\n","\n","    data = list(ligand_scores.values())\n","\n","    plt.figure(figsize=(8, 6), dpi=80)\n","\n","    plt.hist(data, bins=50, density=True, color='gray', alpha=0.7, edgecolor='black')\n","\n","    smoothed_data = np.linspace(min(data), max(data), 1000)\n","    kde = gaussian_kde(data)\n","    smoothed_line = kde(smoothed_data)\n","\n","    plt.plot(smoothed_data, smoothed_line, linewidth=2.5, color='black')\n","\n","    plt.xlabel(\"Values\", fontsize=18)\n","    plt.ylabel(\"Density\", fontsize=18)\n","\n","    plt.xticks(fontsize=16)\n","    plt.yticks(fontsize=16)\n","\n","    plt.title(\"Density Plot of Scores\", fontsize=20)\n","\n","    plt.grid(linestyle='--', linewidth=0.5, alpha=0.7)\n","\n","    plt.gca().spines['top'].set_visible(False)\n","    plt.gca().spines['right'].set_visible(False)\n","\n","    plt.tick_params(axis='both', which='both', direction='in', length=4)\n","\n","    plt.savefig(SCORING_PATH + 'plots/' + CURRENT_CYCLE_PREFIX + '_scores.png')\n","\n","    plt.show()\n","\n","    print(f'There are {list(ligand_scores.values()).count(0)} ligands with 0 connections ({np.round(list(ligand_scores.values()).count(0) / len(ligand_scores)*100, 1)}%)')\n","\n","    for i in range(int(np.max(list(ligand_scores.values()))) + 1):\n","        print(f'There are {len([value for value in list(ligand_scores.values()) if value > i])} ligands with scores greater than {i} ({np.round(len([value for value in list(ligand_scores.values()) if value > i]) / len(ligand_scores)*100, 1)}%)')\n","\n","\n","\n","    print(f'The mean score for all ligands is {np.round(np.mean(list(ligand_scores.values())), 1)}')\n","    print(f'The lowest score for all ligands is {np.min(list(ligand_scores.values()))}')"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"JYpuxAweb5Jg","executionInfo":{"status":"ok","timestamp":1691253672320,"user_tz":240,"elapsed":5,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"}}},"outputs":[],"source":["def parse_and_prepare_diffdock_data(ligand_scores, config, diffdock_samples_path, lower_percentile=None, threshold=None, scored_db = None):\n","    if scored_db is None: scored_db = {}\n","    diffdock_samples = pd.read_csv(diffdock_samples_path)\n","    if lower_percentile is not None:\n","        threshold = np.percentile(list(ligand_scores.values()), lower_percentile)\n","    all_ligands = {int(complex_name[7:]): score for complex_name, score in ligand_scores.items()} # complex names are complex000\n","    getter = lambda x: scored_db[x] if x in scored_db else all_ligands.get(x, 0)\n","    diffdock_samples['score'] = [getter(complex_number) for complex_number in diffdock_samples.index]\n","    diffdock_samples.to_csv(config[\"path_to_scored\"])\n","    good_ligands = diffdock_samples.loc[diffdock_samples['score'] >= threshold]\n","    good_ligands.to_csv(config[\"path_to_good_ligands\"])\n","    return diffdock_samples"]},{"cell_type":"markdown","metadata":{"id":"KhUk_1SLmzvh"},"source":["### Runs"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321764,"status":"ok","timestamp":1691253595430,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"LOZj7YU9Fdye","outputId":"f40e387c-f269-482f-c590-66b5bd19a78e"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 73%|███████▎  | 726/995 [03:57<01:20,  3.33it/s]"]},{"output_type":"stream","name":"stdout","text":["Complex has no meaningful protein-ligand connections\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 995/995 [05:21<00:00,  3.09it/s]\n"]}],"source":["ligand_scores = score_ligands(DIFFDOCK_RESULTS_PATH, PROTEIN_PATH)\n","# ligand_scores_unweighted = score_ligands(ligand_poses_dir, protein_path)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":980},"executionInfo":{"elapsed":2056,"status":"ok","timestamp":1691253617528,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"bKVQurmgFu41","outputId":"b1d97ea4-8a35-4e62-e14d-77e3b72e10bf"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["There are 1 ligands with 0 connections (0.1%)\n","There are 994 ligands with scores greater than 0 (99.9%)\n","There are 981 ligands with scores greater than 1 (98.6%)\n","There are 962 ligands with scores greater than 2 (96.7%)\n","There are 934 ligands with scores greater than 3 (93.9%)\n","There are 891 ligands with scores greater than 4 (89.5%)\n","There are 821 ligands with scores greater than 5 (82.5%)\n","There are 714 ligands with scores greater than 6 (71.8%)\n","There are 589 ligands with scores greater than 7 (59.2%)\n","There are 475 ligands with scores greater than 8 (47.7%)\n","There are 375 ligands with scores greater than 9 (37.7%)\n","There are 298 ligands with scores greater than 10 (29.9%)\n","There are 247 ligands with scores greater than 11 (24.8%)\n","There are 180 ligands with scores greater than 12 (18.1%)\n","There are 121 ligands with scores greater than 13 (12.2%)\n","There are 78 ligands with scores greater than 14 (7.8%)\n","There are 53 ligands with scores greater than 15 (5.3%)\n","There are 38 ligands with scores greater than 16 (3.8%)\n","There are 24 ligands with scores greater than 17 (2.4%)\n","There are 17 ligands with scores greater than 18 (1.7%)\n","There are 15 ligands with scores greater than 19 (1.5%)\n","There are 11 ligands with scores greater than 20 (1.1%)\n","There are 6 ligands with scores greater than 21 (0.6%)\n","There are 2 ligands with scores greater than 22 (0.2%)\n","There are 2 ligands with scores greater than 23 (0.2%)\n","There are 1 ligands with scores greater than 24 (0.1%)\n","There are 1 ligands with scores greater than 25 (0.1%)\n","There are 0 ligands with scores greater than 26 (0.0%)\n","The mean score for all ligands is 8.6\n","The lowest score for all ligands is 0.0\n"]}],"source":["plot_ligand_scores(ligand_scores)\n","# plot_ligand_scores(ligand_scores_unweighted, save_name='good_ligands_iter1_plot_unweighted_connections.png')"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":1830,"status":"ok","timestamp":1691253679157,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"4828Gu_zFwUu","outputId":"a127c267-8f93-478e-bdd8-2a271f6cf1ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Unnamed: 0                                             smiles  \\\n","0             0                 Nc1cc(C2CCN(C(=O)Cc3ccccc3)CC2)no1   \n","1             1           Clc1cccc(-n2cnc(-c3ccccc3Nc3ccncc3)n2)c1   \n","2             2                   C#CCOCC1CCCN(C(=O)c2cccc(C)c2)C1   \n","3             3            CC(NC(=O)CCn1nnc2ccccc2c1=O)c1cccc(F)c1   \n","4             4                  CC1CNc2ccc(NC(=O)c3cnc[nH]3)cc2O1   \n","..          ...                                                ...   \n","995         995             CC1CN(C(=O)c2ccon2)c2cc(F)c(F)cc2NC1=O   \n","996         996         O=C(O)c1ccc(Nc2nc(-c3cccnc3)nc3ccccc23)cc1   \n","997         997        O=C1Cc2cc(OCc3nn(Cc4ccccc4)c4ccccc34)ccc2N1   \n","998         998                                           Cc1nccs1   \n","999         999  N#CC1CCCN1C(=O)[C@H]1[C@H](C(=O)Nc2ccccc2)C2CC...   \n","\n","     cluster_id  score  \n","0             1   12.5  \n","1             1   13.0  \n","2             1    6.5  \n","3             1   12.5  \n","4             1    9.0  \n","..          ...    ...  \n","995           1    8.0  \n","996           1    8.0  \n","997           1    6.5  \n","998           1    2.5  \n","999           1    6.5  \n","\n","[1000 rows x 4 columns]"],"text/html":["\n","\n","  <div id=\"df-c8a9107c-e38d-4cad-8694-74ee96d56097\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>smiles</th>\n","      <th>cluster_id</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Nc1cc(C2CCN(C(=O)Cc3ccccc3)CC2)no1</td>\n","      <td>1</td>\n","      <td>12.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Clc1cccc(-n2cnc(-c3ccccc3Nc3ccncc3)n2)c1</td>\n","      <td>1</td>\n","      <td>13.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>C#CCOCC1CCCN(C(=O)c2cccc(C)c2)C1</td>\n","      <td>1</td>\n","      <td>6.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>CC(NC(=O)CCn1nnc2ccccc2c1=O)c1cccc(F)c1</td>\n","      <td>1</td>\n","      <td>12.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>CC1CNc2ccc(NC(=O)c3cnc[nH]3)cc2O1</td>\n","      <td>1</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>995</td>\n","      <td>CC1CN(C(=O)c2ccon2)c2cc(F)c(F)cc2NC1=O</td>\n","      <td>1</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>996</td>\n","      <td>O=C(O)c1ccc(Nc2nc(-c3cccnc3)nc3ccccc23)cc1</td>\n","      <td>1</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>997</td>\n","      <td>O=C1Cc2cc(OCc3nn(Cc4ccccc4)c4ccccc34)ccc2N1</td>\n","      <td>1</td>\n","      <td>6.5</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>998</td>\n","      <td>Cc1nccs1</td>\n","      <td>1</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>999</td>\n","      <td>N#CC1CCCN1C(=O)[C@H]1[C@H](C(=O)Nc2ccccc2)C2CC...</td>\n","      <td>1</td>\n","      <td>6.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8a9107c-e38d-4cad-8694-74ee96d56097')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-ed6623d0-04dc-4f71-a1be-2472f188a8c1\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed6623d0-04dc-4f71-a1be-2472f188a8c1')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-ed6623d0-04dc-4f71-a1be-2472f188a8c1 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c8a9107c-e38d-4cad-8694-74ee96d56097 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c8a9107c-e38d-4cad-8694-74ee96d56097');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":21}],"source":["parse_and_prepare_diffdock_data(ligand_scores, config=scoring_config, diffdock_samples_path=sampling_config[\"diffdock_save_path\"],\n","                                threshold=GOOD_LIGANDS_THRESHOLD, lower_percentile=GOOD_LIGANDS_PERCENTILE, scored_db=load_scored_mols(CONFIG_DICT['diffdock_scored_path_list']))"]},{"cell_type":"markdown","metadata":{"id":"oUjA5PGgZbQd"},"source":["# Prepare training dataset for next round of active learning"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1691151855315,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"lhWjqnBYaJSQ","outputId":"0ed19666-ad90-468e-bc8e-a38be87444f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Will read scored molecules from\n"," 5. Scoring/scored_dataframes/model1_baseline_random.csv\n","... and good ligands from\n"," 5. Scoring/scored_dataframes/model1_baseline_random_threshold11.csv\n","... and clusterings from\n"," 3. Sampling/clusterings/model1_baseline_random_cluster_to_mols.pkl\n","... and will save the AL training set to\n"," 6. ActiveLearning/training_sets/model1_baseline_random_threshold11.csv\n","... and will save the no score samplings to\n"," 6. ActiveLearning/training_sets/model1_baseline_random_threshold11_noscore.csv\n"]}],"source":["# @title Run this cell to ensure paths are correct\n","\n","PROBABILITY_CALCULATION = \"softmax\" #@param [\"softmax\", \"linear\"]\n","SOFTMAX_NORMALIZATION_TYPE = \"subtract\" #@param [\"divide\", \"subtract\"]\n","# @markdown the following variable is only relevant when softmax is selected\n","SOFTMAX_DIV_FACTOR = 0.25 #@param\n","N_SAMPLES = 5_000 # @param\n","if RANDOM_SAMPLING:\n","    al_suffix = ''\n","elif PROBABILITY_CALCULATION == 'softmax':\n","    al_suffix = f\"_{PROBABILITY_CALCULATION}\"\n","    if SOFTMAX_NORMALIZATION_TYPE == 'divide':\n","        al_suffix += f'_divf{SOFTMAX_DIV_FACTOR}'\n","    else:\n","        al_suffix += '_sub'\n","elif PROBABILITY_CALCULATION == 'linear':\n","    al_suffix = f\"_{PROBABILITY_CALCULATION}\"\n","else:\n","    raise KeyError(\"Only softmax and linear probabilities are supported\")\n","\n","\n","AL_TRAIN_PATH = f\"{AL_PATH}training_sets/{CURRENT_CYCLE_PREFIX}{scoring_config['suffix']}{al_suffix}.csv\"\n","AL_DIFFUSION_PATH = f\"{AL_PATH}training_sets/{CURRENT_CYCLE_PREFIX}{scoring_config['suffix']}{al_suffix}_noscore.csv\"\n","\n","print(\"Will read scored molecules from\\n\", '/'.join(scoring_config['path_to_scored'].split('/')[6:]))\n","print(\"... and good ligands from\\n\", '/'.join(scoring_config['path_to_good_ligands'].split('/')[6:]))\n","print(\"... and clusterings from\\n\", '/'.join(sampling_config['clusters_save_path'].split('/')[6:]))\n","print(\"... and will save the AL training set to\\n\", '/'.join(AL_TRAIN_PATH.split('/')[6:]))\n","print(\"... and will save the no score samplings to\\n\", '/'.join(AL_DIFFUSION_PATH.split('/')[6:]))"]},{"cell_type":"markdown","metadata":{"id":"TQ9BaRa8GyK7"},"source":["Here, we need to map the good data back to the original clusters and create a training set for active learning. THen, perform active learning, generate molecules, and repeat process. Finally, generate 2 million molecules to train BERT"]},{"cell_type":"markdown","metadata":{"id":"svfAh4qsC17K"},"source":["## Definitions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRsKbVS6akBs"},"outputs":[],"source":["import numpy as np\n","np.random.seed(RANDOM_SEED)\n","import pandas as pd\n","\n","def compute_cluster_scores():\n","    good_data = pd.read_csv(scoring_config['path_to_scored'])\n","    cluster_to_scores = {}\n","    for index, row in good_data.iterrows():\n","        cluster_to_scores.setdefault(row['cluster_id'], []).append(row['score'])\n","    cluster_to_score = {cluster_id: np.mean(scores) for cluster_id, scores in cluster_to_scores.items()}\n","    return cluster_to_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aqjFiWRObkRf"},"outputs":[],"source":["import plotly.graph_objects as go\n","\n","def plot_probability_distribution(cluster_scores, args_list, bin_size=0.001):\n","    fig = go.Figure()\n","    fig.add_trace(go.Histogram(x=[1/100 for _ in range(100)], name='uniform', opacity=0.75, histnorm='probability', xbins=dict(start=-0.1, end=1, size=bin_size)))\n","    keyToFunc = {\"linear\": _preprocess_scores_linearly, \"softmax\": _preprocess_scores_softmax}\n","    for (func, param_switch, param_value) in args_list:\n","        suffix, extras = \"\", {}\n","        if func == \"softmax\":\n","            suffix = f\" divf {param_value}\" if param_switch else \"\"\n","            extras = dict(divide=param_switch, divide_factor=param_value)\n","        fig.add_trace(go.Histogram(x=list(keyToFunc[func](cluster_scores, **extras).values()), name=f\"{func}{suffix}\", opacity=0.75, histnorm='probability', xbins=dict(start=-0.1, end=1, size=bin_size)))\n","    fig.update_layout(barmode='overlay', title=\"Probabilities of sampling from clusters based on mean scores\", xaxis_title=\"probability\", yaxis_title=\"rel. frequency\")\n","    return fig\n","\n","def plot_mean_cluster_scores(cluster_scores):\n","    fig = go.Figure()\n","    fig.add_trace(go.Histogram(x=list(cluster_scores.values()), opacity=0.75, histnorm='probability'))\n","    fig.update_layout(barmode='overlay', title=\"Distribution of cluster scores\", xaxis_title=\"Mean cluster score\", yaxis_title=\"rel. frequency\")\n","    return fig\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84XMCXxAQyfa"},"outputs":[],"source":["import pickle\n","\n","def _preprocess_scores_linearly(scores, do_negation=False, **kwargs):\n","    \"\"\"\n","        Preprocesses a dictionary of scores by negating and normalizing them.\n","\n","        The function negates all scores and optionally removes positive scores. If the minimum value among the negated scores\n","        is less than zero, it shifts all values by subtracting the minimum value and adding 'lowest_score'. The final step is\n","        to normalize the scores so that their total sum equals to 1.\n","\n","        Parameters\n","        ----------\n","        scores : dict\n","            A dictionary of scores where the keys are identifiers and the values are their corresponding scores.\n","\n","        remove_positives : bool, optional (default=False)\n","            If True, all positive scores are removed after negation.\n","\n","        lowest_score : int, optional (default=1)\n","            This value is added to all scores if the minimum score is less than zero.\n","\n","        Returns\n","        -------\n","        normalized : dict\n","            The normalized dictionary of scores.\n","\n","    \"\"\"\n","    sign = -1 if do_negation else 1\n","    negated = {k: sign*v for k, v in scores.items()}\n","    total = sum(negated.values())\n","    normalized = {k: v / total for k, v in negated.items()}\n","    return normalized\n","\n","def _preprocess_scores_softmax(scores, do_negation=False, divide=True, divide_factor=None):\n","    sign = -1 if do_negation else 1\n","    negated = {k: sign*v for k, v in scores.items()}\n","    max_value = max(negated.values())\n","    if divide:\n","        assert divide_factor is not None, 'You have to specify a value p in (0, 1). Softmax is computed as e^[x/(p*max)]'\n","        exponentiate = {k: np.exp(v / (divide_factor*max_value)) for k, v in negated.items()}\n","    else:\n","        exponentiate = {k: np.exp(v - max_value) for k, v in negated.items()}\n","    total = sum(exponentiate.values())\n","    softmax = {k: v / total for k, v in exponentiate.items()}\n","    return softmax\n","\n","def balance_cluster_to_n(cluster_to_n, cluster_to_len):\n","    \"\"\"\n","        Balances the target number of samples for each cluster to ensure it doesn't exceed the actual size of the cluster.\n","\n","        The function first calculates the surplus (i.e., the excess of the target number over the actual size) for each cluster.\n","        Then, it distributes the total surplus proportionally among the clusters that have a deficit (i.e., the target number is less than the actual size).\n","        If after this distribution, there's still a deficit (i.e., the sum of target numbers is less than the sum of actual sizes), the function\n","        increases the target number of the largest clusters one by one until the sum of target numbers equals to the sum of actual sizes.\n","\n","        Parameters\n","        ----------\n","        cluster_to_n : dict\n","            A dictionary mapping cluster identifiers to their target number of samples.\n","\n","        cluster_to_len : dict\n","            A dictionary mapping cluster identifiers to the actual size of each cluster.\n","\n","        Returns\n","        -------\n","        balanced : dict\n","            A dictionary mapping cluster identifiers to their balanced target number of samples.\n","\n","        Raises\n","        ------\n","        AssertionError\n","            If the sum of target numbers before and after balancing don't match.\n","\n","    \"\"\"\n","\n","    surplus = {key: cluster_to_n[key] - cluster_to_len[key] for key in cluster_to_n if cluster_to_n[key] > cluster_to_len[key]}\n","    balanced = {k:v for k, v in cluster_to_n.items()}\n","    n_to_cluster = {v: k for k, v in cluster_to_n.items()}\n","\n","    for key in surplus:\n","        balanced[key] = cluster_to_len[key]\n","\n","    total_surplus = sum(surplus.values())\n","    initial_n_sum = sum(n for key, n in cluster_to_n.items() if key not in surplus)\n","\n","    for key in balanced:\n","        if key in surplus: continue\n","        surplus_to_add = total_surplus * cluster_to_n[key] / initial_n_sum\n","        new_n = int(cluster_to_n[key] + surplus_to_add)\n","        balanced[key] = min(new_n, cluster_to_len[key])\n","\n","    deficit = sum(cluster_to_n.values()) - sum(balanced.values())\n","    while deficit > 0:\n","        for initial_n in sorted(n_to_cluster, reverse=True):\n","            if deficit == 0:\n","                break\n","            if (cluster:=n_to_cluster[initial_n]) in surplus: continue\n","            if balanced[cluster] < cluster_to_len[cluster]:\n","                balanced[cluster] += 1\n","                deficit -= 1\n","\n","    assert sum(cluster_to_n.values()) == sum(balanced.values()), f\"Before balancing had {sum(cluster_to_n.values())}, post balancing = {sum(balanced.values())}\"\n","    return balanced\n","\n","def sample_clusters_for_active_learning(cluster_to_scores, n_samples, config, probability_type='softmax', divide=True, divide_factor=None):\n","    \"\"\"\n","        Sample molecules from clusters for active learning purposes, considering previously docked molecules and balancing the sampling among clusters.\n","\n","        This function uses either softmax or uniform probabilities to determine how many molecules to sample from each cluster. The function then samples\n","        the required number of new molecules (i.e., those not present in docked_mols) from each cluster. The sampling is balanced to ensure the target number\n","        doesn't exceed the actual size of the cluster.\n","\n","        Parameters\n","        ----------\n","        cluster_to_scores : dict\n","            A dictionary mapping cluster identifiers to their scores.\n","\n","        n_samples : int\n","            The total number of molecules to sample.\n","\n","        path_to_clusters : str\n","            The path to a pickle file storing a dictionary that maps each cluster to a list of molecules.\n","\n","        probability_type : str, optional (default='softmax')\n","            The type of probability distribution used to determine the number of samples per cluster.\n","            Options are 'softmax' and 'uniform'.\n","\n","        remove_positives : bool, optional (default=False)\n","            Only used when probability_type is 'uniform'. If True, positive scores are removed after negation.\n","\n","        lowest_score : int, optional (default=1)\n","            Only used when probability_type is 'uniform'. This value is added to all scores if the minimum score is less than zero.\n","\n","        Returns\n","        -------\n","        training : list\n","            A list of randomly sampled molecules for active learning.\n","\n","        Raises\n","        ------\n","        KeyError\n","            If an unsupported probability_type is provided.\n","        AssertionError\n","            If the number of sampled molecules doesn't equal to n_samples.\n","\n","    \"\"\"\n","    if probability_type == 'softmax':\n","        probability_function = lambda x: _preprocess_scores_softmax(x, divide=divide, divide_factor=divide_factor)\n","    elif probability_type == 'linear':\n","        probability_function = lambda x: _preprocess_scores_linearly(x)\n","    elif probability_type == 'no_score':\n","        probability_function = lambda x: x\n","    else:\n","        raise KeyError(\"Only uniform and softmax probabilities are supported\")\n","    cluster_to_mols = pickle.load(open(config['clusters_save_path'], 'rb'))\n","    cluster_to_samples = pickle.load(open(config['samples_save_path'], 'rb'))\n","    docked_mols = {smile for smiles in cluster_to_samples.values() for smile in smiles}\n","    cluster_to_new_mols = {k: [smile for smile in set(v) if smile not in docked_mols] for k, v in cluster_to_mols.items()}\n","\n","    probabilities = probability_function(cluster_to_scores)\n","    # print(f\"Probabilities\\n\", probabilities)\n","    cluster_to_n = {k: int(v * n_samples) for k, v in probabilities.items()}\n","    max_cluster_id, max_prob = None, 0\n","    for cluster, prob in probabilities.items():\n","        if prob > max_prob:\n","            max_cluster_id, max_prob = cluster, prob\n","    cluster_to_n[max_cluster_id] += n_samples - sum(cluster_to_n.values())\n","\n","    cluster_to_len = {k: len(v) for k, v in cluster_to_new_mols.items()}\n","    balanced = balance_cluster_to_n(cluster_to_n, cluster_to_len)\n","\n","    training = []\n","    np.random.seed(RANDOM_SEED)\n","    for i, (cluster, n) in enumerate(balanced.items()):\n","        training.extend(np.random.choice(cluster_to_new_mols[cluster], n, replace=False))\n","    assert len(training) == n_samples, f\"{len(training)=} != {n_samples=}\"\n","    return training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFY3C94tXbki"},"outputs":[],"source":["def combine_sampled_and_good_ligands(sampled, good_ligands, good_ligand_multiplier:int, save_path):\n","    assert isinstance(good_ligand_multiplier, int), \"A multiplier should be an integer\"\n","    keyToData = {}\n","    if sampled is not None:\n","        print(f\"Sampled {len(sampled)} molecules, of which {len(set(sampled))} are unique\")\n","        for mol in sampled:\n","            keyToData.setdefault('smiles', []).append(mol)\n","    for mol in good_ligands:\n","        for _ in range(good_ligand_multiplier):\n","            keyToData.setdefault('smiles', []).append(mol)\n","    combined = pd.DataFrame(keyToData)\n","    print(\"Combined dataframe has shape\", combined.shape)\n","    combined.to_csv(save_path)\n","    return combined"]},{"cell_type":"markdown","metadata":{"id":"xGA3B_vOC0Dn"},"source":["## Runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDhJii45al0b"},"outputs":[],"source":["cluster_to_score = compute_cluster_scores()\n","plot_mean_cluster_scores(cluster_to_score).show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9yKQZOjCzj8"},"outputs":[],"source":["plot_probability_distribution(cluster_to_score, [\n","    (\"linear\", None, None), (\"softmax\", False, np.nan), (\"softmax\", True, 1), (\"softmax\", True, 0.5), (\"softmax\", True, 0.25)\n","], bin_size=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__L_nvs-CyTl"},"outputs":[],"source":["good_ligands = pd.read_csv(scoring_config['path_to_good_ligands'])\n","print(f\"There are {len(good_ligands)} good ligands\")\n","gl_mult = int(np.ceil(N_SAMPLES/len(good_ligands)))\n","\n","training_sampled = sample_clusters_for_active_learning(cluster_to_score, n_samples=N_SAMPLES, config=sampling_config, probability_type=PROBABILITY_CALCULATION, divide=True if SOFTMAX_NORMALIZATION_TYPE == 'divide' else False, divide_factor=SOFTMAX_DIV_FACTOR)\n","df1 = combine_sampled_and_good_ligands(training_sampled, good_ligands['smiles'].values, good_ligand_multiplier=gl_mult,\n","                                 save_path=AL_TRAIN_PATH)\n","\n","diffusion_sampled = sample_clusters_for_active_learning({cluster_id: 1/100 for cluster_id in cluster_to_score.keys()}, n_samples=N_SAMPLES, config=sampling_config, probability_type='no_score', divide=True if SOFTMAX_NORMALIZATION_TYPE == 'divide' else False, divide_factor=SOFTMAX_DIV_FACTOR)\n","df2 = combine_sampled_and_good_ligands(diffusion_sampled, good_ligands['smiles'].values, good_ligand_multiplier=gl_mult,\n","                                 save_path=AL_DIFFUSION_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1691151620650,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"AHZKIQbKfXgk","outputId":"d701e3a2-6c47-4586-ca20-a11ee2af7dc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 243 good ligands\n","Combined dataframe has shape (5103, 1)\n"]}],"source":["good_ligands = pd.read_csv(scoring_config['path_to_good_ligands'])\n","print(f\"There are {len(good_ligands)} good ligands\")\n","gl_mult = int(np.ceil(N_SAMPLES/len(good_ligands)))\n","\n","df1 = combine_sampled_and_good_ligands(None, good_ligands['smiles'].values, good_ligand_multiplier=gl_mult,\n","                                 save_path=AL_TRAIN_PATH)"]},{"cell_type":"markdown","metadata":{"id":"0iAJS9sVH69y"},"source":["# Active Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1691153650336,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"i6CPhht2dnuM","outputId":"7572baf8-e52c-48b9-9ab8-b36c754149c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated molecules from previous round will be read from\n"," 2. Generation/smiles/model1_baseline_temp1.0_processed.csv\n","... active learning will be performed on\n"," 6. ActiveLearning/training_sets/model1_baseline_random_threshold11_translated.csv\n","... model weights will be LOADED from\n"," 1. Pretraining/model_weights/GPT_pretrain_07_14_23:39_1end_ignore_moses+bindingdb.pt\n","... model weights will be SAVED to\n"," 6. ActiveLearning/model_weights/model1_random_al1.pt\n","... dataset descriptors will be saved to\n"," 6. ActiveLearning/dataset_descriptors/model1_baseline_random_threshold11.yaml\n"]}],"source":["# @title Run this cell to ensure proper variables are set\n","assert MODE == 'Active Learning', \"Please go to the beginning of the notebook and set the MODE to Active Learning\"\n","# @markdown if true, weights will be loaded from 1. Pretraining/model_weights\n","# @markdown otherwise from 6. Active Learning/model_weights\n","LOAD_FROM_BASELINE = True #@param {type:\"boolean\"}\n","LOAD_CKPT_FNAME = \"GPT_pretrain_07_14_23:39_1end_ignore_moses+bindingdb.pt\" #@param [\"GPT_pretrain_07_14_23:39_1end_ignore_moses+bindingdb.pt\", \"model1_softsub_al1.pt\"]\n","if LOAD_FROM_BASELINE:\n","    CONFIG_DICT['load_ckpt_path'] = f\"{PRETRAINING_PATH}model_weights/{LOAD_CKPT_FNAME}\"\n","else:\n","    CONFIG_DICT['load_ckpt_path'] = f\"{AL_PATH}model_weights/{LOAD_CKPT_FNAME}\"\n","\n","CONFIG_DICT[\"desc_path\"] = f\"{AL_PATH}dataset_descriptors/{AL_TRAIN_PATH.split('/')[-1][:-4]}.yaml\"\n","sampling_config['path_to_predicted'] = '/content/drive/MyDrive/Generative_ML/current_data/2. Generation/smiles/model1_baseline_temp1.0_processed.csv'\n","sampling_config['path_to_completions'] = '/content/drive/MyDrive/Generative_ML/current_data/2. Generation/smiles/model1_baseline_temp1.0_completions.csv'\n","CONFIG_DICT['al_path'] = AL_TRAIN_PATH.split('.csv')[0]+'_translated.csv'\n","\n","print(\"Generated molecules from previous round will be read from\\n\", '/'.join(sampling_config['path_to_predicted'].split('/')[6:]))\n","print(\"... active learning will be performed on\\n\", '/'.join(CONFIG_DICT['al_path'].split('/')[6:]))\n","print('... model weights will be LOADED from\\n', '/'.join(CONFIG_DICT['load_ckpt_path'].split('/')[6:]))\n","print('... model weights will be SAVED to\\n', '/'.join(CONFIG_DICT['save_ckpt_path'].split('/')[6:]))\n","print('... dataset descriptors will be saved to\\n', '/'.join(CONFIG_DICT['desc_path'].split('/')[6:]))"]},{"cell_type":"markdown","metadata":{"id":"NtOQLpdXWE9w"},"source":["\n","### Translation Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsaWjfTyQ5ij"},"outputs":[],"source":["from tqdm import tqdm\n","from rdkit import Chem\n","\n","def get_mol(smile_string):\n","    mol = Chem.MolFromSmiles(smile_string)\n","    if mol is None:\n","        return None\n","    try:\n","        Chem.SanitizeMol(mol)\n","    except ValueError:\n","        return None\n","    return mol\n","\n","def fill_translation_table():\n","    smile_df = pd.read_csv(sampling_config['path_to_completions'])\n","    rdkit_to_predicted = {}\n","    pbar = tqdm(smile_df['smiles'], total=len(smile_df))\n","    for completion in pbar:\n","        if '~' not in completion: continue\n","        mol_string = completion[1:completion.index('~')]\n","        mol = get_mol(mol_string)\n","        if mol is None: continue\n","        canonic_smile = Chem.MolToSmiles(mol)\n","        rdkit_to_predicted[canonic_smile] = mol_string\n","    return rdkit_to_predicted\n","\n","def translate_dataset_for_al():\n","    rdkit_to_predicted = fill_translation_table()\n","    sampled = pd.read_csv(AL_TRAIN_PATH)\n","    translated = []\n","    for mol in sampled['smiles'].values:\n","        mol = rdkit_to_predicted[mol]\n","        translated.append(mol)\n","    pd.DataFrame({\"smiles\": translated}).to_csv(AL_TRAIN_PATH.split('.csv')[0]+'_translated.csv')\n"]},{"cell_type":"markdown","metadata":{"id":"MB99Ldh4WGAs"},"source":["### Run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TedCQM1XqhSP"},"outputs":[],"source":["translate_dataset_for_al()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-MirLdsnO6Q"},"outputs":[],"source":["def load_pretraining_vocab():\n","    import yaml\n","    with open(f\"{PRETRAINING_PATH}dataset_descriptors/moses_and_binding_no_rare_tokens.yaml\", 'r') as f:\n","        data = yaml.load(f, Loader=yaml.FullLoader)\n","    return set(data['stoi'].keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1691153839299,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"_JWTjsqFKQl5","outputId":"31c1d35d-a767-4449-8d92-39dc4acd2aae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading AL dataset from 6. ActiveLearning/training_sets/model1_baseline_random_threshold11_translated.csv\n","45 131\n"]}],"source":["al_train_dataset = load_data(CONFIG_DICT, mode='al', forced_block_size=131, forced_vocab=load_pretraining_vocab())[0]\n","print(al_train_dataset.vocab_size, al_train_dataset.block_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":876,"referenced_widgets":["66feb8bfad9246348f006a95a527a96a","b36ef68e7a2a407ca43f5495573dcdc7","c50c41190a83419bae60623616de9920","e84899f350f848a09404cd56be6b7cd9","df8b45cfaa31432fb24df9c1db87967a","00d4bfeb5bce44f4bbb773bcece01770","51ab735677ea4d80ad45dd4a4628f3aa","ca4785125fde4ae0b44abe4ddc70565b"]},"executionInfo":{"elapsed":82592,"status":"ok","timestamp":1691153924439,"user":{"displayName":"Batista Colab","userId":"04968770630191453479"},"user_tz":240},"id":"Nuh0rVnAKXlQ","outputId":"fa6e8f5f-baa1-4a31-8c56-5fa01a6ac742"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: WANDB_EXECUTABLE=python3\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230804_125749-y3c26u5o</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/generative_ml/BetaPipeline/runs/y3c26u5o' target=\"_blank\">model1_random_al1</a></strong> to <a href='https://wandb.ai/generative_ml/BetaPipeline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/generative_ml/BetaPipeline' target=\"_blank\">https://wandb.ai/generative_ml/BetaPipeline</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/generative_ml/BetaPipeline/runs/y3c26u5o' target=\"_blank\">https://wandb.ai/generative_ml/BetaPipeline/runs/y3c26u5o</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch=0\n"]},{"name":"stderr","output_type":"stream","text":["epoch 1 iter 9: train loss 0.45499. lr 2.926585e-05: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch=1\n"]},{"name":"stderr","output_type":"stream","text":["epoch 2 iter 9: train loss 0.42621. lr 2.713525e-05: 100%|██████████| 10/10 [00:03<00:00,  2.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch=2\n"]},{"name":"stderr","output_type":"stream","text":["epoch 3 iter 9: train loss 0.39971. lr 2.381678e-05: 100%|██████████| 10/10 [00:03<00:00,  2.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch=3\n"]},{"name":"stderr","output_type":"stream","text":["epoch 4 iter 9: train loss 0.39309. lr 1.963525e-05: 100%|██████████| 10/10 [00:03<00:00,  2.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch=4\n"]},{"name":"stderr","output_type":"stream","text":["epoch 5 iter 9: train loss 0.36222. lr 1.500000e-05: 100%|██████████| 10/10 [00:03<00:00,  2.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch=5\n"]},{"name":"stderr","output_type":"stream","text":["epoch 6 iter 9: train loss 0.36093. lr 1.036475e-05: 100%|██████████| 10/10 [00:03<00:00,  2.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch=6\n"]},{"name":"stderr","output_type":"stream","text":["epoch 7 iter 9: train loss 0.35033. lr 6.183221e-06: 100%|██████████| 10/10 [00:03<00:00,  2.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch=7\n"]},{"name":"stderr","output_type":"stream","text":["epoch 8 iter 9: train loss 0.34563. lr 3.000000e-06: 100%|██████████| 10/10 [00:03<00:00,  2.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch=8\n"]},{"name":"stderr","output_type":"stream","text":["epoch 9 iter 9: train loss 0.34754. lr 3.000000e-06: 100%|██████████| 10/10 [00:03<00:00,  2.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch=9\n"]},{"name":"stderr","output_type":"stream","text":["epoch 10 iter 9: train loss 0.33617. lr 3.000000e-06: 100%|██████████| 10/10 [00:03<00:00,  2.72it/s]\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66feb8bfad9246348f006a95a527a96a","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch_train_loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr><tr><td>learning_rate</td><td>███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_train_loss</td><td>██▇▇▇▆▆▆▅▅▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▁▂▁▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>epoch_train_loss</td><td>0.34342</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>step_train_loss</td><td>0.33617</td></tr><tr><td>train_step</td><td>99</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">model1_random_al1</strong> at: <a href='https://wandb.ai/generative_ml/BetaPipeline/runs/y3c26u5o' target=\"_blank\">https://wandb.ai/generative_ml/BetaPipeline/runs/y3c26u5o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230804_125749-y3c26u5o/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["model, trainer, wandb = train_GPT(\n","                train_dataset = al_train_dataset,\n","                config_dict = CONFIG_DICT,\n","                load_ckpt=True\n","        )\n","wandb.finish()\n","#GK wandb API Key: c99c9a01523f93287716691fa3360b1f4566e115\n","#RB wandb API Key: 4d3d628c6b5a4b3554c7a89ea50df8a4a6be0f85\n","#AM wandb API key: 5be14d5930441de4707f6a58e4f7c2e229dab1d1"]},{"cell_type":"markdown","metadata":{"id":"4CXn_Jqt_76M"},"source":["#BERT"]},{"cell_type":"markdown","metadata":{"id":"EJqiexX6AAsv"},"source":["##Set up notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A23L1dGiAO0V"},"outputs":[],"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# install necessary packages\n","!pip install rdkit\n","!pip install pandas==1.5.3\n","!pip install molsets\n","!pip install wandb\n","\n","# clone Sophia optimizer GitHub repository\n","!git clone https://github.com/Liuhong99/Sophia.git\n","\n","# import necessary packages\n","import numpy as np\n","import h5py\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, pairwise_distances\n","import os\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","import pkg_resources\n","pkg_resources.require(\"pandas==1.5.3\")\n","import pandas as pd\n","import re\n","import math\n","import random\n","import logging\n","import wandb\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data.dataloader import DataLoader\n","from tqdm import tqdm\n","import torch.optim as optim\n","from torch.cuda.amp import GradScaler\n","from rdkit import Chem\n","from rdkit.Chem import QED, Crippen\n","from rdkit.Contrib.SA_Score import sascorer\n","from rdkit.Chem.rdMolDescriptors import CalcTPSA\n","from rdkit.Chem.Fingerprints import FingerprintMols\n","from rdkit.DataStructs.cDataStructs import TanimotoSimilarity\n","from rdkit.Chem.Scaffolds.MurckoScaffold import MurckoScaffoldSmiles\n","import moses\n","from moses.utils import get_mol\n","from Sophia.sophia import SophiaG\n","import yaml\n","\n","# set random seed for reproducibility\n","random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","torch.cuda.manual_seed_all(42)"]},{"cell_type":"markdown","metadata":{"id":"0gbEP-i0Av6M"},"source":["##Utils & Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7FK7qHr5Axl3"},"outputs":[],"source":["@torch.no_grad()\n","def sample(model, x, steps, temperature=1.0, prop=None, scaffold=None):\n","    block_size = model.get_block_size() # define size of context window used for input conditioning\n","    model.eval()\n","    for k in range(steps):\n","        x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # limit conditioning input to the most recent block_size elements\n","        logits, _= model(x_cond, prop = prop, scaffold = scaffold) # give input to model and get logits (unnormalized scores or probabilities)\n","        logits = logits[:, -1, :] / temperature # extract the logits for the next token in the sequence\n","        probs = F.softmax(logits, dim=-1)\n","        ix = torch.multinomial(probs, 1)\n","        x = torch.cat((x, ix), dim=1) # concatenate the chosen token index with the existing sequence\n","    return x\n","\n","\n","\n","@torch.no_grad()\n","def fill_mask(model, x, temperature=1.0, prop=None, scaffold=None):\n","    block_size = model.get_block_size()  # Get model's maximum context length\n","    model.eval()\n","\n","    # Check if mask token is present\n","    mask_index = model.config.mask_index  # Assuming 'mask_index' is available in your model's config\n","    while mask_index in x[0]:  # If mask token is present\n","        # Find all mask positions\n","        mask_positions = (x[0] == mask_index).nonzero(as_tuple=True)\n","\n","        for pos in mask_positions:  # Iterate over each mask position\n","            # Limit conditioning input to the most recent block_size elements\n","            x_cond = x if x.size(1) <= block_size else x[:, -block_size:]\n","            # Get token probabilities\n","            logits, _ = model(x_cond, prop=prop, scaffold=scaffold)\n","\n","            # Extract the logits for the masked token position, apply temperature and softmax to get probabilities\n","            logits = logits[0, pos, :] / temperature\n","            probs = F.softmax(logits, dim=-1)\n","            ix = torch.multinomial(probs, 1)  # Sample token from probability distribution\n","\n","            x[0, pos] = ix  # Replace mask token with sampled token\n","\n","    return x  # Return unmasked tensor\n","\n","def check_novelty(gen_smiles, train_smiles):\n","    if len(gen_smiles) == 0:\n","        novel_ratio = 0\n","    else:\n","        duplicates = [1 for mol in gen_smiles if mol in train_smiles]\n","        novel = len(gen_smiles) - sum(duplicates)\n","        novel_ratio = novel*100/len(gen_smiles)\n","    return novel_ratio\n","\n","def canonic_smiles(smiles_or_mol):\n","    mol = get_mol(smiles_or_mol)\n","    if mol is None:\n","        return None\n","    return Chem.MolToSmiles(mol)\n","\n","class SMILESDataset(Dataset):\n","\n","    def __init__(self, data=None, content=None, block_size=None, prop=None, scaffold=None, scaffold_maxlen=None, len_data=None, mask_prob=0.15):\n","        if content is None:\n","            self.desc_only = True\n","            return\n","        self.desc_only = False\n","        self.chars = sorted(list(set(content)))\n","        data_size, vocab_size = len(content), len(self.chars)\n","        self.vocab_size = vocab_size\n","\n","        self.stoi = {ch:i for i,ch in enumerate(self.chars)}\n","        self.itos = {i:ch for i,ch in enumerate(self.chars)}\n","        self.max_len = block_size\n","        self.data = data\n","        self.prop = prop\n","        self.sca = scaffold\n","        self.scaf_max_len = scaffold_maxlen\n","        self.len_data = len_data\n","        self.mask_prob = mask_prob\n","\n","        # add X token to vocabulary\n","        self.stoi['X'] = len(self.stoi)\n","        self.itos[len(self.itos)] = 'X'\n","        self.vocab_size = len(self.stoi)\n","\n","    def export_desc_attributes(self, export_path):\n","        attr_dict = {\n","            \"desc_only\": self.desc_only,\n","            \"vocab_size\": self.vocab_size,\n","            \"max_len\": self.max_len,\n","            \"stoi\": self.stoi,\n","            \"itos\": self.itos,\n","            \"scaf_max_len\": self.scaf_max_len,\n","            \"len_data\": self.len_data\n","        }\n","        with open(export_path, 'w') as f:\n","            yaml.dump(attr_dict, f)\n","\n","    def load_desc_attributes(self, load_path):\n","        with open(load_path, 'r') as f:\n","            attr_dict = yaml.load(f, Loader=yaml.SafeLoader)\n","        self.__dict__.update(attr_dict)\n","\n","    def __len__(self):\n","        assert not self.desc_only, \"Dataset is not initialized\"\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        assert not self.desc_only, \"Dataset is not initialized\"\n","        smiles, prop, scaffold = self.data[idx].strip(), self.prop[idx], self.sca[idx]\n","        if scaffold:\n","          scaffold=scaffold.strip()\n","        pattern =  \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]|X)\"\n","        regex = re.compile(pattern)\n","\n","        #tokenize input string\n","        tokens_arr=regex.findall(smiles)\n","\n","        #Save ground truth encodings before token masking\n","        smiles_true = smiles+str('<')*(self.max_len - len(tokens_arr))\n","        if len(tokens_arr) > self.max_len:\n","            smiles_true = smiles[:self.max_len]\n","        dix_true=[self.stoi[s] for s in regex.findall(smiles_true)]\n","\n","\n","\n","        # randomly replace tokens\n","        mask_idx = [] #True indicates that the corresponding position will be ignored for computing loss\n","        for s in range(len(tokens_arr)):\n","          if random.random() < .15:\n","            mask_idx.append(False)\n","            num = random.random()\n","            if num >= .2: # 80%\n","                tokens_arr[s]='X'\n","            elif num >= 0.1: # 10%\n","                tokens_arr[s] = self.chars[int(random.random()*len(self.chars))]\n","          else:\n","            mask_idx.append(True)\n","\n","        #pad the mask appropriately\n","        while len(mask_idx)<self.max_len:\n","            mask_idx.append(True)\n","\n","        assert len(mask_idx)==self.max_len\n","        smiles=''.join(tokens_arr)\n","\n","        smiles += str('<')*(self.max_len - len(regex.findall(smiles)))\n","        if len(regex.findall(smiles)) > self.max_len:\n","            smiles = smiles[:self.max_len]\n","\n","        assert len(''.join(regex.findall(smiles)))==len(smiles)\n","        smiles=regex.findall(smiles)\n","\n","\n","        dix =  [self.stoi[s] for s in smiles]\n","        if scaffold:\n","          scaffold += str('<')*(self.scaf_max_len - len(regex.findall(scaffold)))\n","          if len(regex.findall(scaffold)) > self.scaf_max_len:\n","              scaffold = scaffold[:self.scaf_max_len]\n","          scaffold=regex.findall(scaffold)\n","          sca_dix = [self.stoi[s] for s in scaffold]\n","          sca_tensor = torch.tensor(sca_dix, dtype=torch.long)\n","        else:\n","          sca_tensor=torch.tensor(scaffold,dtype=torch.bool)\n","        x = torch.tensor(dix, dtype=torch.long)\n","        y = torch.tensor(dix_true, dtype=torch.long)\n","        prop = torch.tensor([prop], dtype=torch.float)\n","        return x, y, prop, sca_tensor, torch.tensor(mask_idx)"]},{"cell_type":"markdown","metadata":{"id":"VXLdZWy9A5Tk"},"source":["##Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wLo8qZ7yA4SF"},"outputs":[],"source":["class GPTConfig:\n","    def __init__(self, vocab_size=None, block_size=None, mask_index=None, **kwargs):\n","        self.vocab_size = vocab_size\n","        self.block_size = block_size\n","        self.mask_index = mask_index\n","        for k,v in kwargs.items():\n","            setattr(self, k, v)\n","\n","    def export_attributes(self, export_path):\n","        with open(export_path, 'w') as f:\n","            yaml.dump(vars(self), f)\n","\n","    def load_attributes(self, load_path):\n","        with open(load_path, 'r') as f:\n","            config_dict = yaml.load(f, Loader=yaml.SafeLoader)\n","        self.__dict__.update(config_dict)\n","\n","class SelfAttention(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        assert config.n_embed % config.n_head == 0\n","        self.config = config\n","\n","        self.query = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n","        self.key = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n","        self.value = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n","\n","        self.attn_drop = nn.Dropout(config.att_drop_rate)\n","        self.resid_drop = nn.Dropout(config.att_drop_rate)\n","\n","        self.proj = nn.Linear(config.n_embed, config.n_embed)\n","        self.n_head = config.n_head\n","\n","        num = int(bool(config.num_props)) + int(config.scaffold_maxlen)\n","        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size + num, config.block_size + num))\n","                                .view(1, 1, config.block_size + num, config.block_size + num))\n","\n","    def forward(self, x, layer_past=None):\n","        B, T, C = x.size()\n","        # apply attention functions to get tensors with dimensions (B, n_head, T, head_size)\n","        q = self.query(x).view(B, T, self.n_head, C // self.n_head)\n","        k = self.key(x).view(B, T, self.n_head, C // self.n_head)\n","        v = self.value(x).view(B, T, self.n_head, C // self.n_head)\n","        if self.config.do_flash:\n","            q = q.transpose(1, 2)\n","            k = k.transpose(1, 2)\n","            v = v.transpose(1, 2)\n","            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, dropout_p=self.config.att_drop_rate if self.training else 0, is_causal=self.config.is_causal)\n","            y = y.transpose(1, 2)\n","        else:\n","            # (B h T s) @ (B h s T) -> (B h T T)\n","            att = torch.einsum('bths,bihs->bhti', q, k) / math.sqrt(k.size(-1))\n","            att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n","            att = F.softmax(att, dim=-1)\n","            # (B h T T) @ (B h T s) -> (B h T s)\n","            y = torch.einsum('bhtq,bqhs->bths', att, v)\n","            self.att_weights = att\n","        self.attended = y\n","        y = y.contiguous().view(B, T, C)\n","        y = self.resid_drop(self.proj(y))\n","        self.out = y\n","        return y\n","\n","class Block(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        self.ln1 = nn.LayerNorm(config.n_embed)\n","        self.ln2 = nn.LayerNorm(config.n_embed)\n","        self.attn = SelfAttention(config)\n","        self.mlp = nn.Sequential(nn.Linear(config.n_embed, config.ff_mult*config.n_embed), nn.GELU() if config.doGELU else nn.ReLU(),\n","            nn.Linear(config.ff_mult*config.n_embed, config.n_embed), nn.Dropout(config.att_drop_rate))\n","\n","    def forward(self, x):\n","        y = self.attn(self.ln1(x))\n","        x = x + y # perform a residual connection by summing input and attention output\n","        x = x + self.mlp(self.ln2(x)) # apply layer normalization and then MLP, create a residual connection with input\n","        return x\n","\n","class GPT(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embed)\n","        self.type_emb = nn.Embedding(2, config.n_embed)\n","        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embed))\n","        # if conditioning on at least 1 property:\n","        if config.num_props:\n","            # initialize property linear layer, map property vector to embedding dimension\n","            self.prop_nn = nn.Linear(config.num_props, config.n_embed)\n","\n","        self.drop = nn.Dropout(config.gpt_drop_rate)\n","        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n","\n","        self.ln_f = nn.LayerNorm(config.n_embed)\n","        self.head = nn.Linear(config.n_embed, config.vocab_size, bias=config.gpt_bias)\n","        self.block_size = config.block_size # define the context size\n","        self.apply(self._init_weights) # initialize weights and apply to all relevant modules in the model\n","\n","    def get_block_size(self):\n","        return self.block_size\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, (nn.Linear, nn.Embedding)):\n","            module.weight.data.normal_(mean=0.0, std=0.02)\n","            if isinstance(module, nn.Linear) and module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def configure_optimizers(self, train_config):\n","        decay, no_decay = set(), set()\n","        no_decay = set()\n","\n","        whitelist_weight_modules = (torch.nn.Linear)\n","        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n","        # for named module of the model:\n","        for mn, m in self.named_modules():\n","            # for named parameter of each module:\n","            for pn, p in m.named_parameters():\n","                # construct full parameter name by concatenating module name and parameter name, separated by a dot\n","                fpn = '%s.%s' % (mn, pn) if mn else pn\n","                if pn.endswith('bias') or ('bias' in pn):\n","                    no_decay.add(fpn)\n","                elif (pn.endswith('weight') or ('weight' in pn)) and isinstance(m, whitelist_weight_modules):\n","                    decay.add(fpn)\n","                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n","                    no_decay.add(fpn)\n","        no_decay.add('pos_emb')\n","        param_dict = {pn:p for pn, p in self.named_parameters()}\n","        assert len(decay & no_decay) == 0\n","        # assert that all parameters from both sets have been correctly separated\n","        assert len(param_dict.keys() - (decay | no_decay)) == 0\n","        optim_groups = [{\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n","                        {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0}]\n","        optimizer = SophiaG(optim_groups, lr=train_config.learning_rate, betas=train_config.betas, rho=train_config.rho, weight_decay=train_config.weight_decay)\n","        return optimizer\n","\n","    def forward(self, idx, targets=None, prop=None, scaffold=None):\n","        b, t = idx.size()\n","        assert t <= self.block_size\n","        if self.config.num_props:\n","            assert prop.size(-1) == self.config.num_props, f\"number of properties {prop.size(-1)=} doesn't match the expected size {self.config.num_props=}\"\n","        token_embeddings = self.tok_emb(idx)\n","        position_embeddings = self.pos_emb[:, :t, :]\n","        type_embeddings = self.type_emb(torch.ones((b,t), dtype=torch.long, device=idx.device))\n","        x = self.drop(token_embeddings + position_embeddings + type_embeddings)\n","        # Condition on properties\n","        if self.config.num_props:\n","            type_embd = self.type_emb(torch.zeros((b, 1), dtype=torch.long, device=idx.device))\n","            if prop.ndim == 2:\n","                p = self.prop_nn(prop.unsqueeze(1))\n","            else:\n","                p = self.prop_nn(prop)\n","            p += type_embd\n","            x = torch.cat([p, x], 1)\n","        # Condition on scaffold\n","        if self.config.scaffold:\n","            type_embd = self.type_emb(torch.zeros((b, 1), dtype = torch.long, device = idx.device))\n","            scaffold_embeds = self.tok_emb(scaffold)\n","            scaffold_embeds += type_embd\n","            x = torch.cat([scaffold_embeds, x], 1)\n","\n","        # Transformer blocks\n","        for layer in self.blocks:\n","            x = layer(x)\n","        x = self.ln_f(x)\n","        logits = self.head(x)\n","\n","        if self.config.num_props and self.config.scaffold:\n","            num = int(bool(self.config.num_props)) + int(self.config.scaffold_maxlen)\n","        elif self.config.num_props:\n","            num = int(bool(self.config.num_props))\n","        elif self.config.scaffold:\n","            num = int(self.config.scaffold_maxlen)\n","        else:\n","            num = 0\n","        # Slice the logits tensor along the second dimension to exclude the first num elements\n","        logits = logits[:, num:, :]\n","\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"6Jia_2uzBQOp"},"source":["##Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"It9Ei0OYBSey"},"outputs":[],"source":["class TrainerConfig:\n","    epochs = 10\n","    batch_size = 64\n","    learning_rate = 3e-4\n","    betas = (0.965, 0.99) #(0.9, 0.95)\n","    rho = 0.04 # For SophiaG\n","    weight_decay = 0.1\n","\n","    lr_decay = False\n","    warmup_tokens = 375e6 # number of warm-up tokens for learning rate decay\n","    final_tokens = 260e9 # number of tokens at which the learning rate decays to 10% of the original\n","    num_workers = 0 # number of worker processes to use for loading data\n","\n","    def __init__(self, **kwargs):\n","        for k,v in kwargs.items():\n","            setattr(self, k, v)\n","\n","def loss_function(logits, y, mask_idx):\n","    loss=nn.CrossEntropyLoss(ignore_index=-1)\n","    y[mask_idx]=-1\n","    return loss(logits.view(-1,logits.size(-1)),y.view(-1))\n","\n","class Trainer:\n","\n","    def __init__(self, model, train_dataset, test_dataset, config, stoi, itos):\n","        self.model = model\n","        self.train_dataset = train_dataset\n","        self.test_dataset = test_dataset\n","        self.config = config\n","        self.stoi = stoi\n","        self.itos = itos\n","        self.model = self.model.to(config.device)\n","\n","    def train(self, wandb):\n","        model, config = self.model, self.config\n","        optimizer = model.configure_optimizers(config)\n","        scaler = GradScaler() # define variable used for gradient scaling in mixed-precision training\n","        self.tokens = 0 # initialize a counter used for learning rate decay\n","\n","        def run_epoch(split):\n","            is_train = split == 'train'\n","            model.train(is_train)\n","            data = self.train_dataset if is_train else self.test_dataset\n","            loader = DataLoader(data, shuffle=True, pin_memory=True, batch_size=config.batch_size, num_workers=config.num_workers)\n","            losses = []\n","            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n","            # for batch index, batch in progress bar:\n","            for it, (x, y, p, scaffold, mask_idx) in pbar:\n","                # move the input data tensor, target data tensor, property tensor, and scaffold tensor to GPU\n","                x, y, p, scaffold , mask_idx = x.to(config.device), y.to(config.device), p.to(config.device), scaffold.to(config.device), mask_idx.to(config.device)\n","                # allow model to use lower-precision computations for improved memory usage\n","                if config.device == 'cuda':\n","                    with torch.cuda.amp.autocast():\n","                        with torch.set_grad_enabled(is_train):\n","                            logits= model(x, y, p, scaffold)\n","                            loss = loss_function(logits, y, mask_idx)\n","                            loss = loss.mean()\n","                            losses.append(loss.item())\n","                else:\n","                    with torch.cpu.amp.autocast():\n","                        with torch.set_grad_enabled(is_train):\n","                            logits = model(x, y, p, scaffold)\n","                            loss = loss_function(x, y, mask_idx)\n","                            loss = loss.mean()\n","                            losses.append(loss.item())\n","\n","                if is_train:\n","                    model.zero_grad()\n","                    scaler.scale(loss).backward()\n","                    scaler.unscale_(optimizer) # unscale the gradients of the optimizer's parameters to their original values\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip gradients of model parameters to prevent them from exploding, setting maximum gradient norm to be 1.0\n","                    scaler.step(optimizer) # update the optimizer's parameters based on calculated gradients\n","                    scaler.update() # update the scale factor of the gradient scaler\n","                    if config.lr_decay:\n","                        self.tokens += (y >= 0).sum() # increment the number of processed tokens by the count of valid tokens (not padding or special tokens)\n","                        if self.tokens < config.warmup_tokens:\n","                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens)) # perform a linear warm-up\n","                        else:\n","                            # calculate the progress of training in terms of the number of tokens processed\n","                            progress = float(self.tokens - config.warmup_tokens) / float(max(1, config.final_tokens - config.warmup_tokens))\n","                            # calculate the scaling factor for the learning rate (between 0.1 and 1.0)\n","                            # to gradually reduce learning rate as training progresses\n","                            lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n","                        lr = config.learning_rate * lr_mult # multiply the base learning rate by the scaling factor to obtain the updated learning rate\n","                        for param_group in optimizer.param_groups:\n","                            param_group['lr'] = lr\n","                    else:\n","                        lr = config.learning_rate\n","                    # log training progress using Weights & Biases\n","                    if wandb is not None:\n","                        wandb.log({'step_train_loss': loss, 'train_step': it + epoch*len(loader), 'learning_rate': lr})\n","                    # update the description of the progress bar with epoch, iteration, and training loss\n","                    pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n","            return float(np.mean(losses))\n","\n","\n","        # initialize best loss as infinity\n","        best_loss = float('inf')\n","        for epoch in range(config.epochs):\n","            print(f'{epoch=}')\n","            train_loss = run_epoch('train')\n","            if self.test_dataset is not None:\n","                test_loss = run_epoch('test')\n","            if wandb is not None:\n","                wandb.log({'epoch_valid_loss': test_loss, 'epoch_train_loss': train_loss, 'epoch': epoch + 1})\n","            good_model = self.test_dataset is None or test_loss < best_loss\n","            if good_model:\n","                best_loss = test_loss\n","                torch.save(self.model.state_dict(), self.config.ckpt_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gthVEc2ZBX2u"},"outputs":[],"source":["def load_data(train_config_dict):\n","    if (cut:=train_config_dict[\"slice_data\"]):\n","        train_data = pd.read_csv(train_config_dict[\"train_path\"])[:cut]\n","        val_data = pd.read_csv(train_config_dict[\"val_path\"])[:cut]\n","    else:\n","        train_data = pd.read_csv(train_config_dict[\"train_path\"])\n","        val_data = pd.read_csv(train_config_dict[\"val_path\"])\n","\n","    smiles = train_data['smiles']\n","    vsmiles = val_data['smiles']\n","\n","    prop = train_data[train_config_dict[\"props\"]].values.tolist()\n","    vprop = val_data[train_config_dict[\"props\"]].values.tolist()\n","\n","    scaffold = train_data['scaffold_smiles']\n","    vscaffold = val_data['scaffold_smiles']\n","\n","    # define a regular expression that matches molecular tokens in SMILES strings\n","    pattern = \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]|X)\"\n","    # compile pattern into a regular expression object that can be used for matching operations\n","    regex = re.compile(pattern)\n","\n","    context = {'<'}\n","\n","    max_len, scaffold_max_len = 0, 0\n","    for iterator in (smiles.values, vsmiles.values):\n","        for i in iterator:\n","            chars = regex.findall(i.strip())\n","            max_len = max(max_len, len(chars))\n","            for char in chars:\n","                context.add(char)\n","    for iterator in (scaffold.values, vscaffold.values):\n","        for i in iterator:\n","            chars = regex.findall(i.strip())\n","            scaffold_max_len = max(scaffold_max_len, len(chars))\n","            for char in chars:\n","                context.add(char)\n","    print(max_len)\n","    context = sorted(list(context))\n","\n","    smiles = [i + str('<')*(max_len - len(regex.findall(i.strip()))) for i in smiles]\n","    vsmiles = [i + str('<')*(max_len - len(regex.findall(i.strip()))) for i in vsmiles]\n","    scaffold = [i + str('<')*(scaffold_max_len - len(regex.findall(i.strip()))) for i in scaffold]\n","    vscaffold = [i + str('<')*(scaffold_max_len - len(regex.findall(i.strip()))) for i in vscaffold]\n","\n","    # if not conditioning on scaffolds: define 'scaffold' as a list of length SMILES string filled with 'False' values\n","    scaffold=[False]*len(smiles) if not train_config_dict[\"use_scaf\"] else scaffold\n","    train_dataset = SMILESDataset(smiles, context, max_len, prop=prop, scaffold=scaffold, scaffold_maxlen=scaffold_max_len, len_data=len(train_data), mask_prob=0.15)\n","    valid_dataset = SMILESDataset(vsmiles, context, max_len, prop=vprop, scaffold=vscaffold, scaffold_maxlen=scaffold_max_len, len_data=len(val_data), mask_prob=0.15)\n","    train_dataset.export_desc_attributes(train_config_dict[\"desc_path\"])\n","    return train_dataset, valid_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWAIfqxj9to1"},"outputs":[],"source":["def pretrain_BERT(train_dataset, valid_dataset, model_config_dict, train_config_dict):\n","  \"\"\"\n","  OUTPUTS:\n","  1) checkpoint of trained model parameters\n","  2) Weights & Biases logged run\n","  \"\"\"\n","\n","  mask_index = train_dataset.stoi['X']\n","  mconf = GPTConfig(train_dataset.vocab_size, train_dataset.max_len, mask_index=mask_index, num_props=len(train_config_dict[\"props\"]), scaffold=train_config_dict[\"use_scaf\"], scaffold_maxlen=train_dataset.scaf_max_len, **model_config_dict)\n","  model = GPT(mconf).to(model_config_dict[\"device\"])\n","\n","  if train_config_dict['load_cpt'] != None:\n","    model.load_state_dict(torch.load(train_config_dict['load_cpt']))\n","  torch.compile(model)\n","\n","  tconf = TrainerConfig(warmup_tokens=0.1*train_dataset.len_data*train_dataset.max_len, final_tokens=train_config_dict[\"epochs\"]*train_dataset.len_data*train_dataset.max_len, block_size=train_dataset.max_len, **train_config_dict)\n","  trainer = Trainer(model, train_dataset, valid_dataset, tconf, train_dataset.stoi, train_dataset.itos)\n","\n","  %env WANDB_EXECUTABLE=python3\n","  wandb.init(project=\"mol_transformer\", name=train_config_dict[\"wandb_runname\"])\n","  trainer.train(wandb=wandb)\n","  return model, tconf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eApgFW7e9vd6"},"outputs":[],"source":["DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n","BASE = '/content/drive/MyDrive/Generative_ML/'\n","\n","model_config_dict = {\n","    \"device\": DEVICE,\n","    \"att_bias\": False,\n","    \"gpt_bias\": True,\n","    \"att_drop_rate\": 0.1,\n","    \"gpt_drop_rate\": 0.1,\n","    \"n_layer\": 8,\n","    \"n_head\": 8,\n","    \"n_embed\": 256,\n","    \"ff_mult\": 4, # multiplier for FF inside multihead,\n","    \"doGELU\": True, # else ReLU\n","    \"attention_times\": [],\n","    \"do_flash\": True,\n","    \"is_causal\": False\n","}\n","\n","train_config_dict = {\n","    \"desc_path\": BASE + 'checkpoints/descriptors_10k.yaml',\n","    \"train_path\": BASE + 'data/MOSES_processed_train.csv',\n","    \"val_path\": BASE + 'data/MOSES_processed_val.csv',\n","    \"slice_data\": False,\n","    \"ckpt_path\": BASE + 'checkpoints/7-03_all_mask.pt',\n","    \"wandb_runname\": \"7_03_all_mask\",\n","    \"use_scaf\": False,\n","    \"props\": [],\n","    \"device\": DEVICE,\n","    \"epochs\": 10,\n","    \"batch_size\": 512,\n","    \"lr_decay\": True,\n","    \"num_workers\": 0,\n","    \"load_cpt\": None\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xk6icEUs9xFh"},"outputs":[],"source":["train_dataset, val_dataset = load_data(train_config_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gg3xxdXyRLZ3"},"outputs":[],"source":["# define function to train BERT model\n","model, tconf = pretrain_BERT(\n","                train_dataset = train_dataset,\n","                valid_dataset = val_dataset,\n","                model_config_dict = model_config_dict,\n","                train_config_dict = train_config_dict\n","        )\n","\n","#GK wandb API Key: c99c9a01523f93287716691fa3360b1f4566e115\n","#RB wandb API Key: 4d3d628c6b5a4b3554c7a89ea50df8a4a6be0f85"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjaK3DzoSLB5"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ywY37VNWSLS9"},"source":["##Generation & Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ChKsmt1qSLS9"},"outputs":[],"source":["def generate_SMILES(model_config_dict, inference_config_dict):\n","  props = inference_config_dict[\"props\"]\n","  scaffold = inference_config_dict[\"scaffold\"]\n","\n","  # define a regular expression that matches molecular tokens in SMILES strings\n","  pattern = \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]|X)\"\n","  regex = re.compile(pattern)\n","\n","  dataset = SMILESDataset()\n","  dataset.load_desc_attributes(inference_config_dict['desc_path'])\n","  use_scaf = False if scaffold is None else True\n","\n","  mconf = GPTConfig(dataset.vocab_size, dataset.max_len, num_props=len(props), scaffold=use_scaf, scaffold_maxlen=dataset.scaf_max_len, **model_config_dict)\n","  model = GPT(mconf).to(model_config_dict['device'])\n","  torch.compile(model)\n","\n","  # load parameters into the model\n","  model.load_state_dict(torch.load(inference_config_dict[\"model_params\"], map_location=torch.device(model_config_dict['device'])))\n","  block_size = model.get_block_size() #inference_config_dict[\"block_size\"]\n","  assert block_size == dataset.max_len, \"Warning: model block size and dataset block size are different\"\n","  # calculate number of generation iterations from total number of SMILES to generate and batch size\n","  gen_iter = math.ceil(inference_config_dict[\"gen_size\"] / inference_config_dict[\"batch_size\"])\n","  stoi = dataset.stoi # define dictionary to map strings to integers\n","  itos = dataset.itos # define dictionary to map integers to strings\n","  # is a scaffold is defined for conditioning:\n","  if scaffold is not None:\n","      # pad '<' to end of scaffold string to achieve maximum scaffold length\n","      scaffold += str('<')*(dataset.scaf_max_len - len(regex.findall(scaffold)))\n","      # convert the scaffold SMILES to a tensor of integers and repeat along the batch dimension, move to GPU\n","      scaffold=torch.tensor([stoi[s] for s in regex.findall(scaffold)])[None,...].repeat(inference_config_dict[\"batch_size\"], 1).to(model_config_dict['device'])\n","\n","  if props is None:\n","    p = None\n","  elif len(props) == 1:\n","    # create a tensor for conditioning with a single property value\n","    p = torch.tensor([[props[0]]]).repeat(inference_config_dict[\"batch_size\"], 1).to(model_config_dict['device'])\n","  else:\n","    # create a tensor for conditioning with multiple property values\n","    p = torch.tensor([props]).repeat(inference_config_dict[\"batch_size\"], 1).unsqueeze(1).to(model_config_dict['device'])\n","\n","  molecules = []\n","  for i in tqdm(range(gen_iter)):\n","          # create an input tensor by converting 'context' to a tensor of token indices,\n","          # repeat this batch times along the batch dimension\n","          x = torch.tensor([stoi[s] for s in regex.findall(inference_config_dict[\"context\"])], dtype=torch.long)[None,...].repeat(inference_config_dict[\"batch_size\"], 1).to(model_config_dict['device'])\n","\n","          if ['X'] in inference_config_dict['context']:\n","            # call sample function to generate molecules conditioned on the input\n","            y = fill_mask(model, x, block_size, temperature=inference_config_dict[\"temp\"], prop=p, scaffold=scaffold)\n","          else:\n","            y = sample(model, x, block_size, temperature=inference_config_dict[\"temp\"], prop=p, scaffold=scaffold)\n","\n","          # for each generated molecule:\n","          for gen_mol in y:\n","                  # convert generated molecule from list of integers to list of strings and concatenate to one string\n","                  completion = ''.join([itos[int(i)] for i in gen_mol])\n","                  # remove padding tokens\n","                  completion = completion.replace('<', '')\n","                  # convert the string representation of the molecule to an rdkit Mol object\n","                  mol = get_mol(completion)\n","                  # if an rdkit Mol object was created:\n","                  if mol:\n","                          # append the Mol object to the list\n","                          molecules.append(mol)\n","  # create dataframe where first column contains rdkit Mols and second column contins SMILES\n","  results = pd.DataFrame([{'molecule' : i, 'smiles': Chem.MolToSmiles(i)} for i in molecules])\n","  # iterate over each SMILES and ensure that equivalent molecules have same SMILES\n","  canon_smiles = [canonic_smiles(s) for s in results['smiles']]\n","  # create set of unique SMILES strings\n","  unique_smiles = list(set(canon_smiles))\n","  data = pd.read_csv(inference_config_dict[\"train_data\"]) # load training data\n","  novel_ratio = check_novelty(unique_smiles, set(data['smiles'])) # calculate novelty ratio from generated SMILES and training SMILES\n","  results['qed'] = results['molecule'].apply(lambda x: QED.qed(x)) # quantitative estimate of drug-likeliness (QED)\n","  results['sas'] = results['molecule'].apply(lambda x: sascorer.calculateScore(x)) #synthetic accessibility score (SAS)\n","  results['logp'] = results['molecule'].apply(lambda x: Crippen.MolLogP(x)) #(measure of hydrophobicity)\n","  results['tpsa'] = results['molecule'].apply(lambda x: CalcTPSA(x)) #topological polar surface area (TPSA)\n","  results['validity'] = np.round(len(results)/(inference_config_dict[\"batch_size\"]*gen_iter), 3)\n","  results['unique'] = np.round(len(unique_smiles)/len(results), 3)\n","  results['novelty'] = np.round(novel_ratio/100, 3)\n","  # save the dataframe as a csv file\n","  results.to_csv(inference_config_dict[\"save_path\"], index = False)\n","  # print all evaluation metrics using function from moses package\n","  print(moses.get_all_metrics(list(results['smiles'].values), device=model_config_dict['device']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6N-mabNHSLS-"},"outputs":[],"source":["inference_config_dict = {\n","    # \"model_params\": train_config_dict[\"ckpt_path\"],\n","    \"model_params\": BASE + 'checkpoints/test_6_21.pt',\n","    \"train_data\": train_config_dict[\"train_path\"],\n","    # \"desc_path\": model_config_dict[\"desc_path\"],\n","    \"desc_path\": BASE + 'checkpoints/descriptors_200k.yaml',\n","    \"save_path\": BASE + 'data/test_06_21_t.csv',\n","    \"batch_size\": 1,\n","    \"gen_size\": 10,\n","    \"temp\": 1,\n","    \"context\": \"C1CCXCCC1\",\n","    \"scaffold\": None,\n","    \"props\": []\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5DqRGAxSLS-"},"outputs":[],"source":["# run function to generate SMILES strings\n","generate_SMILES(\n","              model_config_dict = model_config_dict,\n","              inference_config_dict = inference_config_dict\n","              )"]},{"cell_type":"markdown","metadata":{"id":"efDKGmL7-lKW"},"source":["We present GPT-based pipeline for molecular generation that can identify regions of PCA chemical space of interest"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["jzRj6bGQpUaM","78g7xtxZK7-e","iTFNFFNGpUaR","zWbFS84KpUaS","lo6dY-UstJbu","Mdcw_UmAV8FK","7iB0S7xSK7-i","B-JpaIyJVwYw","zBgupbjAPYu7","j8-Pj-x1K7-l","42dkxj7rRd1z","Tamyd6Hstkpl","nTDMdNdimsus","KhUk_1SLmzvh","svfAh4qsC17K","xGA3B_vOC0Dn","NtOQLpdXWE9w","4CXn_Jqt_76M","EJqiexX6AAsv","0gbEP-i0Av6M","VXLdZWy9A5Tk","6Jia_2uzBQOp"],"machine_shape":"hm","provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00d4bfeb5bce44f4bbb773bcece01770":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51ab735677ea4d80ad45dd4a4628f3aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66feb8bfad9246348f006a95a527a96a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_b36ef68e7a2a407ca43f5495573dcdc7","IPY_MODEL_c50c41190a83419bae60623616de9920"],"layout":"IPY_MODEL_e84899f350f848a09404cd56be6b7cd9"}},"b36ef68e7a2a407ca43f5495573dcdc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df8b45cfaa31432fb24df9c1db87967a","placeholder":"​","style":"IPY_MODEL_00d4bfeb5bce44f4bbb773bcece01770","value":"0.002 MB of 0.011 MB uploaded (0.000 MB deduped)\r"}},"c50c41190a83419bae60623616de9920":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_51ab735677ea4d80ad45dd4a4628f3aa","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca4785125fde4ae0b44abe4ddc70565b","value":0.15984159841598417}},"ca4785125fde4ae0b44abe4ddc70565b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df8b45cfaa31432fb24df9c1db87967a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e84899f350f848a09404cd56be6b7cd9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}