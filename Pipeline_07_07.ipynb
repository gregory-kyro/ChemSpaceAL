{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#GPT"
      ],
      "metadata": {
        "id": "94C4_8BipUaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set up notebook"
      ],
      "metadata": {
        "id": "jzRj6bGQpUaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# install necessary packages\n",
        "!pip install rdkit\n",
        "!pip install pandas==1.5.3\n",
        "!pip install molsets\n",
        "!pip install wandb\n",
        "\n",
        "# clone Sophia optimizer GitHub repository\n",
        "!git clone https://github.com/Liuhong99/Sophia.git\n",
        "\n",
        "# import necessary packages\n",
        "import numpy as np\n",
        "import h5py\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, pairwise_distances\n",
        "import os\n",
        "import random\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import pkg_resources\n",
        "pkg_resources.require(\"pandas==1.5.3\")\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import logging\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import QED, Crippen\n",
        "from rdkit.Contrib.SA_Score import sascorer\n",
        "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
        "from rdkit.Chem.Fingerprints import FingerprintMols\n",
        "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity\n",
        "from rdkit.Chem.Scaffolds.MurckoScaffold import MurckoScaffoldSmiles\n",
        "import moses\n",
        "from moses.utils import get_mol\n",
        "from Sophia.sophia import SophiaG\n",
        "import yaml\n",
        "\n",
        "# set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)"
      ],
      "metadata": {
        "id": "zVkT-uNwAUsD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "8fe1a635-cbbe-40ef-db2e-d842a50b5552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-89f2ec328947>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mount google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# install necessary packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Utils & Dataset"
      ],
      "metadata": {
        "id": "7pfZIi6qpUaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def sample(model, x, steps, temperature=1.0, prop=None, scaffold=None):\n",
        "    block_size = model.get_block_size() # define size of context window used for input conditioning\n",
        "    model.eval()\n",
        "    for k in range(steps):\n",
        "        x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # limit conditioning input to the most recent block_size elements\n",
        "        logits, _= model(x_cond, prop = prop, scaffold = scaffold) # give input to model and get logits (unnormalized scores or probabilities)\n",
        "        logits = logits[:, -1, :] / temperature # extract the logits for the next token in the sequence\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        ix = torch.multinomial(probs, 1)\n",
        "        x = torch.cat((x, ix), dim=1) # concatenate the chosen token index with the existing sequence\n",
        "    return x\n",
        "\n",
        "def check_novelty(gen_smiles, train_smiles):\n",
        "    if len(gen_smiles) == 0:\n",
        "        novel_ratio = 0\n",
        "    else:\n",
        "        duplicates = [1 for mol in gen_smiles if mol in train_smiles]\n",
        "        novel = len(gen_smiles) - sum(duplicates)\n",
        "        novel_ratio = novel*100/len(gen_smiles)\n",
        "    return novel_ratio\n",
        "\n",
        "def canonic_smiles(smiles_or_mol):\n",
        "    mol = get_mol(smiles_or_mol)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    return Chem.MolToSmiles(mol)\n",
        "\n",
        "class SMILESDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data=None, content=None, block_size=None, prop = None, scaffold = None, scaffold_maxlen = None, len_data = None):\n",
        "        if content is None:\n",
        "            self.desc_only = True\n",
        "            return\n",
        "        self.desc_only = False\n",
        "        chars = sorted(list(set(content)))\n",
        "        self.vocab_size = len(chars)\n",
        "\n",
        "        self.stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "        self.itos = {i:ch for i,ch in enumerate(chars)}\n",
        "\n",
        "        self.max_len = block_size\n",
        "        self.data = data\n",
        "        self.prop = prop # define properties to use for conditioning\n",
        "        self.sca = scaffold # define scaffold to use for conditioning\n",
        "        self.scaf_max_len = scaffold_maxlen\n",
        "        self.len_data = len_data\n",
        "\n",
        "    def export_desc_attributes(self, export_path):\n",
        "        attr_dict = {\n",
        "            \"desc_only\": self.desc_only,\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"max_len\": self.max_len,\n",
        "            \"stoi\": self.stoi,\n",
        "            \"itos\": self.itos,\n",
        "            # \"prop\": self.prop,\n",
        "            # \"sca\": self.sca,\n",
        "            \"scaf_max_len\": self.scaf_max_len,\n",
        "            \"len_data\": self.len_data\n",
        "        }\n",
        "        with open(export_path, 'w') as f:\n",
        "            yaml.dump(attr_dict, f)\n",
        "\n",
        "    def load_desc_attributes(self, load_path):\n",
        "        with open(load_path, 'r') as f:\n",
        "            attr_dict = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "        self.__dict__.update(attr_dict)\n",
        "\n",
        "    def __len__(self):\n",
        "        assert not self.desc_only, \"Dataset is not initialized\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        assert not self.desc_only, \"Dataset is not initialized\"\n",
        "        # retrieve SMILES, property, and scaffold information with a given index,\n",
        "        # remove any leading or trailing whitespaces with .strip() method\n",
        "        smiles, prop, scaffold = self.data[idx].strip(), self.prop[idx], self.sca[idx]\n",
        "        if scaffold:\n",
        "          scaffold=scaffold.strip() # remove any leading or trailing whitespaces\n",
        "        # define regular expressin pattern used to identify characters in the SMILES strings\n",
        "        pattern =  \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|!|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
        "        regex = re.compile(pattern)\n",
        "        # pad SMILES string by appending '<' to the end until self.max_len is achieved\n",
        "        smiles = str('!') + smiles\n",
        "        smiles += str('<')*(self.max_len - len(regex.findall(smiles)))\n",
        "        # if the number of matches found by the regular expression pattern applied\n",
        "        # to the SMILES string exceeds self.max_len:\n",
        "        if len(regex.findall(smiles)) > self.max_len+1:\n",
        "            smiles = smiles[:self.max_len+1]\n",
        "        # find all matches of the regular expression pattern in the SMILES string\n",
        "        smiles=regex.findall(smiles)\n",
        "        dix =  [self.stoi[s] for s in smiles]\n",
        "        if scaffold:\n",
        "          # pad scaffold string by appending '<' to the end until self.scaf_max_len is achieved\n",
        "          scaffold += str('<')*(self.scaf_max_len - len(regex.findall(scaffold)))\n",
        "          if len(regex.findall(scaffold)) > self.scaf_max_len:\n",
        "              scaffold = scaffold[:self.scaf_max_len]\n",
        "          scaffold=regex.findall(scaffold) # find all matches of the regular expression pattern in the scaffold string\n",
        "          # convert each string in scaffold to the corresponding integer\n",
        "          sca_dix = [self.stoi[s] for s in scaffold]\n",
        "          # convert scaffold index list to tensor\n",
        "          sca_tensor = torch.tensor(sca_dix, dtype=torch.long)\n",
        "        # if scaffold information is not provided:\n",
        "        else:\n",
        "          # create boolean tensor representing the absence of scaffold elements\n",
        "          # to ensure compatibility and consistency with the expected data type\n",
        "          sca_tensor=torch.tensor(scaffold,dtype=torch.bool)\n",
        "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
        "        prop = torch.tensor([prop], dtype=torch.float) # create tensor of property value associated with the SMILES\n",
        "        # return input sequence, target sequence, and associated property value\n",
        "        return x, y, prop, sca_tensor"
      ],
      "metadata": {
        "id": "3MhywaNlpUaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "iTFNFFNGpUaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTConfig:\n",
        "    def __init__(self, vocab_size=None, block_size=None, **kwargs):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.block_size = block_size\n",
        "        for k,v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "    def export_attributes(self, export_path):\n",
        "        with open(export_path, 'w') as f:\n",
        "            yaml.dump(vars(self), f)\n",
        "\n",
        "    def load_attributes(self, load_path):\n",
        "        with open(load_path, 'r') as f:\n",
        "            config_dict = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "        self.__dict__.update(config_dict)\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embed % config.n_head == 0\n",
        "        self.config = config\n",
        "\n",
        "        self.query = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n",
        "        self.key = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n",
        "        self.value = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n",
        "\n",
        "        self.attn_drop = nn.Dropout(config.att_drop_rate)\n",
        "        self.resid_drop = nn.Dropout(config.att_drop_rate)\n",
        "\n",
        "        self.proj = nn.Linear(config.n_embed, config.n_embed)\n",
        "        self.n_head = config.n_head\n",
        "\n",
        "        num = int(bool(config.num_props)) + int(config.scaffold_maxlen)\n",
        "        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size + num, config.block_size + num))\n",
        "                                .view(1, 1, config.block_size + num, config.block_size + num))\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        B, T, C = x.size()\n",
        "        # apply attention functions to get tensors with dimensions (B, n_head, T, head_size)\n",
        "        q = self.query(x).view(B, T, self.n_head, C // self.n_head)\n",
        "        k = self.key(x).view(B, T, self.n_head, C // self.n_head)\n",
        "        v = self.value(x).view(B, T, self.n_head, C // self.n_head)\n",
        "        if self.config.do_flash:\n",
        "            q = q.transpose(1, 2)\n",
        "            k = k.transpose(1, 2)\n",
        "            v = v.transpose(1, 2)\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, dropout_p=self.config.att_drop_rate if self.training else 0, is_causal=True)\n",
        "            y = y.transpose(1, 2)\n",
        "        else:\n",
        "            # (B h T s) @ (B h s T) -> (B h T T)\n",
        "            att = torch.einsum('bths,bihs->bhti', q, k) / math.sqrt(k.size(-1))\n",
        "            att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            # (B h T T) @ (B h T s) -> (B h T s)\n",
        "            y = torch.einsum('bhtq,bqhs->bths', att, v)\n",
        "            self.att_weights = att\n",
        "        self.attended = y\n",
        "        y = y.contiguous().view(B, T, C)\n",
        "        y = self.resid_drop(self.proj(y))\n",
        "        self.out = y\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(config.n_embed)\n",
        "        self.ln2 = nn.LayerNorm(config.n_embed)\n",
        "        self.attn = SelfAttention(config)\n",
        "        self.mlp = nn.Sequential(nn.Linear(config.n_embed, config.ff_mult*config.n_embed), nn.GELU() if config.doGELU else nn.ReLU(),\n",
        "            nn.Linear(config.ff_mult*config.n_embed, config.n_embed), nn.Dropout(config.att_drop_rate))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.attn(self.ln1(x))\n",
        "        x = x + y # perform a residual connection by summing input and attention output\n",
        "        x = x + self.mlp(self.ln2(x)) # apply layer normalization and then MLP, create a residual connection with input\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embed)\n",
        "        self.type_emb = nn.Embedding(2, config.n_embed)\n",
        "        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embed))\n",
        "        # if conditioning on at least 1 property:\n",
        "        if config.num_props:\n",
        "            # initialize property linear layer, map property vector to embedding dimension\n",
        "            self.prop_nn = nn.Linear(config.num_props, config.n_embed)\n",
        "\n",
        "        self.drop = nn.Dropout(config.gpt_drop_rate)\n",
        "        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(config.n_embed)\n",
        "        self.head = nn.Linear(config.n_embed, config.vocab_size, bias=config.gpt_bias)\n",
        "        self.block_size = config.block_size # define the context size\n",
        "        self.apply(self._init_weights) # initialize weights and apply to all relevant modules in the model\n",
        "\n",
        "    def get_block_size(self):\n",
        "        return self.block_size\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        decay, no_decay = set(), set()\n",
        "        no_decay = set()\n",
        "\n",
        "        whitelist_weight_modules = (torch.nn.Linear)\n",
        "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
        "        # for named module of the model:\n",
        "        for mn, m in self.named_modules():\n",
        "            # for named parameter of each module:\n",
        "            for pn, p in m.named_parameters():\n",
        "                # construct full parameter name by concatenating module name and parameter name, separated by a dot\n",
        "                fpn = '%s.%s' % (mn, pn) if mn else pn\n",
        "                if pn.endswith('bias') or ('bias' in pn):\n",
        "                    no_decay.add(fpn)\n",
        "                elif (pn.endswith('weight') or ('weight' in pn)) and isinstance(m, whitelist_weight_modules):\n",
        "                    decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
        "                    no_decay.add(fpn)\n",
        "        no_decay.add('pos_emb')\n",
        "        param_dict = {pn:p for pn, p in self.named_parameters()}\n",
        "        assert len(decay & no_decay) == 0\n",
        "        # assert that all parameters from both sets have been correctly separated\n",
        "        assert len(param_dict.keys() - (decay | no_decay)) == 0\n",
        "        optim_groups = [{\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
        "                        {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0}]\n",
        "        optimizer = SophiaG(optim_groups, lr=train_config.learning_rate, betas=train_config.betas, rho=train_config.rho, weight_decay=train_config.weight_decay)\n",
        "        return optimizer\n",
        "\n",
        "    def forward(self, idx, targets=None, prop = None, scaffold = None):\n",
        "        b, t = idx.size()\n",
        "\n",
        "        assert t <= self.block_size\n",
        "        if self.config.num_props: # if conditioning on at least one property:\n",
        "            assert prop.size(-1) == self.config.num_props, f\"number of properties {prop.size(-1)=} doesn't match the expected size {self.config.num_props=}\"\n",
        "\n",
        "        token_embeddings = self.tok_emb(idx) # pass input tensor through token embedding layer\n",
        "        # select a subset of the position embedding matrix based on the length of the input sequence\n",
        "        position_embeddings = self.pos_emb[:, :t, :]\n",
        "        # pass a tensor of ones of shape (b, t) through the type embedding layer,\n",
        "        # maps a binary type indicator to a learnable embedding vector, all type indicators\n",
        "        # are set to 1, indicating same type for all tokens in input sequence\n",
        "        type_embeddings = self.type_emb(torch.ones((b,t), dtype=torch.long, device=idx.device))\n",
        "        x = self.drop(token_embeddings + position_embeddings + type_embeddings)\n",
        "        if self.config.num_props:\n",
        "            type_embd = self.type_emb(torch.zeros((b, 1), dtype=torch.long, device=idx.device)) # create a tensor of size (b, 1, n_embed)\n",
        "            if prop.ndim == 2: # if there are multiple properties defined for conditioning (dimsnionality=2):\n",
        "                p = self.prop_nn(prop.unsqueeze(1))\n",
        "            else:\n",
        "                p = self.prop_nn(prop)\n",
        "            p += type_embd # add type embedding tensor element-wise to the property tensor\n",
        "            x = torch.cat([p, x], 1) # concatenate the property tensor with the input tensor along the second dimension\n",
        "        if self.config.scaffold:\n",
        "            # create a tensor of shape (b, 1, n_embed) to contain embeddings for\n",
        "            # a special type representing the scaffold\n",
        "            type_embd = self.type_emb(torch.zeros((b, 1), dtype = torch.long, device = idx.device))\n",
        "            scaffold_embeds = self.tok_emb(scaffold) # apply the token embedding layer to the scaffold sequence\n",
        "            scaffold_embeds += type_embd # add the type embedding tensor element-wise to the scaffold embedding tensor\n",
        "            x = torch.cat([scaffold_embeds, x], 1) # concatenate the scaffold embedding tensor with the input tensor along the second dimension\n",
        "\n",
        "        for layer in self.blocks:\n",
        "            x = layer(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "\n",
        "        if self.config.num_props and self.config.scaffold:\n",
        "            num = int(bool(self.config.num_props)) + int(self.config.scaffold_maxlen) # define number of variables to exclude from logits tensor as 1 + length of scaffold\n",
        "        elif self.config.num_props:\n",
        "            num = int(bool(self.config.num_props)) # define number of variables to exclude from logits tensor as 1\n",
        "        elif self.config.scaffold:\n",
        "            num = int(self.config.scaffold_maxlen) # define number of variables to exclude from logits tensor as length of scaffold\n",
        "        else:\n",
        "            num = 0 # define number of variables to exclude from logits tensor as 0\n",
        "        # slice the logits tensor along the second dimension to exclude the first num elements\n",
        "        logits = logits[:, num:, :]\n",
        "        loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.view(-1)) if targets is not None else None\n",
        "        return logits, loss"
      ],
      "metadata": {
        "id": "7QbYJpQ3pUaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "zWbFS84KpUaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerConfig:\n",
        "    epochs = 10\n",
        "    batch_size = 64\n",
        "    learning_rate = 3e-4\n",
        "    betas = (0.965, 0.99) #(0.9, 0.95)\n",
        "    rho = 0.04 # For SophiaG\n",
        "    weight_decay = 0.1\n",
        "\n",
        "    lr_decay = False\n",
        "    warmup_tokens = 375e6 # number of warm-up tokens for learning rate decay\n",
        "    final_tokens = 260e9 # number of tokens at which the learning rate decays to 10% of the original\n",
        "    num_workers = 0 # number of worker processes to use for loading data\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        for k,v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, train_dataset, test_dataset, config, stoi, itos):\n",
        "        self.model = model\n",
        "        self.train_dataset = train_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.config = config\n",
        "        self.stoi = stoi\n",
        "        self.itos = itos\n",
        "        self.model = self.model.to(config.device)\n",
        "\n",
        "    def train(self, wandb):\n",
        "        model, config = self.model, self.config\n",
        "        optimizer = model.configure_optimizers(config)\n",
        "        scaler = GradScaler() # define variable used for gradient scaling in mixed-precision training\n",
        "        self.tokens = 0 # initialize a counter used for learning rate decay\n",
        "\n",
        "        def run_epoch(split):\n",
        "            is_train = split == 'train'\n",
        "            model.train(is_train)\n",
        "            data = self.train_dataset if is_train else self.test_dataset\n",
        "            loader = DataLoader(data, shuffle=True, pin_memory=True, batch_size=config.batch_size, num_workers=config.num_workers)\n",
        "            losses = []\n",
        "            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n",
        "            # for batch index, batch in progress bar:\n",
        "            for it, (x, y, p, scaffold) in pbar:\n",
        "                # move the input data tensor, target data tensor, property tensor, and scaffold tensor to GPU\n",
        "                x, y, p, scaffold = x.to(config.device), y.to(config.device), p.to(config.device), scaffold.to(config.device)\n",
        "                # allow model to use lower-precision computations for improved memory usage\n",
        "                if config.device == 'cuda':\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        with torch.set_grad_enabled(is_train):\n",
        "                            logits, loss = model(x, y, p, scaffold)\n",
        "                            loss = loss.mean()\n",
        "                            losses.append(loss.item())\n",
        "                else:\n",
        "                    with torch.cpu.amp.autocast():\n",
        "                        with torch.set_grad_enabled(is_train):\n",
        "                            logits, loss = model(x, y, p, scaffold)\n",
        "                            loss = loss.mean()\n",
        "                            losses.append(loss.item())\n",
        "\n",
        "                if is_train:\n",
        "                    model.zero_grad()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(optimizer) # unscale the gradients of the optimizer's parameters to their original values\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip gradients of model parameters to prevent them from exploding, setting maximum gradient norm to be 1.0\n",
        "                    scaler.step(optimizer) # update the optimizer's parameters based on calculated gradients\n",
        "                    scaler.update() # update the scale factor of the gradient scaler\n",
        "                    if config.lr_decay:\n",
        "                        self.tokens += (y >= 0).sum() # increment the number of processed tokens by the count of valid tokens (not padding or special tokens)\n",
        "                        if self.tokens < config.warmup_tokens:\n",
        "                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens)) # perform a linear warm-up\n",
        "                        else:\n",
        "                            # calculate the progress of training in terms of the number of tokens processed\n",
        "                            progress = float(self.tokens - config.warmup_tokens) / float(max(1, config.final_tokens - config.warmup_tokens))\n",
        "                            # calculate the scaling factor for the learning rate (between 0.1 and 1.0)\n",
        "                            # to gradually reduce learning rate as training progresses\n",
        "                            lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "                        lr = config.learning_rate * lr_mult # multiply the base learning rate by the scaling factor to obtain the updated learning rate\n",
        "                        for param_group in optimizer.param_groups:\n",
        "                            param_group['lr'] = lr\n",
        "                    else:\n",
        "                        lr = config.learning_rate\n",
        "                    # log training progress using Weights & Biases\n",
        "                    if wandb is not None:\n",
        "                        wandb.log({'step_train_loss': loss, 'train_step': it + epoch*len(loader), 'learning_rate': lr})\n",
        "                    # update the description of the progress bar with epoch, iteration, and training loss\n",
        "                    pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n",
        "            return float(np.mean(losses))\n",
        "            # if is_train:\n",
        "            #     return float(np.mean(losses))\n",
        "            # if not is_train:\n",
        "            #     test_loss = float(np.mean(losses))\n",
        "            #     return test_loss\n",
        "\n",
        "        # initialize best loss as infinity\n",
        "        best_loss = float('inf')\n",
        "        for epoch in range(config.epochs):\n",
        "            print(f'{epoch=}')\n",
        "            train_loss = run_epoch('train')\n",
        "            if self.test_dataset is not None:\n",
        "                test_loss = run_epoch('test')\n",
        "            if wandb is not None:\n",
        "                wandb.log({'epoch_valid_loss': test_loss, 'epoch_train_loss': train_loss, 'epoch': epoch + 1})\n",
        "            good_model = self.test_dataset is None or test_loss < best_loss\n",
        "            if good_model:\n",
        "                best_loss = test_loss\n",
        "                torch.save(self.model.state_dict(), self.config.ckpt_path)"
      ],
      "metadata": {
        "id": "mrnqKEZwpUaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(train_config_dict):\n",
        "    if (cut:=train_config_dict[\"slice_data\"]):\n",
        "        train_data = pd.read_csv(train_config_dict[\"train_path\"])[:cut]\n",
        "        val_data = pd.read_csv(train_config_dict[\"val_path\"])[:cut]\n",
        "    else:\n",
        "        train_data = pd.read_csv(train_config_dict[\"train_path\"])\n",
        "        val_data = pd.read_csv(train_config_dict[\"val_path\"])\n",
        "\n",
        "    smiles = train_data['smiles']\n",
        "    vsmiles = val_data['smiles']\n",
        "\n",
        "    prop = train_data[train_config_dict[\"props\"]].values.tolist()\n",
        "    vprop = val_data[train_config_dict[\"props\"]].values.tolist()\n",
        "\n",
        "    scaffold = train_data['scaffold_smiles']\n",
        "    vscaffold = val_data['scaffold_smiles']\n",
        "\n",
        "    # define a regular expression that matches molecular tokens in SMILES strings\n",
        "    pattern = \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|!|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
        "    # compile pattern into a regular expression object that can be used for matching operations\n",
        "    regex = re.compile(pattern)\n",
        "\n",
        "    context = {'<','!'}\n",
        "    # context={'<'}\n",
        "\n",
        "    max_len, scaffold_max_len = 0, 0\n",
        "    for iterator in (smiles.values, vsmiles.values):\n",
        "        for i in iterator:\n",
        "            chars = regex.findall(i.strip())\n",
        "            max_len = max(max_len, len(chars))\n",
        "            for char in chars:\n",
        "                context.add(char)\n",
        "    for iterator in (scaffold.values, vscaffold.values):\n",
        "        for i in iterator:\n",
        "            chars = regex.findall(i.strip())\n",
        "            scaffold_max_len = max(scaffold_max_len, len(chars))\n",
        "            for char in chars:\n",
        "                context.add(char)\n",
        "\n",
        "    context = sorted(list(context))\n",
        "    max_len+=1    #accounting for the start token, which hasn't been added yet\n",
        "\n",
        "    smiles = [i + str('<')*(max_len - len(regex.findall(i.strip()))) for i in smiles]\n",
        "    vsmiles = [i + str('<')*(max_len - len(regex.findall(i.strip()))) for i in vsmiles]\n",
        "    scaffold = [i + str('<')*(scaffold_max_len - len(regex.findall(i.strip()))) for i in scaffold]\n",
        "    vscaffold = [i + str('<')*(scaffold_max_len - len(regex.findall(i.strip()))) for i in vscaffold]\n",
        "\n",
        "    # if not conditioning on scaffolds: define 'scaffold' as a list of length SMILES string filled with 'False' values\n",
        "    scaffold=[False]*len(smiles) if not train_config_dict[\"use_scaf\"] else scaffold\n",
        "    train_dataset = SMILESDataset(smiles, context, max_len, prop=prop, scaffold=scaffold, scaffold_maxlen=scaffold_max_len, len_data=len(train_data))\n",
        "    valid_dataset = SMILESDataset(vsmiles, context, max_len, prop=vprop, scaffold=vscaffold, scaffold_maxlen=scaffold_max_len, len_data=len(val_data))\n",
        "    train_dataset.export_desc_attributes(train_config_dict[\"desc_path\"])\n",
        "    return train_dataset, valid_dataset"
      ],
      "metadata": {
        "id": "OuGEvPXDpUaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain_GPT(train_dataset, valid_dataset, model_config_dict, train_config_dict):\n",
        "  \"\"\"\n",
        "  OUTPUTS:\n",
        "  1) checkpoint of trained model parameters\n",
        "  2) Weights & Biases logged run\n",
        "  \"\"\"\n",
        "\n",
        "  mconf = GPTConfig(train_dataset.vocab_size, train_dataset.max_len, num_props=len(train_config_dict[\"props\"]), scaffold=train_config_dict[\"use_scaf\"], scaffold_maxlen=train_dataset.scaf_max_len, **model_config_dict)\n",
        "  model = GPT(mconf)\n",
        "  model.to(model_config_dict[\"device\"])\n",
        "\n",
        "  torch.compile(model)\n",
        "\n",
        "  tconf = TrainerConfig(warmup_tokens=0.1*train_dataset.len_data*train_dataset.max_len, final_tokens=train_config_dict[\"epochs\"]*train_dataset.len_data*train_dataset.max_len, block_size=train_dataset.max_len, **train_config_dict)\n",
        "  trainer = Trainer(model, train_dataset, valid_dataset, tconf, train_dataset.stoi, train_dataset.itos)\n",
        "\n",
        "  %env WANDB_EXECUTABLE=python3\n",
        "  wandb.init(project=\"mol_transformer\", name=train_config_dict[\"wandb_runname\"])\n",
        "  trainer.train(wandb=wandb)\n",
        "  return model, tconf"
      ],
      "metadata": {
        "id": "zH-gwID9pUaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "BASE = '/content/drive/MyDrive/Generative_ML/'\n",
        "\n",
        "model_config_dict = {\n",
        "    \"device\": DEVICE,\n",
        "    \"att_bias\": False,\n",
        "    \"gpt_bias\": True,\n",
        "    \"att_drop_rate\": 0.1,\n",
        "    \"gpt_drop_rate\": 0.1,\n",
        "    \"n_layer\": 8,\n",
        "    \"n_head\": 8,\n",
        "    \"n_embed\": 256,\n",
        "    \"ff_mult\": 4, # multiplier for FF inside multihead,\n",
        "    \"doGELU\": True, # else ReLU\n",
        "    \"attention_times\": [],\n",
        "    \"do_flash\": True,\n",
        "}\n",
        "\n",
        "train_config_dict = {\n",
        "    \"desc_path\": BASE + 'checkpoints/descriptors_10k.yaml',\n",
        "    \"train_path\": BASE + 'data/MOSES_processed_train.csv',\n",
        "    \"val_path\": BASE + 'data/MOSES_processed_val.csv',\n",
        "    \"slice_data\": False,\n",
        "    \"ckpt_path\": BASE + 'current_data/GPT_pretrain_07-06.pt',\n",
        "    \"wandb_runname\": 'GPT_pretrain_07-06',\n",
        "    \"use_scaf\": False,\n",
        "    \"props\": [],\n",
        "    \"device\": DEVICE,\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 512,\n",
        "    \"lr_decay\": True,\n",
        "    \"num_workers\": 0,\n",
        "}"
      ],
      "metadata": {
        "id": "sovWcrBipUaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = load_data(train_config_dict)"
      ],
      "metadata": {
        "id": "mWOb6fsKpUaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to train GPT model\n",
        "model, tconf = pretrain_GPT(\n",
        "                train_dataset = train_dataset,\n",
        "                valid_dataset = val_dataset,\n",
        "                model_config_dict = model_config_dict,\n",
        "                train_config_dict = train_config_dict\n",
        "        )\n",
        "\n",
        "#GK wandb API Key: c99c9a01523f93287716691fa3360b1f4566e115\n",
        "#RB wandb API Key: 4d3d628c6b5a4b3554c7a89ea50df8a4a6be0f85"
      ],
      "metadata": {
        "id": "uvCDiyssBbZl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "c92e9da7-7aca-442d-80db-e8668899cbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_EXECUTABLE=python3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:lyhzcckw) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>▁▂▃▄▄▅▆▇████████████████████████████████</td></tr><tr><td>step_train_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0003</td></tr><tr><td>step_train_loss</td><td>0.40228</td></tr><tr><td>train_step</td><td>1376</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">PT_pretrain_07-06</strong> at: <a href='https://wandb.ai/generative_ml/mol_transformer/runs/lyhzcckw' target=\"_blank\">https://wandb.ai/generative_ml/mol_transformer/runs/lyhzcckw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230706_174635-lyhzcckw/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:lyhzcckw). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230706_175324-wh8my2sz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/generative_ml/mol_transformer/runs/wh8my2sz' target=\"_blank\">PT_pretrain_07-06</a></strong> to <a href='https://wandb.ai/generative_ml/mol_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/generative_ml/mol_transformer' target=\"_blank\">https://wandb.ai/generative_ml/mol_transformer</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/generative_ml/mol_transformer/runs/wh8my2sz' target=\"_blank\">https://wandb.ai/generative_ml/mol_transformer/runs/wh8my2sz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 1 iter 2784: train loss 0.37426. lr 2.939239e-04: 100%|██████████| 2785/2785 [08:38<00:00,  5.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2 iter 2784: train loss 0.34127. lr 2.735515e-04: 100%|██████████| 2785/2785 [08:42<00:00,  5.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generation & Evaluation"
      ],
      "metadata": {
        "id": "PR2QZRicBmed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_SMILES(model_config_dict, inference_config_dict):\n",
        "  props = inference_config_dict[\"props\"]\n",
        "  scaffold = inference_config_dict[\"scaffold\"]\n",
        "\n",
        "  # define a regular expression that matches molecular tokens in SMILES strings\n",
        "  pattern = \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|!|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
        "  regex = re.compile(pattern)\n",
        "\n",
        "  dataset = SMILESDataset()\n",
        "  dataset.load_desc_attributes(inference_config_dict['desc_path'])\n",
        "  use_scaf = False if scaffold is None else True\n",
        "\n",
        "  mconf = GPTConfig(dataset.vocab_size, dataset.max_len, num_props=len(props), scaffold=use_scaf, scaffold_maxlen=dataset.scaf_max_len, **model_config_dict)\n",
        "  model = GPT(mconf).to(model_config_dict['device'])\n",
        "  torch.compile(model)\n",
        "\n",
        "  # load parameters into the model\n",
        "  model.load_state_dict(torch.load(inference_config_dict[\"model_params\"], map_location=torch.device(model_config_dict['device'])))\n",
        "  block_size = model.get_block_size() #inference_config_dict[\"block_size\"]\n",
        "  assert block_size == dataset.max_len, \"Warning: model block size and dataset block size are different\"\n",
        "  # calculate number of generation iterations from total number of SMILES to generate and batch size\n",
        "  gen_iter = math.ceil(inference_config_dict[\"gen_size\"] / inference_config_dict[\"batch_size\"])\n",
        "  stoi = dataset.stoi # define dictionary to map strings to integers\n",
        "  itos = dataset.itos # define dictionary to map integers to strings\n",
        "  # is a scaffold is defined for conditioning:\n",
        "  if scaffold is not None:\n",
        "      # pad '<' to end of scaffold string to achieve maximum scaffold length\n",
        "      scaffold += str('<')*(dataset.scaf_max_len - len(regex.findall(scaffold)))\n",
        "      # convert the scaffold SMILES to a tensor of integers and repeat along the batch dimension, move to GPU\n",
        "      scaffold=torch.tensor([stoi[s] for s in regex.findall(scaffold)])[None,...].repeat(inference_config_dict[\"batch_size\"], 1).to(model_config_dict['device'])\n",
        "\n",
        "  if props is None:\n",
        "    p = None\n",
        "  elif len(props) == 1:\n",
        "    # create a tensor for conditioning with a single property value\n",
        "    p = torch.tensor([[props[0]]]).repeat(inference_config_dict[\"batch_size\"], 1).to(model_config_dict['device'])\n",
        "  else:\n",
        "    # create a tensor for conditioning with multiple property values\n",
        "    p = torch.tensor([props]).repeat(inference_config_dict[\"batch_size\"], 1).unsqueeze(1).to(model_config_dict['device'])\n",
        "\n",
        "  molecules = []\n",
        "  for i in tqdm(range(gen_iter)):\n",
        "          # create an input tensor by converting 'context' to a tensor of token indices,\n",
        "          # repeat this batch times along the batch dimension\n",
        "          x = torch.tensor([stoi[s] for s in regex.findall(inference_config_dict[\"context\"])], dtype=torch.long)[None,...].repeat(inference_config_dict[\"batch_size\"], 1).to(model_config_dict['device'])\n",
        "          # call sample function to generate molecules conditioned on the input\n",
        "          y = sample(model, x, block_size, temperature=inference_config_dict[\"temp\"], prop=p, scaffold=scaffold)\n",
        "          # for each generated molecule:\n",
        "          for gen_mol in y:\n",
        "                  # convert generated molecule from list of integers to list of strings and concatenate to one string\n",
        "                  completion = ''.join([itos[int(i)] for i in gen_mol])\n",
        "                  # remove padding tokens\n",
        "                  completion = completion.replace('<', '')\n",
        "                  completion = completion.replace('!', '')\n",
        "                  # convert the string representation of the molecule to an rdkit Mol object\n",
        "                  mol = get_mol(completion)\n",
        "                  # if an rdkit Mol object was created:\n",
        "                  if mol:\n",
        "                          # append the Mol object to the list\n",
        "                          molecules.append(mol)\n",
        "  # create dataframe where first column contains rdkit Mols and second column contins SMILES\n",
        "  results = pd.DataFrame([{'molecule' : i, 'smiles': Chem.MolToSmiles(i)} for i in molecules])\n",
        "  # iterate over each SMILES and ensure that equivalent molecules have same SMILES\n",
        "  canon_smiles = [canonic_smiles(s) for s in results['smiles']]\n",
        "  # create set of unique SMILES strings\n",
        "  unique_smiles = list(set(canon_smiles))\n",
        "  data = pd.read_csv(inference_config_dict[\"train_data\"]) # load training data\n",
        "  novel_ratio = check_novelty(unique_smiles, set(data['smiles'])) # calculate novelty ratio from generated SMILES and training SMILES\n",
        "  results['qed'] = results['molecule'].apply(lambda x: QED.qed(x)) # quantitative estimate of drug-likeliness (QED)\n",
        "  results['sas'] = results['molecule'].apply(lambda x: sascorer.calculateScore(x)) #synthetic accessibility score (SAS)\n",
        "  results['logp'] = results['molecule'].apply(lambda x: Crippen.MolLogP(x)) #(measure of hydrophobicity)\n",
        "  results['tpsa'] = results['molecule'].apply(lambda x: CalcTPSA(x)) #topological polar surface area (TPSA)\n",
        "  results['validity'] = np.round(len(results)/(inference_config_dict[\"batch_size\"]*gen_iter), 3)\n",
        "  results['unique'] = np.round(len(unique_smiles)/len(results), 3)\n",
        "  results['novelty'] = np.round(novel_ratio/100, 3)\n",
        "  # save the dataframe as a csv file\n",
        "  results.to_csv(inference_config_dict[\"save_path\"], index = False)\n",
        "  # print all evaluation metrics using function from moses package\n",
        "  print(moses.get_all_metrics(list(results['smiles'].values), device=model_config_dict['device']))"
      ],
      "metadata": {
        "id": "4RccqlCxBqFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_config_dict = {\n",
        "    # \"model_params\": train_config_dict[\"ckpt_path\"],\n",
        "    \"model_params\": BASE + 'current_data/GPT_pretrain_07-06.pt',\n",
        "    \"train_data\": train_config_dict[\"train_path\"],\n",
        "    # \"desc_path\": model_config_dict[\"desc_path\"],\n",
        "    \"desc_path\": BASE + 'checkpoints/descriptors_10k.yaml',\n",
        "    \"save_path\": BASE + 'current_data/GPT_pretrain_inference_07-06.csv',\n",
        "    \"checkpoint_dir\": BASE + 'current_data/',\n",
        "    \"batch_size\": 1,\n",
        "    \"gen_size\": 10000,\n",
        "    \"temp\": 1,\n",
        "    \"context\": \"!\",\n",
        "    \"scaffold\": None,\n",
        "    \"props\": []\n",
        "}"
      ],
      "metadata": {
        "id": "uO6ReKqdBt85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run function to generate SMILES strings\n",
        "generate_SMILES(\n",
        "              model_config_dict = model_config_dict,\n",
        "              inference_config_dict = inference_config_dict\n",
        "              )"
      ],
      "metadata": {
        "id": "4pCo5E2K-EtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sampling for DiffDock"
      ],
      "metadata": {
        "id": "RmPym8y6p18t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5iCVkclJXWf",
        "outputId": "249fc9e9-44c7-4b62-a008-684b2f1ac929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew77adUnI5WJ",
        "outputId": "ace942ba-d296-4161-82b0-75face393b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (8.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rdkit.Chem\n",
        "import rdkit.Chem.Descriptors\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "def descriptors_for_gpt_predictions(path_to_predicted, path_to_save):\n",
        "    gpt_mols = pd.read_csv(path_to_predicted)\n",
        "    keySet = None\n",
        "    keyToData = {}\n",
        "    pbar = tqdm(gpt_mols.iterrows(), total=len(gpt_mols))\n",
        "    for index, row in pbar:\n",
        "        smile = row['smiles']\n",
        "        mol = rdkit.Chem.MolFromSmiles(smile)\n",
        "        if not mol: continue\n",
        "        mol_data = rdkit.Chem.Descriptors.CalcMolDescriptors(mol)\n",
        "        if keySet is None:\n",
        "            keySet = set(mol_data.keys())\n",
        "        for key in keySet:\n",
        "            keyToData.setdefault(key, []).append(mol_data[key])\n",
        "        keyToData.setdefault('smiles', []).append(smile)\n",
        "    gpt_df = pd.DataFrame(keyToData)\n",
        "    gpt_df.to_pickle(path_to_save)\n",
        "    return gpt_df\n",
        "\n",
        "descriptors_for_gpt_predictions(path_to_predicted=inference_config_dict['save_path'], path_to_save=inference_config_dict['save_path'].split('.')[0]+'_descriptors.pickle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "hPBcXwkBIZIL",
        "outputId": "f5748b39-65c2-4662-b6fb-5fec02e93a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9960/9960 [01:56<00:00, 85.80it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      SlogP_VSA3  SMR_VSA10  VSA_EState3      Chi0v     Chi1v  fr_COO2  \\\n",
              "0      19.386400   5.817863     3.995305  13.774088  8.439863        0   \n",
              "1       4.794537  23.356451    11.126017  13.943740  8.356280        0   \n",
              "2      11.339294   5.907180    14.740891  13.842987  7.425829        0   \n",
              "3      27.659472  21.617857     2.758791  14.213796  9.196835        0   \n",
              "4      20.640100  17.112217     0.000000  14.209419  8.470927        0   \n",
              "...          ...        ...          ...        ...       ...      ...   \n",
              "9955   11.339294  23.195506    11.717590  11.093376  6.127098        0   \n",
              "9956   28.414708  15.710677     0.000000  12.553510  7.685074        0   \n",
              "9957   22.683039   5.907180     6.451621  13.127244  7.267950        0   \n",
              "9958    0.000000  11.594566    13.489445  12.711753  7.144210        0   \n",
              "9959    0.000000  11.718501     2.867889  11.498113  6.969845        0   \n",
              "\n",
              "      NumAromaticRings  fr_imidazole  fr_Imine  PEOE_VSA13  ...  fr_NH2  \\\n",
              "0                    3             0         0    5.890724  ...       0   \n",
              "1                    2             0         0    5.222756  ...       0   \n",
              "2                    1             0         0    0.000000  ...       0   \n",
              "3                    2             0         0    0.000000  ...       0   \n",
              "4                    2             1         0    5.559267  ...       0   \n",
              "...                ...           ...       ...         ...  ...     ...   \n",
              "9955                 2             0         0    5.559267  ...       0   \n",
              "9956                 2             0         0   15.582558  ...       0   \n",
              "9957                 2             0         0    5.890724  ...       0   \n",
              "9958                 3             0         0   12.332624  ...       0   \n",
              "9959                 2             0         0    0.000000  ...       0   \n",
              "\n",
              "      fr_azo  PEOE_VSA8  PEOE_VSA9  NumSaturatedCarbocycles   TPSA    Kappa3  \\\n",
              "0          0  25.707178   5.563451                        0  55.05  2.892365   \n",
              "1          0  24.784799   0.000000                        0  68.02  5.181651   \n",
              "2          0  18.504503  18.063713                        0  71.25  2.950509   \n",
              "3          0  44.012229   4.895483                        0  79.37  3.467237   \n",
              "4          0  33.729613   0.000000                        0  65.06  2.576326   \n",
              "...      ...        ...        ...                      ...    ...       ...   \n",
              "9955       0  12.263211  22.342692                        0  74.89  3.247899   \n",
              "9956       0  20.354313  11.502365                        0  77.40  3.502383   \n",
              "9957       0   6.544756   0.000000                        0  77.25  4.962452   \n",
              "9958       0  11.753753   5.687386                        0  94.82  4.309710   \n",
              "9959       0  24.625830   6.041841                        0  45.23  3.017634   \n",
              "\n",
              "      FractionCSP3     Chi3v                                       smiles  \n",
              "0         0.315789  4.391160        CCCc1noc(-c2ccc(N3CCc4ccccc4C3)nc2)n1  \n",
              "1         0.437500  4.047044          Cc1nnc(SCCCC(=O)Nc2ccc(C(C)C)cc2)o1  \n",
              "2         0.800000  4.685508   Cc1nc(C)n(CC(C)C(=O)N2CC(C)(C)C(C)(O)C2)n1  \n",
              "3         0.294118  5.942220  CN(CCc1ccccn1)S(=O)(=O)c1ccc2c(c1)CCC(=O)N2  \n",
              "4         0.687500  4.702001      CCCCCn1c(N2CCCC2)nc2c1c(=O)n(C)c(=O)n2C  \n",
              "...            ...       ...                                          ...  \n",
              "9955      0.071429  2.912089           N#Cc1ccc(Cl)c(NC(=O)Cn2ccccc2=O)c1  \n",
              "9956      0.214286  4.293706         COCc1ccc(S(=O)(=O)Nc2cccn(C)c2=O)cc1  \n",
              "9957      0.437500  3.164395          Cc1noc(COCC(=O)NCc2ccc(C(C)C)cc2)n1  \n",
              "9958      0.133333  3.052115    O=C(Nc1ccc(-n2cnnn2)cc1)c1cccc(OCC(F)F)n1  \n",
              "9959      0.250000  3.700032             O=C(Nc1ccncc1)N1CCCC1c1ccc(F)cc1  \n",
              "\n",
              "[9960 rows x 210 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f081120-c1fb-4eb1-9a81-06a65131567a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SlogP_VSA3</th>\n",
              "      <th>SMR_VSA10</th>\n",
              "      <th>VSA_EState3</th>\n",
              "      <th>Chi0v</th>\n",
              "      <th>Chi1v</th>\n",
              "      <th>fr_COO2</th>\n",
              "      <th>NumAromaticRings</th>\n",
              "      <th>fr_imidazole</th>\n",
              "      <th>fr_Imine</th>\n",
              "      <th>PEOE_VSA13</th>\n",
              "      <th>...</th>\n",
              "      <th>fr_NH2</th>\n",
              "      <th>fr_azo</th>\n",
              "      <th>PEOE_VSA8</th>\n",
              "      <th>PEOE_VSA9</th>\n",
              "      <th>NumSaturatedCarbocycles</th>\n",
              "      <th>TPSA</th>\n",
              "      <th>Kappa3</th>\n",
              "      <th>FractionCSP3</th>\n",
              "      <th>Chi3v</th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.386400</td>\n",
              "      <td>5.817863</td>\n",
              "      <td>3.995305</td>\n",
              "      <td>13.774088</td>\n",
              "      <td>8.439863</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.890724</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.707178</td>\n",
              "      <td>5.563451</td>\n",
              "      <td>0</td>\n",
              "      <td>55.05</td>\n",
              "      <td>2.892365</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>4.391160</td>\n",
              "      <td>CCCc1noc(-c2ccc(N3CCc4ccccc4C3)nc2)n1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.794537</td>\n",
              "      <td>23.356451</td>\n",
              "      <td>11.126017</td>\n",
              "      <td>13.943740</td>\n",
              "      <td>8.356280</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.222756</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.784799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>68.02</td>\n",
              "      <td>5.181651</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>4.047044</td>\n",
              "      <td>Cc1nnc(SCCCC(=O)Nc2ccc(C(C)C)cc2)o1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.339294</td>\n",
              "      <td>5.907180</td>\n",
              "      <td>14.740891</td>\n",
              "      <td>13.842987</td>\n",
              "      <td>7.425829</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18.504503</td>\n",
              "      <td>18.063713</td>\n",
              "      <td>0</td>\n",
              "      <td>71.25</td>\n",
              "      <td>2.950509</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>4.685508</td>\n",
              "      <td>Cc1nc(C)n(CC(C)C(=O)N2CC(C)(C)C(C)(O)C2)n1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27.659472</td>\n",
              "      <td>21.617857</td>\n",
              "      <td>2.758791</td>\n",
              "      <td>14.213796</td>\n",
              "      <td>9.196835</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44.012229</td>\n",
              "      <td>4.895483</td>\n",
              "      <td>0</td>\n",
              "      <td>79.37</td>\n",
              "      <td>3.467237</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>5.942220</td>\n",
              "      <td>CN(CCc1ccccn1)S(=O)(=O)c1ccc2c(c1)CCC(=O)N2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.640100</td>\n",
              "      <td>17.112217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.209419</td>\n",
              "      <td>8.470927</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5.559267</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33.729613</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>65.06</td>\n",
              "      <td>2.576326</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>4.702001</td>\n",
              "      <td>CCCCCn1c(N2CCCC2)nc2c1c(=O)n(C)c(=O)n2C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9955</th>\n",
              "      <td>11.339294</td>\n",
              "      <td>23.195506</td>\n",
              "      <td>11.717590</td>\n",
              "      <td>11.093376</td>\n",
              "      <td>6.127098</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.559267</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.263211</td>\n",
              "      <td>22.342692</td>\n",
              "      <td>0</td>\n",
              "      <td>74.89</td>\n",
              "      <td>3.247899</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>2.912089</td>\n",
              "      <td>N#Cc1ccc(Cl)c(NC(=O)Cn2ccccc2=O)c1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9956</th>\n",
              "      <td>28.414708</td>\n",
              "      <td>15.710677</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.553510</td>\n",
              "      <td>7.685074</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.582558</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.354313</td>\n",
              "      <td>11.502365</td>\n",
              "      <td>0</td>\n",
              "      <td>77.40</td>\n",
              "      <td>3.502383</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>4.293706</td>\n",
              "      <td>COCc1ccc(S(=O)(=O)Nc2cccn(C)c2=O)cc1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9957</th>\n",
              "      <td>22.683039</td>\n",
              "      <td>5.907180</td>\n",
              "      <td>6.451621</td>\n",
              "      <td>13.127244</td>\n",
              "      <td>7.267950</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.890724</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.544756</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>77.25</td>\n",
              "      <td>4.962452</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>3.164395</td>\n",
              "      <td>Cc1noc(COCC(=O)NCc2ccc(C(C)C)cc2)n1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9958</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.594566</td>\n",
              "      <td>13.489445</td>\n",
              "      <td>12.711753</td>\n",
              "      <td>7.144210</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.332624</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.753753</td>\n",
              "      <td>5.687386</td>\n",
              "      <td>0</td>\n",
              "      <td>94.82</td>\n",
              "      <td>4.309710</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>3.052115</td>\n",
              "      <td>O=C(Nc1ccc(-n2cnnn2)cc1)c1cccc(OCC(F)F)n1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9959</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.718501</td>\n",
              "      <td>2.867889</td>\n",
              "      <td>11.498113</td>\n",
              "      <td>6.969845</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.625830</td>\n",
              "      <td>6.041841</td>\n",
              "      <td>0</td>\n",
              "      <td>45.23</td>\n",
              "      <td>3.017634</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>3.700032</td>\n",
              "      <td>O=C(Nc1ccncc1)N1CCCC1c1ccc(F)cc1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9960 rows × 210 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f081120-c1fb-4eb1-9a81-06a65131567a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f081120-c1fb-4eb1-9a81-06a65131567a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f081120-c1fb-4eb1-9a81-06a65131567a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "def project_into_pca_space(path_to_pca, path_to_mols):\n",
        "    scaler, pca = pickle.load(open(path_to_pca, 'rb'))\n",
        "    gptMols = pd.read_pickle(path_to_mols)\n",
        "    return gptMols['smiles'], pca.transform(scaler.transform(gptMols[scaler.get_feature_names_out()]))\n",
        "\n",
        "gpt_smiles, pca_transformed = project_into_pca_space(path_to_pca=inference_config_dict['checkpoint_dir'] + 'scaler_pca_tuple.pickle', path_to_mols=inference_config_dict['save_path'].split('.')[0]+'_descriptors.pickle')"
      ],
      "metadata": {
        "id": "k2Te1IDeJnao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def _cluster_mols_experimental_loss(mols, n_clusters, n_iter):\n",
        "    min_loss, best_kmeans = float('inf'), None\n",
        "    for _ in range(n_iter):\n",
        "        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', init='k-means++').fit(mols)\n",
        "        if kmeans.inertia_ < min_loss:\n",
        "            min_loss = kmeans.inertia_\n",
        "            best_kmeans = kmeans\n",
        "    return best_kmeans\n",
        "\n",
        "def _cluster_mols_experimental_variance(mols, n_clusters, n_iter):\n",
        "    max_variance, best_kmeans = float('-inf'), None\n",
        "    for _ in range(n_iter):\n",
        "        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', init='k-means++').fit(mols)\n",
        "        counts = np.unique(kmeans.labels_, return_counts=True)[1]\n",
        "        if (variance:=np.var(counts)) > max_variance:\n",
        "            max_variance = variance\n",
        "            best_kmeans = kmeans\n",
        "    return best_kmeans\n",
        "\n",
        "def _cluster_mols_experimental_mixed(mols, n_clusters, n_iter, mixed_objective_loss_quantile):\n",
        "    inertias = []\n",
        "    variances = []\n",
        "    km_objs = []\n",
        "    for _ in range(n_iter):\n",
        "        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', init='k-means++').fit(mols)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "        counts = np.unique(kmeans.labels_, return_counts=True)[1]\n",
        "        variances.append(np.var(counts))\n",
        "        km_objs.append(kmeans)\n",
        "    loss_var_kmeans_triples = sorted(zip(inertias, variances, km_objs), key=lambda x: x[0])\n",
        "    lowest_n = loss_var_kmeans_triples[:int(len(loss_var_kmeans_triples) * mixed_objective_loss_quantile)]\n",
        "    sorted_by_variance = sorted(lowest_n, key=lambda x: x[1])\n",
        "    return sorted_by_variance[0][2]\n",
        "\n",
        "def _cluster_mols_experimental(mols, n_clusters, save_path, n_iter=1, objective='loss', mixed_objective_loss_quantile=0.1):\n",
        "    if n_iter == 1:\n",
        "        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', init='k-means++').fit(mols)\n",
        "    elif objective == 'loss':\n",
        "        kmeans = _cluster_mols_experimental_loss(mols, n_clusters, n_iter)\n",
        "    elif objective == 'variance':\n",
        "        kmeans = _cluster_mols_experimental_variance(mols, n_clusters, n_iter)\n",
        "    elif objective == 'mixed':\n",
        "        kmeans = _cluster_mols_experimental_mixed(mols, n_clusters, n_iter, mixed_objective_loss_quantile)\n",
        "    else:\n",
        "        raise ValueError(f'Unknown objective {objective}')\n",
        "\n",
        "    pickle.dump(kmeans, open(save_path, 'wb'))\n",
        "    return kmeans\n",
        "\n",
        "# out = _cluster_mols_experimental(mols=pca_transformed, n_clusters=100, n_iter=1_000)"
      ],
      "metadata": {
        "id": "0XGAgRrOKPo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from pprint import pprint as pp\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def cluster_and_sample(mols, mols_smiles, n_clusters, n_samples, kmeans_save_path, clusters_save_path, ensure_correctness=False, path_to_pca=None):\n",
        "    \"\"\"\n",
        "        Clusters a given list of molecules, samples from each cluster, and saves the resulting data to specified files.\n",
        "\n",
        "        This function performs K-Means clustering on the input list of molecules and then samples a specified number of molecules\n",
        "        from each cluster. The function ensures that the number of samples requested from each cluster doesn't exceed the total number\n",
        "        of available molecules. The clustered data and sampled data are saved to specified file paths using pickle.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mols : array-like or sparse matrix, shape (n_samples, n_features)\n",
        "            The input samples where n_samples is the number of samples and n_features is the number of features.\n",
        "\n",
        "        mols_smiles : list of str\n",
        "            A list of SMILES strings corresponding to the input molecules.\n",
        "\n",
        "        n_clusters : int\n",
        "            The number of clusters to form as well as the number of centroids to generate.\n",
        "\n",
        "        n_samples : int\n",
        "            The number of samples to draw from each cluster.\n",
        "\n",
        "        kmeans_save_path : str\n",
        "            The path (including file name) where the resulting KMeans object should be saved.\n",
        "\n",
        "        clusters_save_path : str\n",
        "            The path (including file name) where the resulting clusters should be saved.\n",
        "\n",
        "        ensure_correctness : bool, optional (default=False)\n",
        "            If True, performs additional correctness checks, such as comparing SMILES string derived features to features in mols array.\n",
        "            This requires 'path_to_pca' to be set.\n",
        "\n",
        "        path_to_pca : str, optional (default=None)\n",
        "            If ensure_correctness is True, this should be the path to a PCA model used to transform the molecules' descriptors.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        cluster_to_samples : dict\n",
        "            A dictionary where the keys are cluster labels and the values are lists of sampled SMILES strings from each cluster.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        AssertionError\n",
        "            If the number of requested samples exceeds the total number of molecules provided.\n",
        "            If ensure_correctness is True but path_to_pca is None.\n",
        "            If the number of labels returned by the KMeans algorithm differs from the number of molecules.\n",
        "            If features calculated from a smile string differ from features in the mols array.\n",
        "            If the total number of sampled molecules doesn't equal to n_clusters * n_samples.\n",
        "\n",
        "    \"\"\"\n",
        "    assert n_clusters * n_samples <= len(mols), f\"{n_clusters=} * {n_samples=} = {n_clusters*n_samples} requested but only {len(mols)} molecules provided\"\n",
        "    if ensure_correctness:\n",
        "        assert path_to_pca is not None, \"path_to_pca must be provided to ensure correctness\"\n",
        "        scaler, pca = pickle.load(open(path_to_pca, 'rb'))\n",
        "\n",
        "    kmeans = _cluster_mols_experimental(mols=mols, n_iter=100, n_clusters=n_clusters, save_path=kmeans_save_path, objective='mixed', mixed_objective_loss_quantile=0.05)\n",
        "    assert len(kmeans.labels_) == len(mols_smiles), \"Number of labels differs from number of molecules\"\n",
        "\n",
        "    cluster_to_mols = {}\n",
        "    for mol, label, smile in zip(mols, kmeans.labels_, mols_smiles):\n",
        "        cluster_to_mols.setdefault(label, []).append(smile)\n",
        "        if ensure_correctness: # recalculate descriptors from a smile string and compare to the descriptors in the array\n",
        "            smile_features = pca.transform(scaler.transform(pd.DataFrame({k: [v] for k, v in rdkit.Chem.Descriptors.CalcMolDescriptors(rdkit.Chem.MolFromSmiles(smile)).items()})[scaler.get_feature_names_out()]))\n",
        "            assert np.allclose(smile_features[0], mol), \"Features calculated from a smile string differ from features in the array\"\n",
        "\n",
        "    # What happens below is sampling from each cluster. All the extra code is to ensure that the number of samples requested from each cluster\n",
        "    # doesn't exceed the total number of available molecules. This is done by calculating the average number of molecules per cluster and then\n",
        "    # calculating the number of extra molecules that need to be sampled from each cluster. The extra molecules are then distributed among the\n",
        "    # clusters uniformly. If the number of extra molecules is greater than the number of molecules in a cluster, all\n",
        "    # molecules from that cluster are sampled.\n",
        "    avg_len = np.mean([len(v) for v in cluster_to_mols.values()])\n",
        "    cluster_to_samples = {}\n",
        "    extra_mols = 0\n",
        "    left_to_sample = n_clusters*n_samples\n",
        "    cluster_to_len = {cluster:len(mols) for cluster, mols in cluster_to_mols.items()}\n",
        "    for i, (cluster, _) in enumerate(sorted(cluster_to_len.items(), key=lambda x: x[1], reverse=False)):\n",
        "        smiles = cluster_to_mols[cluster]\n",
        "    # for i, (cluster, smiles) in enumerate(cluster_to_mols.items()):\n",
        "        if extra_mols > 0:\n",
        "            cur_extra = int(1+extra_mols/(len(cluster_to_mols) - i) * len(smiles)/avg_len)\n",
        "            cur_samples = n_samples + cur_extra\n",
        "            extra_mols -= cur_extra\n",
        "        else:\n",
        "            cur_samples = n_samples\n",
        "        if cur_samples > left_to_sample:\n",
        "            cur_samples = left_to_sample\n",
        "\n",
        "        if len(smiles) > cur_samples:\n",
        "            cluster_to_samples[cluster] = random.sample(smiles, cur_samples)\n",
        "            left_to_sample -= cur_samples\n",
        "        else:\n",
        "            cluster_to_samples[cluster] = smiles\n",
        "            left_to_sample -= len(smiles)\n",
        "            extra_mols += cur_samples - len(smiles)\n",
        "\n",
        "    assert (n_sampled:=sum(len(vals) for vals in cluster_to_samples.values())) == n_clusters*n_samples, f\"Sampled {n_sampled} but were requested {n_clusters*n_samples}\"\n",
        "    pickle.dump(cluster_to_mols, open(clusters_save_path, 'wb'))\n",
        "    pickle.dump(cluster_to_samples, open(clusters_save_path.split('.')[0] + '_samples.pickle', 'wb'))\n",
        "    return cluster_to_samples\n",
        "\n",
        "\n",
        "cluster_and_sample(mols=pca_transformed, mols_smiles=gpt_smiles, n_clusters=100, n_samples=10,\n",
        "                   kmeans_save_path=inference_config_dict['checkpoint_dir'] + 'k100means_07_07.pickle', ensure_correctness=False,\n",
        "                   clusters_save_path=inference_config_dict['checkpoint_dir'] + 'cluster_to_samples_07_07.pickle')"
      ],
      "metadata": {
        "id": "l24k__P4KPhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzLWORD_OwCw"
      },
      "source": [
        "#Docking pose generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "cluster_to_samples = pickle.load(open(inference_config_dict['checkpoint_dir'] + 'cluster_to_samples_07_07_samples.pickle', 'rb'))\n",
        "print(cluster_to_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m68TViE-NqDN",
        "outputId": "d73bef59-c252-4113-9cf3-0f303605c6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{54: ['CCn1cc(C(=O)NCC2C(=O)N=C(C)C=C2C)cn1', 'CC1=CC(C)=NC(=O)C1CNS(=O)(=O)N(C)CCC#N', 'CC1=CC(C)=NC(=O)C1CNC(=O)NCCC(C)C'], 21: ['CSc1nnc(SCC(=O)Nc2cc(C)cc(C)c2)s1', 'CSc1nnc(SCC(=O)Nc2ccnn2C(C)C)s1', 'CSc1nnc(SCCCC(=O)Nc2ccc(C)cc2)s1', 'CCOc1ccc(CSc2nnc(SC)s2)cc1', 'CSc1nnc(SCC(=O)N(C)C(C)C)s1', 'CCSc1nnc(NC(=O)CSc2nncn2C)s1'], 92: ['O=S1(=O)N=C(N2CCCC2)c2cc(F)ccc21', 'O=S1(=O)N=C(NC2CCCC2)c2cc3c(cc21)OCCCO3', 'CCNC(=O)N1CCN=C1c1ccc(C(F)(F)F)cc1', 'CN1CCN(C2=NC3(CCCCC3)NC2=O)CC1=O', 'CCN1CCN(C2=NS(=O)(=O)c3ccccc32)CC1', 'O=C(NC1CCCCC1)C1CCN(C2=NC=NC3=NC=NC32)CC1', 'O=S1(=O)N=C(NCCC2COCCO2)c2ccccc21', 'O=S1(=O)NC(c2noc(-c3ccccn3)n2)=Nc2ccccc21', 'CCN(C(=O)CCNC1=NS(=O)(=O)c2ccccc21)C1CC1', 'Nc1ccc2c(c1)N=C(Nc1ccc(F)cc1F)CO2', 'CCOC(=O)C1CCN(C2=NCC3=NC=NC32)CC1'], 31: ['Cc1nnc(C2CCCN(C(=O)CC34CC5CC(CC(C5)C3)C4)C2)s1', 'O=C(NC1C2CC3CC(C2)CC1C3)c1c[nH]c2cccc(F)c12', 'O=C(c1ccc(S(=O)(=O)NC2CC2)cc1)C1CC2CCC1C2', 'CCN(C(C)=O)c1nc(C23CC4CC(CC(C4)C2)C3)cs1', 'CC(C)Oc1ncnc(NC23CC4CC(CC(C4)C2)C3)c1N', 'Cc1nnc(NC(=O)C23CC4CC(CC(Cl)(C4)C2)C3)s1', 'CC(C)(C)n1ncc(C(=O)NC23CC4CC(CC(C4)C2)C3)c1C1CC1', 'CC1(C)CCC2(C)C(CC3CCC2C(O)C(N2CCOCC2)C3)N1', 'O=C(CNC(=O)CC12CC3CC(CC(C3)C1)C2)NCc1ccco1', 'CN(C(=O)COC(=O)CC12CC3CC(CC(C3)C1)C2)c1ccccc1', 'CCCC1CN(C(=O)CC23CC4CC(CC(C4)C2)C3)CCO1'], 75: ['C#CCN1CCN(CC(=O)N(C)Cc2cccc(C)c2)CC1', 'C#CCN1CCN(CC=Cc2ccc(Cl)cc2)CC1=O', 'C#CCN1CCN(C(=O)c2ccc(COCC)o2)CC1', 'C#CCOCC1CCCN(C(=O)C2CCN(C(=O)C3CC3)CC2)C1', 'C#CCN1CCN(C(=O)NC(C)CN2CCOCC2)CC1', 'C#CCN1CCC(C(=O)NCc2cccc(Cl)c2)CC1', 'C#CCNC(=O)N1CCN(Cc2c(F)cccc2Cl)CC1', 'C#CCOc1cccc(CNC(=O)N2CCCC(O)C2)c1', 'C#CCN1CCN(C(=O)NCC(C)c2c(C)n[nH]c2C)CC1', 'C#CCN1CCN(CC(=O)N2CCOC(C)(C)C2)CC1', 'C#CCN1CCN(C(=O)NCCc2ncc(CC)s2)CC1'], 81: ['O=C(CNC(=O)c1ccccc1)Nc1cccc(N2CCOC2=O)c1', 'COc1ccc(Cn2c3c(c4cc(C)ccc42)COC3=O)c2cccnc12', 'O=C1OCC2(CCCN(c3ncccc3Cl)C2)O1', 'CN(C)c1cccc(C(=O)Nc2ccc(CN3CCOC3=O)cc2)c1', 'CCOC(=O)C(OC1CCOC1=O)C1CCCCC1', 'CCN(C(=O)c1cccc(N2CCOC2=O)c1)c1ccc(C)cc1', 'O=C1OCCN1CCN1CCN(Cc2ccc3ccccc3n2)CC1', 'COc1cccc(C(=O)N(C)C2CCOC2=O)c1F', 'Cc1ccc(C(C)(C)CNC(=O)c2ccc(N3CCOC3=O)cc2)o1', 'CC1CC(OC(=O)c2cc(S(=O)(=O)N(C)C)c[nH]2)C(=O)O1', 'O=C(CC1OC(=O)c2ccccc21)Nc1ccccn1'], 46: ['CCOC(=O)NC1CCCN(C(=O)COc2ccc(F)cc2)C1', 'CCOC(=O)NC1CCCN(C(=O)c2cc(-c3ccccc3)on2)C1', 'COC(=O)NCC(=O)N(C)C(C)Cc1ccc(Cl)cc1', 'COC(=O)NCCC(=O)N1CCCC1C(=O)Nc1nccs1', 'CC(=O)N1CCN(C(=O)C2(NC(=O)OC(C)(C)C)CCCCC2)CC1', 'COC(=O)NCC(=O)N1CCN(c2cc(C(C)C)nc(C)n2)CC1', 'Cc1cc2c(cc1Cl)CCNC2CNC(=O)OC(C)(C)C', 'CC(C)(C)OC(=O)NCCNC(=O)Cc1c(F)cccc1F', 'CC(C)(C)OC(=O)NC1C2CCC(C2)C1COc1ccccc1', 'CC(C)(C)OC(=O)NCCC(=O)Nc1ncnc2c1CCC2', 'CC(C)(C)OC(=O)NCCC(=O)N1CCC(O)(C(F)(F)F)C1'], 20: ['COc1ccc(OC)c(C(=O)COc2ncnc3sccc23)c1', 'COc1cc(C(=O)OCC(=O)c2cc(C)c(C)cc2OC)ccn1', 'COc1ccc(C(=O)CN2CCc3ccccc3C2)cc1OC', 'COc1ccc(C(C)=O)c(OC(=O)C(C)Oc2ccc(F)cc2)c1', 'CC(=O)c1cccc(OC(=O)C2COc3ccc(F)cc3C2)c1', 'COc1cccc(C(N)=O)c1OCC(=O)c1ccc(C(C)(C)C)cc1', 'O=C(COc1ccccc1)c1cccc(C2OCCO2)c1', 'CC(=O)c1ccc(OC(=O)c2ccccc2OCC(N)=O)cc1', 'COc1ccc(S(=O)(=O)N2CCC(=O)CC2)cc1OC', 'O=C(CC(F)(F)F)NCC(=O)c1ccc2c(c1)OCCO2', 'CCC(C)NC(=O)COc1ccc(C(C)=O)cc1OC'], 56: ['CC1(C)CC(=O)c2cnc3nc(CSc4ncccn4)nn3c2C1', 'COc1ccc(C(C)=O)cc1CSc1nc(C)cs1', 'CC(Sc1nncn1C)C(=O)c1cc(F)ccc1F', 'CC(=O)c1c(C)[nH]c(C(=O)Cn2cnc3ccsc3c2=O)c1C', 'C=CCNC(=O)CSc1nc(CC)nc(C)c1C(C)=O', 'CC(=O)c1ccc(NC(=O)CSc2nc(C)c3ccccn23)cc1', 'CC(=O)c1c(C)[nH]c(C(=O)C(C)Sc2nc(N)cc(=O)[nH]2)c1C', 'Cc1cc(C)nc(C(C#N)C(=O)CCSc2ccccn2)n1', 'CCOC(=O)c1c(C)[nH]c(C(=O)CSc2nnc(C)s2)c1C', 'CSc1nc2nc3c(cn2n1)C(=O)CC(c1ccccc1)C3', 'CC(=O)Nc1ccc(SCC(=O)c2cc(C)n(C3CC3)c2C)cc1'], 95: ['O=c1nc2sc(=Cc3ccco3)c(=O)n2c(=O)n1-c1ccccc1', 'CC(OCc1ccccc1)C(=O)Nc1nc(-c2ccco2)cs1', 'Cc1ccc(-c2nc(NC(=O)c3ccncc3Cl)sc2C)o1', 'Cc1c(C(=O)OCc2cc(=O)n3ccsc3n2)oc2ccccc12', 'Cc1ccc(-c2nc(CC(=O)Nc3cccc(C#N)c3)cs2)o1', 'O=C(NCc1ccco1)c1csc(-c2cc3ccccc3[nH]2)n1', 'Cc1cnc(NC(=O)C2CCN(C(=O)c3ccoc3C)CC2)s1', 'Cc1noc(C2CN(Cc3csc(-c4ccoc4)n3)C2)n1', 'Cc1csc(CCNC(=O)C2CC(=O)N(Cc3ccco3)C2)n1', 'Cc1cc(C(=O)Nc2nc(-c3c[nH]c4ccccc34)cs2)c(C)o1', 'CCn1cc(C(=O)OCc2csc(-c3ccc(C)o3)n2)cn1'], 8: ['C#CCn1c(-c2cccc(C)c2)nc2c1NC(=O)CC2', 'C#CCN(Cc1ccco1)C(=O)Nc1ccc(OC)c(C)c1', 'C#CCNC(=O)c1ccc(OC)c(N2CCCS2(=O)=O)c1', 'C#CCNC(=O)c1c(C(C)C)csc1NC(=O)OC', 'C#Cc1cccc(NC(=O)c2cc(S(=O)(=O)N(C)C(C)C)ccc2C)c1', 'C#CCOc1ccc(NC(=O)NC(CCO)c2cccs2)cc1', 'C#Cc1cccc(NCc2cc(C(=O)OC)ccc2OC)c1', 'C#CCCNS(=O)(=O)c1ccc(C(=O)NC2CC2)cc1', 'C#CCNC(=O)c1cnc2ccc(Cl)cn2c1=O', 'C#CCn1c(CNC(=O)C2CC2)nc2cc(OC)ccc21', 'C#CCN1CCC(C(=O)Nc2ccc(S(N)(=O)=O)c(C)c2)CC1'], 16: ['O=C(CNC(=O)c1ccc2[nH]cnc2c1)OCc1ccccc1', 'CCC(=O)c1ccc(O)c(-c2nc(N(C)C)ncc2-c2ncc[nH]2)c1', 'O=C(Nc1cccnc1)c1cc(F)cc2[nH]cnc12', 'Cc1nc2cc(C(=O)N3CC(c4cccnc4)C3)ccc2[nH]1', 'COCCn1c(C)c(C)n2c3c(=O)[nH]c(=O)n(C)c3nc12', 'COc1cccc(C(=O)Nc2ccc3[nH]c(=O)[nH]c3c2)c1', 'COc1ccc(CC(=O)Nc2ccc3[nH]c(=O)[nH]c3c2)cc1', 'Cc1cc(NC(=O)CN(C)c2ncnc3[nH]cnc23)no1', 'O=C(Nc1ccc2[nH]c(=O)[nH]c2c1)c1ccc(F)cc1', 'CNC(=O)c1cccc(CN(C)C(=O)c2ccc3[nH]cnc3c2)c1', 'CC(C)n1cc(C(=O)OCC(=O)c2ccc3[nH]c(=O)[nH]c3c2)cn1'], 94: ['N#CCc1ccc(NC(=O)CCNC(=O)c2cccs2)cc1', 'CCc1cc(C#N)c(NC(=O)c2ccc(S(C)(=O)=O)cc2)s1', 'Cc1ccccc1Cn1nc(C#N)cc1-c1cccs1', 'CCc1cc(C#N)c(NC(=O)c2ccc(C(=O)OC)cc2)s1', 'Cc1cc(C(C)NC(=O)Nc2cccc(C#N)c2)c(C)s1', 'Cc1ccc(S(=O)(=O)Oc2ccc(C#N)cc2)s1', 'Cc1cc(OCC(=O)C(C#N)c2nc(-c3cccs3)cs2)no1', 'Cc1nc2c3c(C)c(C#N)sc3nc(C)n2n1', 'N#Cc1ccc(CNC(=O)CCCc2cccs2)cc1', 'N#Cc1cnc(NC(=O)c2cc3ccccc3s2)s1', 'N#Cc1cccc(C(=O)Nc2sc3c(c2C#N)CCC3)c1'], 29: ['O=C(c1ccc(-c2cnco2)cc1)N1CCOCC1', 'O=C(c1ccc(-c2cnco2)cc1)N1CCCC1CC1CCCCC1', 'c1ccc(-c2nc(CN3CCn4c(nnc4C4CC4)C3)co2)cc1', 'Cc1ccc(-c2nc3cccnc3o2)cc1NC(=O)C1CC1', 'Cc1nc2cc(-c3csc(N4CCNC(=O)C4)n3)ccc2o1', 'COc1ccc(-c2nc(CN3CCc4cncnc4C3)co2)cc1OC', 'COc1cc2c(c(OC)c1)CN(C(=O)c1nc(C(C)C)oc1C)CC2', 'CN(Cc1ccccn1)C(=O)Nc1ccc2nc(C3CC3)oc2c1', 'COc1ccccc1OCc1nc(C(=O)N(C)CC(=O)N(C)C)co1', 'CCn1cc(-c2nc(Cn3cnc(C4CC4)n3)c(C)o2)c(C)n1'], 14: ['O=C(CSc1nnnn1-c1cccc(F)c1)c1ccc[nH]1', 'COCCNC(=O)CSc1nnnn1-c1c(C)cccc1C', 'Cc1ccccc1NC(=O)CSc1nnnn1-c1ccccc1', 'CCCCn1c(C)nnc1SCc1nnnn1-c1ccccc1', 'C=CCn1nnnc1SCCC(=O)Nc1ccccc1Cl', 'CCOC(C)c1noc(CSc2nnnn2C(C)(C)C)n1', 'CCCSc1nnnn1-c1ccc(NC(C)=O)cc1', 'COc1ccc(CSc2ccc3nnnn3n2)cc1OC', 'Cc1cccnc1NC(=O)CSc1nnnn1C1CCCCC1', 'CSc1ccccc1NC(=O)Cn1nnn(-c2ccc(C)cc2)c1=O'], 0: ['CCOC(=O)c1sc(NC(=O)Cc2csc(C)n2)nc1C1CC1', 'COC(=O)CNC(=O)c1csc(COc2ccc(Cl)cc2)n1', 'Cc1nc(C)c(-c2nccn2CCCC(=O)OC(C)(C)C)s1', 'COCC(=O)N=c1sc2cc(OC)ccc2n1CC(=O)OC', 'CCOC(=O)C=C(NC)Nc1nc2ccccc2s1', 'COC(=O)C1=C(C)N(Cc2csc(C)n2)c2ccccc2C1', 'CCOC(=O)Cc1csc(NC(=O)c2ccc(C)cc2)n1', 'COC(=O)Cn1c(-c2csc(NC(C)=O)n2)nc2ccccc21', 'O=C(OCCNc1nc2ccccc2s1)c1ccc(F)nc1', 'CCC=CCOC(=O)c1csc(-c2cnn(C)c2)n1'], 53: ['CN(C)C(=O)N1CCN(C(=O)c2cccnc2N)CC1', 'O=C(NC1CCCC1)N1CCN(C(=O)c2ccno2)CC1', 'CNC(=O)NCC(=O)N1CCN(C(=O)c2c(C)oc(C)c2C)CC1', 'CC(C)n1nccc1NC(=O)N1CCN(c2cnccn2)CC1', 'O=C(Nc1ccccc1)N1CCN(CC=Cc2ccccc2)CC1', 'COCCCNC(=O)N1CCN(c2ccc(C#N)cn2)CC1', 'CCc1cccc(CC)c1NC(=O)N1CCN(C(=O)C2CC2)CC1', 'CC(C)CNC(=O)CN1CCN(C(=O)Nc2c[nH]ccc2=O)CC1', 'CC(C)C(C)NC(=O)N1CCN(c2ncccn2)CC1', 'CC1CCC(NC(=O)NCCN2CCN(C(=O)c3ccoc3)CC2)CC1'], 83: ['Cc1csc(CCCNC(=O)NC2CCc3ccccc32)n1', 'CCC(CCO)NC(=O)Nc1nc(C2CC2)cs1', 'CCc1nc(CCNC(=O)NC(C)c2cccs2)cs1', 'CCNC(=O)NC(C)c1nc(C)c(C(C)C)s1', 'Cc1cnc(NC(=O)NCC(O)C(F)(F)F)s1', 'O=C(Nc1ccc2c(c1)COC2)Nc1nc(-c2ccccc2)cs1', 'O=C(Nc1nccs1)N1CCN(c2nccs2)CC1', 'O=C(NCc1cscn1)N1CCCc2cc(F)ccc21', 'Cc1nc(CNC(=O)Nc2ccc(-c3nncn3C)cc2)c(C)s1', 'O=C(Nc1nc(-c2ccccc2)cs1)N1CCC(O)CC1'], 28: ['Cn1c(N)nnc1SCc1ccc(Cl)cc1Cl', 'COCCn1c(SCc2ccccc2C)nc2cccnc21', 'C=C(C)CSc1nnc(-c2ccc(Cl)cc2)n1N', 'c1coc(-c2nnc(SCc3nc(C4CC4)no3)n2C2CC2)c1', 'CC(C)Cn1c(SCc2nnc(C3CC3)o2)nnc1-c1ccco1', 'Cc1cc(CSc2nnc3[nH]c4ccccc4n23)no1', 'COCCCn1cnnc1SCc1csc(C)n1', 'Cc1csc2c(CSc3n[nH]c(N)n3)cccc12', 'Cc1noc(C)c1CSc1nnc(-c2cccnc2)n1C1CC1', 'CC1=Nn2c(nnc2-c2ccccc2Cl)SC1'], 44: ['Cc1cc(C)c(C(=O)CN(C)S(=O)(=O)c2ccc(C#N)cc2)cc1C', 'Cc1nnc(-c2ccc(S(=O)(=O)N(C)CC(C)C#N)cc2)o1', 'CS(=O)(=O)NCC(=O)Oc1ccc(C#N)cc1Cl', 'COC(=O)C(C)(C)NS(=O)(=O)c1ccc(C#N)cc1', 'Cc1nc(CNS(=O)(=O)CCc2ccc(C#N)cc2)cs1', 'CC(CC#N)N1CCN(S(=O)(=O)Cc2ccccc2)CC1', 'CC(C#N)CNC(=O)CCNS(=O)(=O)c1ccccc1', 'Cc1ccc(C)c(NS(=O)(=O)c2ccc(F)cc2C#N)c1', 'N#Cc1ccc(S(=O)(=O)NCCc2c(F)cccc2F)cc1', 'COc1c(C)cnc(CNS(=O)(=O)c2ccccc2C#N)c1C'], 98: ['Cc1cc(S(=O)(=O)NC(C)c2ccncc2)c(C)s1', 'CCCC(C)NC(=O)c1sccc1S(=O)(=O)NC1CC1', 'COCCN(c1nc(C)ns1)S(=O)(=O)c1sccc1C', 'CN(c1ccc(-c2ccco2)nn1)S(=O)(=O)c1cccs1', 'NC(=O)c1cc(S(=O)(=O)N2CCCC2)cs1', 'O=S(=O)(c1cccs1)N1CCn2c1nc1ccccc12', 'CCOCC1CCCN(S(=O)(=O)c2cc(C)sc2C)C1', 'O=C(NCCNS(=O)(=O)c1cccnc1)NCc1cccs1', 'O=C(NCCNS(=O)(=O)c1cccs1)Nc1ccccc1F', 'O=S(=O)(NCc1ccc(C(F)(F)F)cc1)c1cccs1'], 59: ['O=C(OC1CCN(c2ncccn2)CC1)C1(c2ccccc2F)CC1', 'COC(=O)C1CCN(C(=O)c2ccc(Br)c(F)c2)CC1', 'COC(=O)C1CCCN1C(=O)c1nn(C)c(=O)c2ccccc12', 'CC(=O)OCC1C(=O)N(Cc2ccccc2)CCC1c1ccccc1', 'CC1CCN(C(=O)C(C)OC(=O)c2ccc(Br)cc2)CC1', 'COC(=O)C1CCN(C(=O)c2cccc(O)c2)CC1', 'O=C(OCC(=O)N1CCCC1)c1cnn(-c2ccc(F)cc2)n1', 'COC(=O)c1c(NC(=O)C2CCCN(C(=O)C(C)(C)C)C2)c[nH]c1C', 'CCOC(=O)N1CCCC(C(=O)Oc2ccc(C)cc2C)C1', 'Cc1noc2ncc(C(=O)OCC(=O)N3CCCC(C)C3)cc12'], 55: ['CC(O)CN1CCN(CC(O)c2ccccc2Br)CC1', 'COc1ccc(OCC(O)CN2CCN(c3nccs3)CC2)cc1', 'O=C(c1cnc(C2CCCC2)s1)N1CCN(CCO)CC1', 'CC(=O)Nc1nc2c(s1)CN(CC(O)COc1ccccc1C)CC2', 'CCOc1cccc2sc(NC(=O)N3CCCC(O)C3)nc12', 'O=C(Cc1ccc2ccccc2c1)N1CCCC(O)(CO)C1', 'Cc1cc(CCC(=O)N2CCN(CC(C)(C)O)CC2)c(C)s1', 'Cc1nn(C)c(C)c1CCNc1nccc(N2CCCC(O)C2)n1', 'Cc1nc(C)n(CC(C)C(=O)N2CC(C)(C)C(C)(O)C2)n1', 'CC(C)(O)CCc1cccc(C(=O)N2CC(O)C(OC(C)(C)C)C2)c1'], 77: ['COC(=O)c1ccccc1NCC(=O)N(C)Cc1ccc(C)s1', 'CCOC(=O)c1sc2nc(COc3ccccc3)[nH]c(=O)c2c1C', 'CCCN(CC(=O)OCC)C(=O)c1cccs1', 'CCOC(=O)c1c(NC(=O)CSc2nncn2C)sc(C)c1C', 'Cc1cc(C(=O)COC(=O)c2cc3ccccc3s2)c(C)[nH]1', 'CCCCc1nc2sc(C(=O)OC)c(C)c2c(=O)[nH]1', 'Cc1ccsc1COC(=O)CSc1ccc(O)cc1', 'COC(=O)c1sccc1NC(=O)CCc1ccccn1', 'CCOC(=O)c1c(NC(=O)C(C)NC(N)=O)sc(C)c1CC', 'O=C(COC(=O)c1ccc(-n2cccc2)cc1)NCc1cccs1'], 58: ['CCN(Cc1nc2ccccc2c(=O)[nH]1)C(=O)c1scnc1C1CC1', 'CSc1nc2ncn(CCCOc3ccccc3)c(=O)c2s1', 'CN(Cc1cnc(-c2ccccc2)s1)C(=O)C1Cc2ccccc2O1', 'CCc1nc(CC(=O)NCCc2nc3ccccc3[nH]2)cs1', 'O=C(c1n[nH]c2ccccc12)N1CCN(c2nccs2)CC1', 'O=C(CN1C(=O)CCOc2ccccc21)Nc1nc2c(s1)CCC2', 'Cc1ccc(OCC(=O)NCc2nc3ccccc3s2)cc1', 'O=C(Cn1c2c(sc1=O)CCCC2)NCC(=O)Nc1ccccc1', 'CCc1nc(CN2C(=O)C(C)Oc3ccccc32)cs1', 'O=c1cc(CSc2nccn2-c2ccccc2)nc2sccn12'], 43: ['COC(=O)c1ccc(Cn2nc(C(F)(F)F)c(Cl)c2C2CC2)o1', 'Cc1ccc2c(CC(=O)Oc3cccc(C(N)=O)c3)coc2c1', 'Cc1cccc(OC(=O)C2CC(=O)N(Cc3ccco3)C2)c1', 'Cc1cc(C(C)OC(=O)c2ccc(C(N)=O)cc2)c(C)o1', 'COC(=O)C(NC(=O)c1cccc(-c2ccoc2)c1)C(C)(C)C', 'CCCn1c(C)cc(C(=O)COC(=O)c2ccoc2C)c1C', 'Cc1cccc(C(C(=O)OCc2ccoc2C)N(C)C)c1', 'O=C(OCc1ccc(F)cc1)C1CCN(C(=O)c2ccoc2)CC1', 'Cc1c(F)cccc1NC(=O)COC(=O)c1cc2ccccc2o1', 'Cn1c(C(=O)OCC(=O)NCc2ccco2)cc2ccccc21'], 82: ['COCC(NC(=O)NCC1CN2CCCC2CO1)c1ccnn1C', 'CC(CO)NC(=O)N1CC(C)OC(c2ccccc2)C1', 'CC(C)NC(=O)Nc1cccnc1N1CCOCC1', 'CC1COCCN1C(=O)Nc1cccc(F)c1F', 'CCCN(Cc1ccccc1)C(=O)NCCC(=O)N1CCOCC1', 'CCNC(=O)N1CCOC(c2ccc(F)c(C)c2)C1', 'COc1ccccc1OCCNC(=O)N1CCOCC1C1CC1', 'CCc1ccccc1CNC(=O)NCCN1CCOCC1', 'CC1CN(C(=O)C(Cc2c[nH]c3ccccc23)NC(N)=O)CC(C)O1', 'CNC(=O)N1CCN(c2cc(C)nc(N3CCOCC3)n2)CC1'], 3: ['COCCNC(=O)N(Cc1ccccc1Cl)C1CC1', 'COCCCNC(=O)NC(C)c1cc(Cl)cc(Cl)c1', 'CCCNC(=O)NC(C)c1ccc(Cl)c(Cl)c1', 'COCCCNC(=O)NC(C)c1ccc(Cl)c(Cl)c1', 'COc1ccc(Cl)cc1CNC(=O)C1CCN(C(N)=O)CC1', 'CC(CCCO)NC(=O)Nc1ccc(Cl)cc1C(=O)NC(C)(C)C', 'NC(=O)c1ccc(NC(=O)Nc2ccccc2Cl)c(F)c1', 'CNC(=O)NCC(=O)NC(C)c1cc(F)cc(Br)c1', 'COc1ccc(NC(=O)N2CCC(O)CC2)cc1Cl', 'COCc1ccc(CNC(=O)Nc2ccc(F)cc2Cl)cc1'], 73: ['COC(=O)C(C)n1c(-c2ccc(OC)cc2)ccc(C#N)c1=O', 'COc1cc(C#N)ccc1OC(C)C(=O)NC(C)c1ccccc1', 'COc1cc(C#N)ccc1OCc1nsc(N(C)C)n1', 'COc1cc(C#N)ccc1OC1CCC(C)CC1', 'COc1ccc(C)cc1CCNC(=O)COc1cccc(C#N)c1', 'COc1cc(OC)cc(C(=O)OC(C)C(=O)Nc2ccccc2C#N)c1', 'COCCN(CC(=O)OC)C(=O)Nc1ccc(C#N)cc1', 'COc1cc(OC)cc(N2CC(C#N)CC2=O)c1', 'CCc1nc(Cc2ccc(OC)c(OC)c2)sc1C#N', 'COc1ccc(OC)c(-c2cc(CC#N)c(=O)n(C)n2)c1'], 33: ['COc1cccc(C(=O)Nc2ccc(OC)cc2OC)c1', 'COc1cc(OC)c(CCC(=O)Nc2ccc(C)c(N)c2)c(OC)c1', 'COc1cccc(COc2cc(C)c(N)cn2)c1OC', 'CCCCOC(=O)Nc1cc(OC)c(OC)cc1Cl', 'COC(=O)c1cc(-c2cc(Cl)c(OC)cc2OC)n[nH]1', 'COC(=O)c1cc(-c2cc(OC)c(OC)c(OC)c2)nc(N)n1', 'COc1cc(N)c(C(=O)N2CCCCC2C)cc1OC', 'COc1cc(CNc2ccccc2OC)cc(OC)c1', 'COc1cc(NC(=O)c2ccc3[nH]cnc3c2)cc(OC)c1OC', 'COc1cccc(OCc2ccc(CO)o2)c1OC'], 7: ['CCCCc1nnc(NC(=O)c2scnc2C2CC2)s1', 'Brc1ccc2c(c1)C(c1cncs1)NCC2', 'CCOCCCNC(=O)c1cnc(C2CCCO2)s1', 'CC(C#N)CN(C)C(=O)c1scnc1C1CC1', 'CC(C)CNC(=O)c1nc2ccc(Cl)cc2s1', 'Cn1cc(-c2ncc(C(=O)NCCCC(N)=O)s2)cn1', 'CC1COCCN1C(=O)c1cn2ccsc2n1', 'Cc1ncc(CNC2CCCCCC2O)s1', 'CCC(NC(=O)c1ccc(OC(C)C)nc1)c1nc(C)cs1', 'CNc1nc(-c2sc(C)nc2C(C)C)cs1'], 61: ['CC(=O)N1CCCN(C(=O)c2ccc(OCC3CC3)cc2)CC1', 'CN1CC(C(=O)NC2CCCCC2Cc2ccccc2)CC1=O', 'CC1CC1C(=O)N1CC(c2nc(C3CC3)no2)C2(CCOCC2)C1', 'O=C(NCCNc1cnccn1)N(CC1CCCCC1)C1CC1', 'CCOC1CC(NC(=O)Nc2cc(Cl)ccc2F)C12CCC2', 'CC(=O)NC(C(=O)Nc1ccccc1N1CCCC1)C1CCCC1', 'CCCn1nc(C(=O)NCCC2CC3CCC2C3)ccc1=O', 'CCC(OC1CCCC1)C(=O)NC1CCCNC1=O', 'CCc1onc(C)c1NC(=O)NC1CC1(C)C1CC1', 'O=C(Nc1cccc(C(=O)N2CCCCC2)c1)NC(C1CC1)C1CC1'], 85: ['Cn1nc(C(=O)N2CCC(C(=O)N3CCCCC3)CC2)ccc1=O', 'CC(C)(C)CC(=O)N1CCC(C(=O)N2CCc3ccccc32)CC1', 'Cc1nc(C2CCCN(C(=O)C3CCOC3)C2)no1', 'O=C1CCCN1CC1CCCN(C(=O)COc2cccnc2)C1', 'O=S(=O)(N1CCCCC1)N(CCc1ccncc1)CC1CCCO1', 'CCC1CCCCN1C(=O)CN1CCN(c2cccc(OC)c2)C1=O', 'CC(=O)N1CCC(C(=O)Nc2cccc(N3CCCCCC3)c2)CC1', 'Cc1cc(N2CCCC(N3CCN(C)C3=O)C2)ncn1', 'CC1CCN(c2ncc3c(n2)CN(C2CCN(C)C2=O)C3=O)CC1', 'CS(=O)(=O)N1CCC2(CCCN(C3CCCCC3)C2=O)C1'], 23: ['OCC#Cc1cccc(OCC(F)(F)C(F)F)c1', 'CCNC(=O)CNC(=O)Nc1ccc(F)c(OCC(F)(F)F)c1', 'NS(=O)(=O)c1ccc(F)c(C(F)(F)F)c1F', 'CCCCN(CC(F)(F)F)c1nc(C)cc(NC)n1', 'NC(=O)c1ccc(OCCC(=O)NCC(F)(F)F)cc1', 'N#CCc1cc(C(N)C(F)(F)F)cc(C(F)(F)F)c1', 'O=c1cc(C(F)(F)F)c2cc(C(F)(F)F)c(O)cc2o1', 'CC(C)CC(=O)Nc1cccc(NS(N)(=O)=O)c1C(F)(F)F', 'CC(O)c1cc(Br)cc(C(F)(F)F)c1', 'CC(NCC(F)(F)F)(C(N)=O)c1ccc(F)cc1'], 25: ['CC(=O)Oc1ccc(C(=O)Nc2ccc(F)cc2F)cc1', 'COC(=O)c1ccc(C(=O)NCC(=O)N(C)Cc2ccccc2)cc1', 'COC(=O)c1cc(CNC(=O)c2cccc(Cl)c2)ccc1OC', 'COC(=O)c1ccc(NC(=O)C(C)Oc2ccc(F)cc2)cc1', 'NC(=O)c1cccc(OC(=O)c2ccc(F)c(F)c2)c1', 'COC(=O)c1ccc(C(=O)OC)c(NC(=O)c2ccccc2OC)c1', 'CCOC(=O)c1ccc(NC(=O)c2ccc(F)cc2F)cc1', 'COC(=O)c1[nH]c2ccccc2c1NC(=O)c1ccccc1Cl', 'CCOc1cccc(COC(=O)c2ccc(C(N)=O)cc2)c1', 'COC(=O)c1cccc(CC(=O)NCCc2ccccc2F)c1'], 40: ['CCN(CC)C(=O)CCC(=O)N1CCSc2ccc(Cl)cc21', 'CCn1c2c(c(=O)n3nc(SC)cc13)CN(C(=O)CCO)CC2', 'CCN1C(=O)C(CC(=O)NCC(C)C)Sc2ncccc21', 'O=C(CCN1C(=O)CSc2ccccc21)NC1CCCCC1', 'C=CCn1c(SCC(=O)N2CCCC2)nnc1-c1ccccc1', 'Cc1cc(C)cc(OCCSc2nnc(CO)n2C2CC2)c1', 'CC(C)c1noc(CSc2ncccc2C(=O)NC2CC2)n1', 'CCCSc1ncc(Cl)c(C(=O)NC2CC2)n1', 'CSc1nc(C2CC(=O)N(C(C)(C)C)C2)cc(=O)[nH]1', 'CSc1ccc(NC(=O)C2CCOC2)cc1F'], 37: ['Cc1nc2ccccc2n1Cc1ccc(C#N)cc1', 'Cc1ccc2c(c1)nc(C#N)n2Cc1ccccc1C#N', 'CC(NC(C)c1cc2ccccc2n1C)c1ncccc1C#N', 'N#CCSc1nnc(C2CC2)n1Cc1ccccc1', 'CSc1ncnc(N2CCN(c3ncccn3)CC2)c1C#N', 'Cc1cccc2cc(C#N)c(N3CCC(C)CC3)nc12', 'CCCCc1ccc(-n2nnc(C#N)c2C(C)C)cc1', 'N#CC(C#N)C(C#N)c1nc2cc(Cl)ccc2s1', 'Cc1cccc(-c2nc(-c3ccc(C#N)cn3)no2)c1', 'CC(C#N)Sc1nnc(-c2ccncc2)n1Cc1ccco1'], 96: ['CC(NC(=O)C1CCCO1)c1ccc(OC(F)F)c(Cl)c1', 'O=C(Oc1cccc(C(F)(F)F)c1)C1CCCN1C(=O)C1CC1', 'O=C(Nc1cn[nH]c1)C1CCN(CC(F)(F)F)CC1', 'O=C(NCc1ccc(OCC(F)(F)F)cc1)C1CCOC1', 'CN(CC1CCC1)C(=O)COc1ccccc1OC(F)(F)F', 'CCOc1ccc(C(=O)N(CC(F)(F)F)C2CCCOC2)cn1', 'CCCCN1C(=O)C(=O)c2cc(C(F)(F)F)ccc21', 'O=C(Cn1cccc(C(F)(F)F)c1=O)NC1CCCCCC1', 'COc1ccc(NC(=O)OCC(F)(F)F)cc1OC1CCCC1', 'O=C(C=C(c1cccs1)C(F)(F)F)NCC(=O)N1CCCC1'], 70: ['COc1ccc(-c2csc(Cc3csc(C)n3)n2)cc1N', 'Cn1ncc2c1CCc1sc(NC(=O)c3cnccn3)nc1-2', 'CCCn1c(=O)c(C)nc2cc(-c3noc(-c4cscn4)n3)ccc21', 'O=C(NCC1CC1)c1cccc(NC(=O)c2ccn3ccsc23)c1', 'Cc1ccc(-c2nc(C(=O)Nc3nc[nH]n3)cs2)c(C)c1', 'CCn1ccc(C(=O)Nc2nc(-c3cccnc3)cs2)n1', 'COc1cccc(NC(=O)c2cc(-c3csc(C)n3)c[nH]2)c1', 'Cc1cccc(-c2noc(Cc3cn4ccsc4n3)n2)c1', 'O=C(NCc1ccccc1)c1cnc2sccn2c1=O', 'COc1cccc(OCc2c(C#N)nnn2-c2nccs2)c1'], 51: ['c1ccc(CCn2ccnc2-c2cc(-c3cccnc3)on2)cc1', 'Nc1c(NCc2ccccn2)ncnc1-n1cnc2ccccc21', 'COCc1cc(-c2nc(-c3ccc(Cl)cc3)no2)no1', 'COCc1nnc2sc(-c3ccc4c(c3)OCO4)nn12', 'COc1ccc(OC)c(-c2nn3c(-c4ccncc4)nnc3s2)c1', 'COCCn1cnnc1C(C)n1ccnc1-c1cc(C(C)(C)C)n[nH]1', 'C1=C(CCNc2ncnc3c2cnn3Cc2ccccc2)COCC1', 'c1cnc(-c2nn3c(-c4ccsc4)nnc3s2)cn1', 'COCCNc1ccc2nnc(-c3ccccn3)n2n1', 'Cn1ncc(Br)c1-c1nn2c(-c3ccccc3)nnc2s1'], 87: ['Cc1nccc(CNC(=O)c2ccc(-c3ccncc3)[nH]c2=O)n1', 'Cc1cc(C(=O)Nc2cnn(C(C)C)c2)c2c(=O)[nH]n(C)c2n1', 'Cc1n[nH]c(C)c1CCOC(=O)c1c[nH]nc1-c1ccccc1', 'Cc1cccnc1Nc1nc2c(c(=O)[nH]1)CCC2', 'COc1ccc(-n2ccc(C(=O)N3CCc4[nH]ncc4C3)n2)cc1', 'Cc1[nH]c2ccnn2c(=O)c1CC(=O)Nc1cn[nH]c1', 'CCc1nnc2n1CCN(Cc1cc(=O)[nH]c(=O)[nH]1)C2', 'Cc1cc(NC(=O)c2c[nH]nc2-c2ccccc2F)n(C)n1', 'CC(C)N(Cc1nc2c(cnn2C)c(=O)[nH]1)c1cccc(C#N)c1', 'Cc1[nH]nc(CCC(=O)NCCc2c[nH]c3ccc(F)cc23)c1C'], 47: ['O=C(CCn1cncn1)NCCNC(=O)C1CC1', 'CCC(C)n1ncc(C(=O)NCC(=O)NC(C)C)c1C1CC1', 'CCCN1CCn2c(nc3cc(NC(=O)C(C)C)ccc32)C1', 'CCCCCn1c(N2CCCC2)nc2c1c(=O)n(C)c(=O)n2C', 'O=C(NC1(c2nc(CO)no2)CCCCC1)c1cnccn1', 'CCCCc1noc(C2CCCN(C(=O)C3CCC3)C2)n1', 'Cc1nn2cc(C(=O)NCC(=O)NCC3CCCC3)nc2s1', 'COc1ccc(C(=O)NC2C3CCOC3C2(C)C)nn1', 'CCOC(=O)c1nn(CC2CC2)c2c1CN(C(=O)CC)CC2', 'Cc1noc(C)c1CC(=O)N1CCCN(c2cccnn2)CC1'], 52: ['Cn1cnnc1C1CCN(C(=O)c2csc(-c3ccccc3)n2)CC1', 'CC(=O)Nc1nc2c(s1)CN(C(=O)C1CC1)CC2', 'Cc1csc(C2CCN(C(=O)c3sc(C(C)C)nc3C)CC2)n1', 'CC1(C)C(NC(=O)Cc2cn3ccsc3n2)C2CCOC21', 'O=C(C1CCCN1c1nccs1)N1CCc2sccc2C1', 'CCOCC1CCCN(C(=O)Cc2cn3ccsc3n2)C1', 'Cc1nc(CNc2ccccc2C(=O)N2CCCC2)cs1', 'COC(=O)C1CCN(C(=O)c2cnc(C3CCCO3)s2)CC1', 'Cc1csc(N(C(=O)c2ccc3c(c2)CCO3)C2CC2)n1', 'Cc1csc(N2CCN(C(C)C(=O)Nc3ccccc3)CC2C)n1'], 71: ['COCC(NC(=O)c1ccc(Cl)c(Cl)c1)C(N)=O', 'O=C(COc1ccc(Cl)c(Cl)c1)NCCCn1ccnc1', 'N#CC(NC(=O)COc1ccc(Cl)c(Cl)c1)C1CCCO1', 'CC(=O)NCCC(=O)N(C)C(C)c1ccc(Cl)cc1Cl', 'COc1c(Cl)cc(Cl)cc1C(=O)CC#N', 'O=C(CSc1ncccn1)Nc1ncc(Cl)cc1Cl', 'Cc1noc(C)c1CNc1cc(Cl)cc(Cl)c1', 'COc1cccc(C(=O)NCCNc2ncc(Cl)cc2Cl)c1', 'Cc1cc(O)cc(C)c1-c1cn2cc(Cl)c(Cl)c(N)c2n1', 'Nc1ccc(=O)n(Cc2cccc(Cl)c2Cl)c1'], 99: ['O=C(CC(c1ccccc1)c1ccccc1)Nc1nnc2n1CCCS2', 'COc1cccc(SC2CCN(c3ccccc3)C2=O)c1', 'CCCSc1ccccc1C(=O)Nc1cccc(O)c1', 'O=C(CSc1ccncc1)OCC(=O)N1CCCc2ccccc21', 'Cc1ccc2cccc(NC(=O)CSc3ccccc3)c2n1', 'O=C1CSc2ccc(NC(=O)c3cccc4ccccc34)cc2N1', 'N#Cc1ccc(SCC(=O)N(Cc2ccncc2)C2CC2)c(F)c1', 'CSc1ccc(NC(=O)c2ccc(C)c(NC(C)=O)c2)cc1', 'O=C(CSc1ccccn1)Nc1ccc2c(c1)OCCO2', 'Cc1nnc(SCC(=O)Nc2ccccn2)n1-c1ccccc1'], 19: ['CC(C)CCNC(=O)C(N)c1cccc(Br)c1', 'CCOC(CC)C(=O)N1CCCN(C(=O)OC(C)(C)C)CC1', 'CC(C)(C)NC(=O)CNc1cccc(Br)c1', 'CCCCN(CCCC)C(=O)c1coc(=O)c(Br)c1', 'CCC(OC)C(=O)NCc1ccc(C)c(F)c1', 'CCC(C)(C)NC(=O)CNc1ccc(NC(=O)C(C)C)cc1C', 'CCC(C)NC(=O)C(C)Nc1ccc(NC(=O)C(C)C)cc1', 'CCC(=O)NCC1(c2ccccc2)CCOCC1', 'CCCC(=O)Nc1ccc2c(c1)OCC(C)(C)C(=O)N2CCC', 'COCCN1C(=O)CCc2cc(C(=O)NCCO)ccc21'], 80: ['O=C(NCCOc1cccc(F)c1)c1csc(Nc2ncccn2)n1', 'CCOc1ccc(-c2nc(CC)c(CO)s2)cc1OC', 'Cc1cnc(NC(=O)c2cccc3c2OCCO3)s1', 'CCN(C(=O)c1cnc2sccn2c1=O)c1cccc(F)c1', 'CN1CCc2nc(NC(=O)CNC(=O)c3ccccc3)sc2C1', 'Fc1cccc2sc(NCC3COCCO3)nc12', 'O=C(Nc1nccs1)c1cc(Cl)ccc1O', 'COc1ccc(OCC(=O)NCc2nc3ccccc3s2)cc1', 'COc1cccc(C(=O)Nc2nc3c(s2)CN(C)CC3)c1F', 'NC(=O)CCCNC(=O)c1cnc(-c2ccccc2F)s1'], 12: ['CC(C)c1cc(C(=O)NCCc2nc3ccccc3[nH]2)nn1C(C)(C)C', 'O=C(COc1cc(Cl)ccc1Cl)NCc1nc2ccccc2[nH]1', 'O=C(Nc1ccncc1)c1ccc(-c2nc3ccccc3[nH]2)cc1', 'CC(NC(=O)CCCc1nc2ccccc2[nH]1)c1ccncc1', 'Cc1ccc(C2(C)NC(N)=Nc3nc4ccccc4n32)cc1', 'COc1ccc2nc(SCC(=O)N3CCc4ccccc43)[nH]c2c1', 'O=C(Cn1c(=O)[nH]c2ccccc21)N1CCCCCC1', 'O=C(c1ccsc1)N1CCn2c1nc1ccccc12', 'Cc1cccc2c(=O)cc(Cn3nnc4ccccc43)oc12', 'CCn1c(=O)n(Cc2ccc(C#N)cc2)c2ccccc21'], 66: ['CCOc1nnc(CN2CCN(Cc3ccncc3)CC2)s1', 'CCc1ccc2nc(NCc3ccncc3)sc2c1', 'Cc1cc2nc(N3CCCC3)n(Cc3ccco3)c2cc1C', 'Cc1cnc(C)c(N2CCN(c3ncccn3)CC2)n1', 'Cc1cc(Sc2nnc3ccccn23)nc(C)n1', 'Brc1ccc(-c2n[nH]c3c2CNCC3)cc1', 'Cc1noc2ncnc(N3CCC(Cc4ccccc4)CC3)c12', 'CCc1cc(NCCc2nc(C)cs2)n2nc(C)c(C)c2n1', 'C=CCOc1ccccc1CNc1cnn(C(C)(C)C)c1', 'CC(C)Oc1ncc(-c2nnc3n2CCCCC3)cc1Cl'], 30: ['CCCn1nc(-c2ccc(OC)cc2F)cc(C#N)c1=O', 'CCCn1nc(-c2ccc(F)cc2)cc(CC#N)c1=O', 'CN(CCC#N)S(=O)(=O)NC1CCc2c(Cl)cccc21', 'CC(C)N(CC(N)=O)C(=O)Cn1cc(C#N)c2ccccc21', 'COC1CCN(c2ccc(C#N)cc2Cl)CC1', 'CCN(C(=O)c1cc(C#N)c[nH]1)C(C)c1cccc(OC(F)F)c1', 'C=CCNC(=O)Nc1cc2c(cc1SCC#N)OCO2', 'CCN(CC(C)C#N)C(=O)CNc1ccc(F)c(NC(C)=O)c1', 'COCCNC(C#N)c1cccc(Br)c1', 'CC(C)(CCC(=O)Nc1ccc(F)cc1SCC#N)C(N)=O'], 67: ['Cc1csc(NC(=O)c2ccc(C(=O)N(C)C)cc2)n1', 'Cc1cc(C)c2nc(NC(=O)Cn3ccnc3)sc2c1', 'Cc1nc(-n2nnc(CO)c2Cc2ccccc2)sc1C', 'Cc1csc(N(C(=O)CCc2cccnc2)C2CC2)n1', 'CCc1ccc(C(=O)Nc2c(C)nc3sccn3c2=O)cc1', 'Cc1csc(=O)n1C(C)C(=O)Nc1ccc(F)cc1', 'COc1ccc(CCC(=O)N(C)Cc2csc(C)n2)cc1', 'Cc1cc(NC(=O)c2cnc3sc(C)c(C)n3c2=O)c2ncccc2c1', 'Cc1nc(C(C)NC(=O)Cn2nc(C)c3ccccc3c2=O)cs1', 'O=C(Nc1cnc2sc3c(n2c1=O)CCCC3)c1ccccc1F'], 9: ['CCOC(=O)N(C)CC(=O)Nc1ccnn1Cc1ccc(F)c(C)c1', 'COCCNC(=O)CN(C)C(=O)C1(c2cccc(C)c2)CCC1', 'CCN(C(=O)CNc1ccc(OC)nc1)C1CCCCC1', 'CC(Nc1ncnc2cccc(F)c12)C(=O)N(C)C', 'COc1ccc(OCC(=O)N(C)Cc2cc(C)on2)cc1', 'Cc1ccc(NC(=O)c2cnn(C)c2)c(OCC(=O)N(C)C)c1', 'CCN(Cc1cccc(Cl)c1)C(=O)C1CN(C)CCO1', 'CCOc1ccc(NC(=O)CN(C)C(=O)C2CCOC2)c(C)c1', 'Cc1cc(Cl)cc2c1OCC(=O)N(C)C2(C)C', 'CN(C)C(=O)CN(C)C(=O)c1ccc(-n2ccnn2)cc1'], 49: ['COc1ccc(-c2cn3cc(Cl)cc(N)c3n2)cc1', 'CCCCCNc1ncnc(Oc2ccccc2C)c1N', 'Cc1c(-c2ccnc(N)n2)nnn1CCCc1ccc(Cl)cc1', 'Cc1ccc(C)c(Nc2ncnc(-n3nc(C)cc3C)c2N)c1', 'Cc1ccc(CCn2nncc2-c2cccc(N)c2)cc1', 'COc1ccc(Cn2c(N)nc3cc(Cl)ccc32)c(OC)c1', 'Nc1ccc(-c2nc3c(s2)CCc2ccccc2-3)cc1', 'CCNc1ncnc(Nc2cc(C)ccc2OC)c1N', 'COc1ccc(-c2ncnc(C)c2N)cc1Br', 'Nc1cc(COc2cccc(Br)c2)no1'], 41: ['CCCN1C(=O)c2ccccc2NC12C(=O)Nc1ccccc12', 'Cc1cccc(OCC(C)NC(=O)C2CC(=O)Nc3ccccc32)c1', 'CC(=O)Nc1ccc(CC(=O)Nc2ccccc2N2CCCC2)cc1', 'CC(CNC(=O)C1Cc2ccccc2O1)N(C)c1ccccc1', 'CC(C)NC(=O)CCC(=O)N1c2cccn2-c2ccccc2C1C', 'COc1ccccc1CNc1ccccc1C(=O)N1CCCC1', 'COc1ccccc1NC1CCN(C(=O)c2n[nH]c3ccccc23)CC1', 'Cc1ccc(NC(=O)C2COc3ccccc3C2)nc1', 'COC(=O)Nc1ccc(CNc2ccccc2C(=O)N2CCCC2)cc1', 'CC(=O)Nc1ccccc1OS(=O)(=O)c1ccc2c(c1)CCC2'], 63: ['CCC(OC(=O)C1CCCN(C(=O)C2CC2)C1)c1nnc2ccccn12', 'Cc1c[nH]nc1C1CCCCCN1C(=O)c1cc(Cn2ccnc2)on1', 'CCn1nc(C(=O)N2CCCC(c3cc4ncccc4cn3)C2)cc1C', 'CCCCC(=O)N1CCC(c2nnc(-c3ccccn3)o2)CC1', 'Cc1cc(C)c(C(=O)N2CCCCCC2c2cccn2C)c(=O)[nH]1', 'O=C(c1cn2ccccc2n1)N1CCCC(c2ccn[nH]2)C1', 'CCn1ncc2cc(C(=O)N3CC(C)CC(C)C3)c(N)nc21', 'Nc1ccc2nc(C(=O)NC3CCCN(C(=O)C4CC4)C3)cn2c1', 'Cc1ccn2ncc(C(=O)Nc3ccc(N4CCCCC4)cn3)c2c1', 'CC(=O)N1CCC(c2ccc(C(=O)NCCCn3ccnn3)cn2)C1'], 91: ['CC(C)c1cc(NC(=O)c2cc(F)cc(F)c2)[nH]n1', 'CCC(OC)C(=O)Nc1ccc2nc[nH]c(=O)c2c1', 'Cc1n[nH]c(=O)nc1N(CCO)C1CCCc2ccccc21', 'CC1CCC(NC(=O)c2n[nH]c3ccccc23)CC1', 'O=C(Nc1c[nH]cc(Br)c1=O)C1CC=CCC1', 'C=C=C(CCC)Cn1cnc2c([nH]c3ccccc32)c1=O', 'O=c1cc(CCO)[nH]c(Cc2ccc(Br)cc2)n1', 'CC(C)(C)n1cc(C(=O)N2CCC(c3n[nH]c(=O)[nH]3)CC2)cn1', 'Cc1n[nH]c(C(=O)NCC(C)(C)c2ccncc2)c1Br', 'COc1ccc(-c2cc(=O)[nH]c(=O)[nH]2)cc1C(C)(C)C'], 26: ['COc1ccc(C(=O)Nc2cccc(O)c2)cc1Br', 'CN(Cc1ccc(O)cc1)C(=O)COc1ccc(F)cc1F', 'Cc1ccc(C2(O)CCN(C(=O)c3ccccc3O)CC2)nc1', 'CCCN1C(=O)c2ccccc2NC1c1ccc(O)cc1', 'Oc1ccc(CCNc2ccc3cc[nH]c3n2)cc1', 'Cc1ccc(C(=O)Nc2ccc(CC(=O)N(C)C)cc2)c(O)c1C', 'COc1ccc2cc(C(=O)Nc3ccccc3O)[nH]c2c1', 'CNC(=O)COc1cccc(CNC(=O)c2ccc(O)cc2)c1', 'O=C(NCCNC(=O)c1ccccc1O)c1cc2ccccn2n1', 'COc1cc(C)ccc1NCc1cccc(O)c1Cl'], 45: ['CC(C)NC(=O)c1coc(NC(=O)c2cccs2)n1', 'CCOc1ccc2cc(C(=O)Nc3ccc4oc(C)nc4c3)[nH]c2c1', 'CCOC(=O)CNS(=O)(=O)c1ccc2c(c1)oc(=O)n2C', 'Cc1ccc(S(=O)(=O)Nc2ccc3oc(=O)[nH]c3c2)s1', 'Cc1oc(-c2ccccc2)nc1CNC(=O)c1ccc[nH]c1=O', 'Cc1ccc2oc(NC(=O)c3nn(C)c(=O)c4ccccc34)nc2c1', 'COC(=O)c1oc(Cc2c[nH]c3ccccc23)nc1C', 'CC(C)c1ccc(Cn2c(=O)oc3cccnc32)cc1', 'O=C(Cc1ccccc1F)NCc1coc(-c2cccs2)n1', 'CC(=O)NC(C)C(=O)OCc1nc2ccccc2o1'], 60: ['CCOC(=O)CCC1NCCc2ccc(O)c(F)c21', 'COC(=O)C(NC(=O)c1cc(C)ccc1C)C(C)C', 'CCN(CCC(=O)OC)C(=O)c1ccccc1Br', 'CC(=O)OCc1c(CO)cc(OC(C)=O)cc1OC(C)=O', 'CNC(=O)C1CCC(NC(=O)COC(=O)c2ccccc2Cl)CC1', 'CCOC(=O)CN(C(=O)c1ccc(OC)cc1O)C(C)C', 'COC(=O)CN(Cc1cccc(OC)c1)C(=O)C1CCC1', 'CCOC(=O)c1ccc(NCC2COCCO2)nc1', 'CC(C)=CC(=O)OCC(=O)NC(C)(C)c1cccc(Cl)c1', 'COC(=O)C(C)N(C(C)=O)c1ccc(Cl)cc1'], 35: ['COc1cc(CNc2ncn[nH]2)ccc1OCOc1cccc(F)c1', 'COc1ccc(OC)c(CN(C)C(=O)Cn2c(=O)n(C)c3ccccc32)c1', 'COc1cc(C)ccc1OS(=O)(=O)c1ccc2c(c1)OCCCO2', 'CCCS(=O)(=O)Nc1ccc(Oc2ccccc2OC)nc1', 'COc1ccc(C(=O)Nc2ccc(CC(N)=O)cc2)cc1OC(C)C', 'COc1cc(OC)cc(C(=O)Nc2cccc(C(N)=O)c2)c1', 'CCc1ccc(OCC(=O)N(C)Cc2ccc(OC)cc2OC)cc1', 'COc1ccc(C(=O)N2CCC(Oc3ccccc3)CC2)c(OC)c1', 'CCN(Cc1ccc(OC)c(OC)c1)C(=O)c1ccncc1', 'COc1ccc(C(=O)Nc2cc(C)ccc2F)cc1OCCO'], 24: ['COc1cccc(C(=O)CCC(=O)NC2CCCCC2)c1', 'COCNC(=O)COC(=O)c1[nH]c(C)c(C(C)=O)c1C', 'CC(=O)c1ccc(NC(=O)N2CCCC2c2cccn2C)cc1C', 'CC(=O)c1c(C)[nH]c(C(=O)NC(C)c2cc(C)sc2C)c1C', 'CCC(C)N1CCN(S(=O)(=O)c2cccc(C(C)=O)c2)CC1', 'CC(=O)N1CCC(NC(=O)CCCC(=O)c2ccccc2)CC1', 'O=C(c1ccc(F)cc1)C1CCN(C(=O)Cc2ccc[nH]2)CC1', 'CC(=O)c1ccc(N2CCCC(C(=O)N3CCCC3)C2)c(F)c1', 'C=CCn1c(C)cc(C(=O)COc2ccc(C#N)c(F)c2)c1C', 'O=C(CCCc1ccccn1)OCC(=O)c1ccc[nH]1'], 65: ['CNS(=O)(=O)c1ccc(NS(=O)(=O)c2cc(C)ccc2C)cc1', 'O=S(=O)(Nc1cc(Cl)ccc1O)c1ccccc1', 'CNC(=O)c1ccc(CN(C)S(=O)(=O)Cc2ccccc2)cc1', 'Cc1ccc(NS(=O)(=O)c2cccc(F)c2)cc1F', 'Cc1ccc(F)cc1S(=O)(=O)Nc1ccccc1O', 'CC(=O)Nc1ccc(S(=O)(=O)N(C)C2CCCc3ccccc32)cc1', 'CC(=O)Nc1cc(NS(=O)(=O)c2ccccc2)ccc1Cl', 'CNS(=O)(=O)c1ccc(C(C)NC(=O)c2ccc(C)cc2)cc1', 'Cc1ccc(S(=O)(=O)NCc2ccccc2Cn2cccn2)cc1C', 'Cc1cccc(CC(=O)Nc2ccc(C)c(S(N)(=O)=O)c2)c1'], 11: ['CC(O)(CNS(=O)(=O)Cc1ccon1)c1ccc(F)cc1', 'COc1ccc(S(=O)(=O)Nc2ncccc2F)cc1OC', 'CCOc1ccc(S(=O)(=O)NCc2cnn(C)c2)cc1', 'CN(c1ccc(C(=O)Nc2ccccn2)cc1)S(C)(=O)=O', 'CCCCOc1cc(C)ccc1S(=O)(=O)Nc1cccnc1', 'O=C(NCCNS(=O)(=O)c1cccnc1)c1ccc2cc[nH]c2c1', 'COc1cc(S(=O)(=O)Nc2cccc(C)n2)ccc1Cl', 'CCN(CCCNc1cc(C)nc(-c2ccccn2)n1)S(C)(=O)=O', 'Cn1c(=O)c2cn(S(=O)(=O)c3ccc(Cl)cc3)cc2n(C)c1=O', 'O=S(=O)(NCCc1nnc2ccccn12)c1cc(F)ccc1F'], 57: ['O=C(COC(=O)Cc1ccc(F)cc1)Nc1ccc(F)cc1F', 'COc1ccc(C(O)CNc2cccc(C)c2)cc1F', 'CN(Cc1ccc(F)cc1)C(=O)c1ccc(F)cc1', 'CCn1cnnc1-c1cccc(NC(=O)c2ccc(F)cc2F)c1', 'O=C(Nc1ccc(F)c(F)c1F)c1c[nH]c2ccccc2c1=O', 'CCc1ccccc1NC(=O)c1cc(F)ccc1F', 'O=C1COc2cc(C(=O)NCCc3ccc(F)cc3F)ccc2N1', 'C=CCn1c(=O)n(CC=C)c(=O)n(Cc2cccc(F)c2)c1=O', 'Cc1cc(C)cc(C(=O)NCC(O)c2c(F)cccc2F)c1', 'Cc1nc2ccc(C(=O)Nc3ccc(Cl)cc3F)cc2nc1C'], 2: ['Cc1cc(C)n(-c2ccc(C(=O)N(C)Cc3cc(C)on3)cc2)n1', 'Cn1cnc(CNC(=O)CCCc2nc(-c3ccccc3)no2)n1', 'COCCCN(C)C(=O)c1cn(-c2ccc(C)c(C)c2)nn1', 'Cc1noc2nc(C)n(Cc3ccc(Cl)cc3)c(=O)c12', 'Cc1noc(NC(=O)Cn2cnc3cc(C)c(C)cc32)n1', 'CCc1noc(CN(C)C(=O)c2cnc(C)nc2C)n1', 'CCCn1c(=O)c2c(nc(-n3nc(C)cc3C)n2C)n(C)c1=O', 'CCc1nc(OCC(=O)Nc2cc(C)on2)c2ccccc2n1', 'Cc1ccc(C)c(OC(=O)CCn2nnc3ccccc3c2=O)c1C', 'Cc1ccc(-n2nc(C)cc2NC(=O)c2cc(C)nn2C)nn1'], 27: ['Cc1nnnn1C(Cc1ccccc1)c1nc(-c2ccccc2)no1', 'Fc1cc(F)cc(-c2noc3c2CN(c2ccc4nnnn4n2)CC3)c1', 'FC(F)(F)c1ccccc1COc1cccc(-n2cnnn2)c1', 'CC(Oc1ccc(-n2cnnn2)cc1)c1nnc(-c2ccccc2)o1', 'O=C(Oc1ccc(Br)cc1F)c1ccc(-n2cnnn2)cc1', 'O=C(Cc1ccc(-n2cnnn2)cc1)Nc1ccccc1F', 'c1ccc2[nH]c(C3CCCN(c4ccc5nnnn5n4)C3)nc2c1', 'O=C(NCc1nncn1C1CC1)c1ccc(F)cc1-n1cnnn1', 'CC(C)(C)OC(=O)N1CCC(c2nnnn2-c2ccccc2)CC1', 'Cc1cc(NC(=O)N(C)C(C)c2ccco2)ccc1-n1cnnn1'], 84: ['NC(=O)C(c1ccccc1)c1ccc2c(c1)OCO2', 'NC(=O)CC1CCN(c2ccc3ccccc3c2)CC1', 'COCc1nc2cc(Cl)ccc2n1CCC(N)=O', 'CC(Nc1nc2ccccc2nc1N(C)C)C(N)=O', 'COc1cccc(CNc2cc(C(N)=O)c(F)cc2F)c1', 'COc1ccc(Cl)cc1COc1ccc(C(N)=O)cc1', 'COc1cccc(NC(=O)c2cc(C(N)=O)cn2C)c1', 'NC(=O)c1ccc(COc2cccc(NC(=O)C3CC3)c2)c(F)c1', 'NC(=O)c1ccc(NC(=O)c2cc(=O)c3ccccc3o2)cc1Cl', 'CCCC(NC(=O)c1cccc(OC)c1)C(=O)N1CCCC1C(N)=O'], 42: ['O=C(Nc1cc(C(F)(F)F)c[nH]c1=O)c1ccc(-n2cccn2)cc1', 'Cc1ccccc1OCCNC(=O)Cn1ccc(C(F)(F)F)n1', 'O=c1[nH]c(Nc2ccc(F)cc2C(F)(F)F)nc2c1CCC2', 'O=C(Cn1nc(C(F)(F)F)cc1C1CC1)NC1CCOc2ccccc21', 'Cc1cc(C)c(C(=O)NC(c2ccccc2)C(F)(F)F)c(=O)[nH]1', 'Nc1ncc(C(F)(F)F)cc1NCc1ccc[nH]1', 'O=C(Cc1c(F)cccc1Cl)NCc1cccnc1OCC(F)(F)F', 'COc1cc(C(=O)Nc2ccc(OC(F)(F)F)cc2)on1', 'CCn1nc(C)c2c1c(C(F)(F)F)nn2CC(=O)OC', 'N#Cc1ccc(NC(=O)c2scnc2C2CC2)cc1C(F)(F)F'], 18: ['CC(C)(C)N(Cc1cccc(N)c1)C(=O)c1ccccc1', 'COc1ccc(CNC(=O)CNc2cccc(C)c2)cc1', 'NC(=O)c1ccc(CN(Cc2ccccc2)C2C=CCC2)cc1', 'CC(C)N(Cc1cccnc1)C(=O)Cc1ccccc1', 'Cc1ccc(Cl)cc1NCC(=O)N(C)Cc1ccccc1', 'CCOc1ccc(C2=CCN(C(=O)c3cccc(F)c3)CC2)cc1', 'COc1ccc(CNc2cccc(NC(C)=O)c2)cc1', 'CN(C)C(=O)c1cccc(CNc2ccccc2C(C)(C)C)c1', 'CCOc1ccc(CNCC(O)c2ccccc2F)cc1', 'CC(C)(C)Oc1ccc(CNC(=O)c2ccccn2)cc1'], 36: ['CCS(=O)(=O)N(C)CC(=O)Nc1cc(C(N)=O)ccc1C', 'CN(CC(=O)Nc1ccc(C(N)=O)c(Cl)c1)S(C)(=O)=O', 'CC(C)S(=O)(=O)Nc1ccc2c(c1)CCC2', 'CC(C)(C)c1ccc(CCNC(=O)CNS(C)(=O)=O)cc1', 'Cc1ccc(C(=O)N(CCNS(C)(=O)=O)C(C)C)cc1F', 'CCCNC(=O)C(C)NS(=O)(=O)c1ccc(C)cc1C', 'CCNC(=O)CN(C)S(=O)(=O)c1cc(N)ccc1Cl', 'CC(C)CN(C)C(=O)CCNS(=O)(=O)c1cccc(F)c1', 'CNC(=O)CCNS(=O)(=O)c1ccc2c(c1)C(C)(C)C(=O)N2C', 'CCC(=O)Nc1ccc(C)c(S(=O)(=O)NC(C)(C)C)c1'], 88: ['CC(=O)c1ccc(NC(=O)C2(c3ccc(F)cc3F)CCOCC2)cc1', 'CC(C)C(=O)c1ccccc1NC(=O)CCCc1cccs1', 'CC(=O)c1cccc(NS(=O)(=O)c2cccc(F)c2)c1', 'O=C(CCC(=O)c1ccccc1)Nc1ccccc1', 'CC(=O)c1ccc(NC(=O)CCC(=O)c2ccc(F)c(F)c2)cc1C', 'COc1ccc(C)cc1C(=O)CNC(=O)c1ccccc1C', 'COCCCn1c(-c2ccccc2)ccc(C(C)=O)c1=O', 'CN1C(=O)C(O)(CC(=O)c2ccc(F)cc2)c2ccccc21', 'O=C(COc1ccccc1F)NCC(=O)c1ccc2c(c1)CCC2', 'CC(=O)c1c(C)[nH]c(C(=O)Nc2ccc(C(N)=O)cc2)c1C'], 6: ['CCOc1cc(CO)cc2c1OC(C)C(=O)N2Cc1ccccc1', 'CCOc1cccc(C(=O)NCc2ccc3c(c2)OCCO3)c1', 'Cc1cc(NCC(=O)Nc2ccc3c(c2)OCO3)ccc1F', 'COc1ccc(C)cc1NC(=O)COc1ccccn1', 'CN(Cc1ccccn1)C(=O)CCc1ccc2c(c1)OCO2', 'CCOc1c(Br)cc(C(=O)NCc2ccccn2)cc1OC', 'CCN(CC)C(=O)CCC(=O)Nc1ccc2c(c1)OCO2', 'COc1ccc(OCCN2CCn3c(nn(C)c3=O)C2)cc1', 'COc1c(Cl)cccc1NC(=O)COc1ccc2c(c1)CCC(=O)N2', 'Cc1ccc(-n2c(=O)[nH]c3c(c2=O)COC2OC(C)(C)OC32)cc1'], 90: ['Cc1nccc(-c2cccc(NC(=O)CC(C)c3ccccc3)c2)n1', 'COc1ccc(CC(=O)Nc2nnc(Cc3ccc(C)cc3)o2)cc1', 'COc1cccc2c(=O)n(Cc3ccc(C)cc3)cnc12', 'CCn1cc(C(=O)Nc2cccc(Oc3ccccc3)c2)cn1', 'COc1ccc(C2CC(c3ccc(F)cc3)Nc3ncnn32)cc1', 'O=C(Nc1cccc(-n2cccn2)c1)c1cc2ccccc2oc1=O', 'O=C(COc1ccccc1)N1CCn2nc(-c3ccccn3)cc2C1', 'Cc1ccccc1-c1cc(C(=O)N(C)C(C)c2ccccn2)no1', 'O=C(NCCc1cn(-c2ccccc2)nc1-c1ccncc1)C1CC1', 'O=C(Cc1ccc2ccccc2c1)NCCc1cccnc1'], 50: ['CCOC(=O)c1c(-c2ccc(Oc3ccccc3)cc2)n[nH]c1N', 'O=C(CCOc1ccc(Cl)c2ccccc12)N=c1[nH]nc2ccccn12', 'CCC(NC(=O)CCc1c[nH]c2ccccc12)c1ccncc1', 'COc1ccc(NC(=O)CCCc2c[nH]c3ccccc23)cc1', 'O=C(Nc1cccc2cn[nH]c12)c1cccc(NC(=O)C2CC2)c1', 'Cc1ccc(C)c(C(C)NC(=O)c2ccc3[nH]c(=O)c(=O)[nH]c3c2)c1', 'Cc1ccc(OC(=O)c2cc(=O)[nH]c3ccccc23)cc1', 'O=C(Cn1c(=O)[nH]c2ccccc2c1=O)NCCc1ccc(F)cc1', 'Cc1ccnc(NC(=O)c2cc3ccccc3[nH]2)c1', 'O=C(NCCc1ccccn1)C1CN(C(=O)c2c[nH]c3ccccc23)C1'], 68: ['CCc1ccc(CNC(=O)NC2CC(=O)N(CC(C)(C)C)C2)s1', 'O=C(Cc1cc(-c2cccs2)on1)N1CCOCC1', 'CCCc1cc(C(=O)N2CCC(NC(C)=O)C2)sc1C', 'Cn1ccc(NC(=O)CCCc2cccs2)n1', 'O=C1CC(C(=O)N2CCCCC2)c2sccc2N1', 'NC(=O)C1(CNC(=O)c2cc3c(s2)CCCCC3)CCOCC1', 'NC(=O)Cn1cnc2sc(C(=O)NCC3CCCO3)c(C3CC3)c2c1=O', 'CCc1nc2sc3c(c2c(=O)n1CCOC)CCN(C)C3', 'Cc1n[nH]c2sc(C(=O)N3CCC(C)CC3)cc12', 'Cc1ccc(CNC(=O)C2(C)CCOCC2)s1'], 69: ['Cc1ccc(N2CCC(NC3C=CCCC3)C2=O)cc1', 'O=C(NC1CC=CCC1)c1nn(-c2ccccc2)c2c1CCC2', 'Cc1cc(NC(=O)C2CC2)ccc1OCc1cccnc1', 'COc1ccccc1C1(C(=O)Nc2nc(C)ns2)CCCC1', 'O=C(NCc1ccc(Cn2cccn2)cc1)c1cc(C2CC2)on1', 'Cc1ccc(OCC#CCNC(=O)CC2(O)CCCCC2)cn1', 'CC1C(=O)Nc2c(Cl)cc(C(O)C3CCCCC3)cc21', 'O=C(NCc1ccccc1)c1noc2c1CCCCC2', 'O=C(NC1CCCCC1)c1ccc(N2CCCC2=O)cc1', 'CCN(C(=O)c1ccnc(NC2CC2)c1)c1ccccc1'], 10: ['N#Cc1cccc(Cn2ccnc2CCN2CCOCC2)c1', 'CC(C)N1CCOC(CNCc2cccc3cccnc23)C1', 'COc1cccc(CNC(=O)c2ccc(N3CCOCC3)nn2)c1', 'O=C(Nc1cccc(N2CCCC2)c1)c1ccc(N2CCOCC2)nc1', 'O=C(Nc1cccnc1)C1COCC(=O)N1Cc1ccccc1', 'CC1COCCN1Cc1ccc(C(=O)N2CCOC2)cc1', 'Cc1ccccc1-n1ncc(C(=O)N2C(C)COCC2C)c1C1CC1', 'c1coc(COc2ccccc2-c2ccc(N3CCOCC3)nn2)c1', 'CC1CN(CCCn2c(=O)c3cccn3c3cccnc32)CC(C)O1', 'Cc1cc(Cl)ccc1OCC(CC#N)N1CCOCC1'], 78: ['N#Cc1cnc2ccccc2c1NC1(CO)CCCC1', 'CC1(C)CC(=O)c2cnc3c(C(=O)N4CCC(C#N)CC4)cnn3c2C1', 'CC(NC(=O)C1(C#N)CCCC1)c1ccc2c(c1)OCCO2', 'Cc1nc(C)n(CC2CCCN2C(=O)COc2ccc(C#N)cc2)n1', 'Cc1noc(C)c1CCC(=O)C(C#N)c1ccccn1', 'Cc1[nH]c(=O)c(C#N)c(C)c1CCC(=O)NCCC1=CCCCC1', 'Cc1nc(C2(NC(=O)c3cccc(C#N)c3)CCCCC2)no1', 'Cc1nc(C(=O)N2CCCC2Cn2cccn2)ccc1C#N', 'N#CCCCN1CCN(C(=O)COc2cccc(Cl)c2)CC1', 'Cc1cccc(C(=O)N(C)C2(C#N)CCC2)c1Oc1cccnc1'], 15: ['N#Cc1ccc(CNc2cc(Br)ccc2F)cc1', 'N#Cc1cccc(C(=O)Nc2cc(-c3c(F)cccc3Cl)[nH]n2)c1', 'N#Cc1c(-c2ccccn2)cc(-c2ccc(F)cc2)nc1N', 'N#Cc1ccccc1NCC(=O)Nc1ccccc1OC(F)F', 'COc1ccc(-c2[nH]c3ccc(F)cc3c2CC#N)cc1', 'N#CC(CC(=O)Nc1cccnc1)c1ccccc1F', 'COC(C)c1cccc(NC(=O)Cc2cccc(OCC#N)c2)c1', 'CCCN(Cc1ccc(C#N)cc1)C(=O)c1cc2ccccc2[nH]1', 'N#Cc1cccc(C(=O)NCC2COc3ccccc3C2)c1', 'Cc1ccc(C(C)N(C)C(=O)c2ccc(C#N)cn2)cc1'], 13: ['O=C(COc1ccccc1)NCCc1ccsc1', 'CC(NC(=O)c1cccs1)C(=O)NC1CCSc2ccccc21', 'Cc1ccc(NC(=O)NCCNC(=O)c2ccc(O)cc2)s1', 'CN(Cc1ccsc1)C(=O)c1ccc(Cl)c(N)c1', 'O=C(NC1CC(=O)N(c2ccc3c(c2)OCCO3)C1)c1cccs1', 'NC(=O)CCN(C(=O)c1ccsc1)c1ccc(F)cc1', 'O=C(c1scc2c1OCO2)N1CCOc2ccccc21', 'O=C(NCCc1cccs1)c1cccc(Cl)c1', 'COc1ccc(N)cc1CNC(=O)c1cc(C)sc1C', 'O=C(Cc1ccccc1)NCC(=O)N1CCc2sccc2C1'], 17: ['Nc1ccc(S(=O)(=O)c2ccc3c(c2)CC(=O)N3)cc1', 'Cc1nc(C)c(Cc2ccc(S(C)(=O)=O)cc2)[nH]1', 'CCCS(=O)(=O)c1ccccc1C(=O)Nc1ccccc1', 'CCc1ccc(OCC(=O)Nc2cccc(S(C)(=O)=O)c2)cc1', 'CC(C)(C)c1nnc(CS(=O)(=O)c2nccn2C2CC2)o1', 'CCn1c(-c2cccc(F)c2)nnc1S(=O)(=O)Cc1c(C)noc1C', 'Cc1csc(S(=O)(=O)Cc2ccc(F)cc2)n1', 'CS(=O)(=O)c1ccc(NC(=O)NCc2ccc(Cl)cc2)cc1', 'Cc1cc(S(C)(=O)=O)ccc1NC(=O)C1CC2C=CC1C2', 'CC1(C)CN(c2ccc(S(C)(=O)=O)cc2S(C)(=O)=O)CCO1'], 32: ['CCNC(=O)c1ccc(CNC(=O)Nc2cc(C)ccc2OC)cc1', 'CCN(Cc1ccccc1)C(=O)NCc1ccc(NC(C)=O)cc1', 'Cc1ccc(NC(=O)NC(C)c2ccncc2)c(Br)c1', 'COc1cc(CNC(=O)NC(C)c2ccc(F)c(F)c2)ccn1', 'CC(CCc1ccccc1)NC(=O)NCc1ccc2c(c1)OCCO2', 'COCCOc1ccccc1NC(=O)NCc1ccc2c(c1)CCC2', 'CNC(=O)NCC(=O)Nc1ccc(Oc2cccc(C)c2)cc1', 'O=C1NCC(C(=O)Nc2ccc(NC(=O)c3ccccc3)cc2)N1', 'O=C(NCC(=O)N1CCc2ccccc21)NC(c1ccccc1)C1CC1', 'O=C(CNC(=O)Nc1nncs1)NCc1ccc(F)cc1'], 89: ['Cc1nc(COc2ccc(C(=O)Nc3ccc(Cl)cc3)cc2)no1', 'COCc1cc(C(=O)Nc2cccc(-n3cnnc3)c2)ccc1F', 'O=C(CCn1cncn1)Nc1ccc(OCc2ccc(F)cc2)cc1', 'COc1c(Cl)cccc1NC(=O)CNC(=O)Cc1ccccc1', 'O=C1c2ccccc2NC(c2cccnc2)N1c1cccc(F)c1', 'CCCNC(=O)c1ccccc1NC(=O)Cn1cccnc1=O', 'COc1ccccc1C(=O)Nc1cc2c(C)cc(=O)oc2cc1C', 'CC(=O)Nc1ccc(CC(=O)Nc2nnc(-c3ccno3)o2)cc1', 'CNC(=O)c1cccc(NC(=O)c2cnn(-c3ccccc3)c2)c1C', 'COc1ccc(C(=O)Nc2ccc(N3CCC(O)CC3)nc2)cc1'], 72: ['Cc1nc2sc(-c3ccccc3Cl)cc2c(=O)n1N', 'O=c1c2ccsc2ncn1Cc1cn(-c2ccccc2)nn1', 'COc1ccsc1C(=O)Nc1cccc(-c2nn[nH]c2C)c1', 'CCn1nc(C)c(NC(=O)c2cc3sccc3n2C)c1C', 'Cn1nc(CNc2ncnc3sccc23)c2ccccc2c1=O', 'Cc1ccsc1CNC(=O)c1ccc2ncnn2c1', 'Cn1c(SCC(=O)Nc2ccc(F)cc2)nc2ccsc2c1=O', 'O=C(Cc1ccsc1)NCCNc1nnc2ccccn12', 'C=CCn1c(NCc2ccncc2)nc2sc3c(c2c1=O)CCC3', 'O=C(CCSc1cccs1)Nc1ccnc2ccnn12'], 74: ['CC(NC(=O)CSc1n[nH]c(=O)n1C1CC1)c1ccccc1Cl', 'CCOC(=O)C1=C(CSc2nc(C)n[nH]2)NC(=O)NC1', 'COc1cccc(Nc2nc(NCCO)nc(SC)n2)c1', 'CCSc1cnn(-c2ccccc2)c(=O)c1Cl', 'CCN(C(=O)CSc1cn[nH]n1)c1ccccc1C', 'COc1ccc(-c2n[nH]c(SCC(=O)NC3CC3)n2)cc1', 'CSc1ccccc1NC(=O)COC(=O)c1c(C)nn(C)c1C', 'COc1ccccc1-c1cc(=O)n2c(n1)SCC2', 'CCCn1c(C)nnc1SCC(=O)NCCc1ccccc1', 'CCCc1cc(O)nc(SCC(=O)Nc2c(F)cccc2F)n1'], 64: ['COCC(C)NC(=O)Nc1cnc2c(c1)c(C)nn2C', 'O=C(Nc1ccc(-n2ccnc2)nc1)NC1CCCCC1', 'Cn1cccc1CN(C(=O)Nc1ccc2c(c1)OCO2)C1CCCC1', 'C=CCNC(=O)Nc1ccc(-c2csnn2)cc1', 'CCn1c(CCNC(=O)NC2CC2)nc2ccccc21', 'Cc1ccc(C2(O)CCN(C(=O)Nc3ccc(C)c(C)c3)CC2)nc1', 'CCC1CCCCC1NC(=O)NCc1ccc(-n2ccnc2)nc1', 'CCCN(CCO)C(=O)Nc1ccc(Oc2cccnc2)nc1', 'CCCCNC(=O)NCCc1cn(C)c2ncccc12', 'CCNC(=O)N(CC)Cc1nc(CC)c2ccccc2n1'], 62: ['COC(=O)C(NC(=O)c1ccc(-n2ccnn2)cc1)C(C)C', 'COC(=O)CCNc1ncnc2c1cnn2CCNC(C)=O', 'COC(=O)Cn1cc(NC(=O)c2ccccc2C)cn1', 'CCOC(=O)c1nnn(-c2ccc(C)cc2)c1-c1ccncc1', 'CCOC(=O)c1nn(-c2cc(C)ccn2)cc1O', 'CCOC(=O)c1cccc(NC(=O)Cn2cnc(C)cc2=O)c1', 'COC(=O)Cn1c(C(=O)NC(C)c2ccncc2)cc2ccccc21', 'CCOC(=O)c1cn(CC(=O)NCc2ccccn2)nn1', 'Cc1cc(-n2cncn2)ccc1C(=O)OCC(=O)NC1CCCC1', 'O=C(CC1CCCCC1)OCn1nnc2ccccc2c1=O'], 48: ['CCCS(=O)(=O)N1CCCC1C(=O)Nc1ccc(C)cc1Cl', 'CCCS(=O)(=O)N1CCN(c2ncccn2)CC1', 'Cc1ccc(S(=O)(=O)NCC(=O)NCC2CCC2)cc1F', 'NC(=O)C1CCCN1C(=O)c1cccc(S(=O)(=O)N2CCCC2)c1', 'Cc1cnc(C(=O)NCCN2CCCS2(=O)=O)cn1', 'COC(=O)CNS(=O)(=O)c1ccc(N2CCCNC2=O)cc1', 'COc1ccc(S(=O)(=O)N2CCNC(=O)C2(C)C)c(C)c1', 'CC1CCCN(C(=O)CCNS(=O)(=O)c2ccccc2)CC1', 'O=S(=O)(NCC1CCOC1)c1ccc2c(c1)OCCO2', 'COc1cccc(N2CCN(S(C)(=O)=O)CC2)c1'], 86: ['CC(=O)N(C)Cc1ccccc1NC(=O)c1cc(C)n(C(C)C)c1C', 'Cc1cccc(C)c1OCC(=O)NC(C)CCC(C)C', 'Cc1noc(C)c1C(C)NC(=O)CCc1ccccc1', 'CCC(C)C(=O)NCc1cccc(Cn2ccnc2C)c1', 'Cc1noc(C)c1C(C)NC(=O)COc1ccccc1F', 'Cc1ccc(NC(=O)c2ccc(=O)n(C)n2)c(OCC2CCOC2)c1', 'CCc1cccc(C)c1NC(=O)COc1ccc2c(c1)CCCC(=O)N2', 'Cc1nnsc1C(=O)NC(C)c1ccc2c(c1)CCC(=O)N2', 'Cc1nc(C)c(CC(=O)Nc2c(C)cccc2C(C)C)c(=O)[nH]1', 'Cc1cccc(NC(=O)Cn2nc(C)c(Br)c2C)c1'], 76: ['CCC(CC(=O)N1CCN(C)C(=O)C1)c1ccccc1', 'COc1ccccc1N1CCN(C(=O)CCCn2cccc2)C(C)C1', 'COc1cccc(N2CCN(C(=O)CCCn3cccn3)CC2)c1', 'COc1ccc(N)cc1N1CCN(C(=O)OC(C)(C)C)CC1', 'COc1cccc(-c2noc(N3CCN(C(=O)C4CC4)CC3)n2)c1', 'O=C(COc1ccccc1)N1CCN(C(=O)c2ccccc2)CC1', 'CC(C)(C)OC(=O)N1CCN(c2n[nH]c3c2CCC3)CC1', 'Cc1cccc(C(C(=O)N2CCN(Cc3ccccc3)CC2)N(C)C)c1', 'CCOC(=O)N1CCN(C(=O)CCc2c(C)nc(C)[nH]c2=O)CC1', 'CC1CN(C(=O)Cc2ccc[nH]2)C(C)CN1Cc1cccc(F)c1'], 22: ['Nn1c(=O)c2c(ncn2C2OC(CO)C(O)C2O)n(CO)c1=O', 'CCOc1ncccc1NC(=O)c1cn(CC)nc1OC', 'CCNc1cc(OCCO)nc(-c2ccccn2)n1', 'COc1ccc2c(C(=O)NC(C)c3nncn3C3CC3)cc(=O)oc2c1', 'CC(C)c1cccc(OCC(=O)Nc2nccn(C)c2=O)c1', 'CC(C)c1nnsc1CN1Cc2ncccc2C1=O', 'Cc1nnsc1-c1nnc(C(C)NC(=O)Cc2ccccc2)o1', 'CCOCC(=O)Nc1ccc(-n2ccnc2C)nc1', 'CC(C)COc1cccc(C(=O)Nc2ncccc2CO)c1', 'O=C(Cn1cnc2ccccc2c1=O)NC1CCCNC1=O'], 1: ['CCc1cc(=O)n(CC(=O)Nc2ccccc2C)c(N)n1', 'Cc1cc(C)cc(NC(=O)CSc2nc(N)cc(N)n2)c1', 'CCC(C)Cn1c(-c2ccc(C)cc2)ccc(N)c1=O', 'Cc1ccc2cccc(OCC(=O)Nc3cccc(N)c3)c2n1', 'CC(C)C1Oc2cc(N)ccc2N(CCCOc2ccccc2)C1=O', 'Nc1cccc(-c2nnc(-c3ccc(F)cc3)o2)c1', 'CCNC(=O)c1ccc(CNC(=O)C2CC2)c(N)c1', 'CCOc1ccc(CCC(=O)NC(C)(C)CO)cc1N', 'CCN(CCO)c1ncnc(Nc2cc(Cl)ccc2C)c1N', 'CCc1cc(=O)n(CC(=O)Nc2ccc(Cl)cc2)c(N)n1'], 97: ['O=C(c1ccn(-c2ccccc2)n1)N1CCCC(c2ccn[nH]2)C1', 'Cn1cnnc1C1CCCN(C(=O)Cc2cc(Cl)ccc2F)C1', 'Cc1noc(CNc2ccccc2C(=O)N2CCCC(C)C2)n1', 'O=C1COc2ccccc2N1CCC(=O)N1CCCCC1Cc1ccc[nH]1', 'O=C(Nc1cnn(-c2ccccc2F)c1)C1CC(=O)N(C2CC2)C1', 'CC1CCN(C(=O)c2cc(NC(=O)c3ccccc3)n(C)n2)CC1', 'COc1ccc(C(=O)N2CCC(OCc3ccc(F)cc3)CC2)nn1', 'CN(c1ccccc1)C1CCN(C(=O)Cc2cccc(F)c2F)CC1', 'Cc1cccc(C(=O)N2CCC(C(=O)Nc3cccnc3)CC2)c1C', 'Cc1nc(C)n(C2CCCN(C(=O)COc3ccccc3)C2)n1'], 93: ['Cc1ccc(C(C)NC(=O)C(C)N2CCOC(C)C2)cc1F', 'CCCC1CN(C(=O)c2nn(C)c3ccc(F)cc3c2=O)CCO1', 'CN1CCOC(C(=O)Nc2ccc3c(c2)CCCC3)C1', 'Cn1cnc2cc(OC(=O)CN3CCOCC3)ccc21', 'COc1ccc(Cl)cc1-n1ccc(C(=O)N2CC(C)OC(C)C2)n1', 'CCN(CC)C(=O)c1ccccc1SCC(=O)N1CCOCC1', 'CC(=O)Nc1cc(N2CCOCC2)c(N)cc1Cl', 'O=S(=O)(C1CC1)N1CCOC(CN2CCOCC2)C1', 'O=C(c1ccc2c(c1)nnn2CC(F)(F)F)N1CCOCC1', 'CC1CN(CC(=O)Nc2ccc(N(C)C)nc2)CC(C)O1'], 4: ['COCC(=O)N1CCC(Oc2ccccc2)CC1', 'CCCC(=O)Nc1cccc(C(=O)NC(C)C2CCCO2)c1', 'CC(=O)NCC1NCCc2ccc3c(c21)CCO3', 'COc1ccc2c(c1)C1(CCN(C(=O)OC(C)(C)C)C1)C(=O)N2C', 'COc1ccc(OC)c(NC(=O)C2CCCN(C(=O)C3CC3)C2)c1', 'COCCN1CC(C(=O)Nc2ccc3c(c2)n(C)c(=O)n3C)CC1=O', 'CC1CC1CNC(=O)C1CCC(=O)N(C)C1c1cccnc1', 'O=C(Nc1ccccc1Br)C1CCCN(C(=O)C2CC2)C1', 'NC(=O)CN1C(=O)C2CCC1CN(C(=O)Cc1ccccc1)C2', 'CCN1CC(C(=O)NCC2(c3ccc(F)cc3F)CC2)CC1=O'], 39: ['COc1ccccc1-n1ccc2c(nnc3ccnn32)c1=O', 'O=C(Nc1ccnc2ccnn12)c1cn(Cc2ccccc2)nn1', 'Cc1ccc2oc(-c3cn(Cc4ccccn4)nn3)cc(=O)c2c1', 'Cn1c(=O)n(C2CC2)c(=O)c2cc(NC(=O)C#Cc3ccccc3)cnc21', 'O=C(NCc1cc(-c2ccc(Cl)cc2)no1)c1cnccn1', 'Cc1nnc(CNC(=O)c2ccc(-n3ccnn3)cc2)n1C', 'Cn1nccc1-c1nc(-c2ccc(F)cc2)no1', 'COc1ccc(CCNC(=O)c2cc3cccn3cn2)cc1', 'O=C(Nn1ccc2c(cnc3ccnn32)c1=O)c1ccccc1', 'O=C(c1ccncc1)c1ccc(Cl)c2cccnc12'], 38: ['COCCC1NCCc2c(Cl)ccc(Br)c21', 'CC1OC(N)CC1c1ccc(Br)cc1', 'CC(C)CC(CO)n1cc(-c2cccc(Cl)c2)nn1', 'Cn1c(C(=O)NCc2nccn2C(F)F)cc2cc(Cl)ccc21', 'COCCn1cc(C(=O)Nc2cccc(Cl)c2)c2cccnc21', 'CCn1nc(-c2cccc(Cl)c2)cc(CO)c1=O', 'O=C1CN(C(=O)c2cc3c(Cl)cccc3n2CCO)CCN1', 'CCc1noc(C)c1C(=O)NC(C)c1ccc(F)cc1Cl', 'COCCn1nc(C(=O)Nc2ccccc2Cl)ccc1=O', 'CC=CC=CC1NCCc2cc(Cl)c(O)cc21'], 34: ['CCC(c1ccco1)N(C)c1ncnc2sc3c(c12)CCNC3=O', 'COc1c(NC(=O)c2oc3c(C)cccc3c2C)c(C)nn1C', 'Cc1nn2ncc(C(=O)NCc3cc4ccccc4o3)c2[nH]1', 'Cc1cc(NC(=O)c2ccc(-c3ccccc3Cl)o2)n(C)n1', 'COC(C)C(=O)NCCn1c(-c2ccco2)nc2ccccc21', 'O=C(Nc1cccc(C(=O)N2CCc3ccccc32)c1)c1ccco1', 'Cc1cc(CN(Cc2cc(C)on2)Cc2ccco2)on1', 'O=C(NCCNC(=O)c1ccc(-c2ccco2)[nH]c1=O)c1ccon1', 'O=S(=O)(c1cc2ccccc2o1)N1CCCC1c1ccncc1', 'Cc1c(C(=O)NCc2ccco2)nnn1-c1ccccc1Cl'], 79: ['COc1c(F)cc(NC(=O)N2CCC(C)CC2)cc1F', 'CC(=O)NCCCNC(=O)NCCc1c(F)cccc1F', 'CCCCCCNC(=O)Nc1ccccc1CO', 'CNC(=O)c1cccc(CNC(=O)NC2CCCC(C)C2)c1', 'CNC(=O)NC(C)(C)C(=O)Nc1cccc(C)c1C', 'CCOC(=O)N1CCC(NC(=O)Nc2cc(C)on2)CC1', 'NC(=O)NC(CC(=O)NC1CCCCCC1)c1ccccc1', 'CCCC1=C(C(=O)OCC)C(c2ccc(C)cc2)NC(=O)N1C', 'CCOC(=O)N1CCC(NC(=O)NCc2cn(C)nc2C)CC1', 'CCC(NC(=O)NCC(=O)Nc1ccccc1)C(C)C'], 5: ['Cc1ccc(-c2cc(N)c(=O)n(CC(=O)N3CCOCC3)n2)o1', 'Cc1cc(C(=O)Nc2cc(C(F)(F)F)ccc2N)c(C)o1', 'Cc1cc(CNC(=O)CN(C)S(=O)(=O)N2CCCCC2)c(C)o1', 'CNC(=O)C(CNC(=O)c1cc(C)oc1C)Cc1ccc(F)cc1', 'Cc1ccoc1C(=O)N1CCC(Oc2ccccc2)CC1', 'CCOc1cc(C(=O)N(C)CC(=O)NC(C)C)cc2occc12', 'O=C(CCCc1ccco1)N1CCN(c2ccc(F)cc2)CC1', 'Cc1cc(C)c(C(=O)NCC(O)c2c(F)cccc2F)o1', 'CC(C)(C)CCNC(=O)c1cnc(-c2ccco2)nc1N', 'C=CCNC(=O)CN1C(=O)COc2cc(NCc3ccco3)ccc21']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "keyToData = {}\n",
        "for cluster, mols in cluster_to_samples.items():\n",
        "    for mol in mols:\n",
        "        keyToData.setdefault('smiles', []).append(mol)\n",
        "        keyToData.setdefault('cluster_id', []).append(cluster)\n",
        "pd.DataFrame(keyToData).to_csv(inference_config_dict['checkpoint_dir']+'mols_sampled_for_difdock_07_07.csv')\n",
        "pd.read_csv(inference_config_dict['checkpoint_dir']+'mols_sampled_for_difdock_07_07.csv').head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "mQaRu5WvOn5H",
        "outputId": "0d6977a5-7759-4cc9-ba33-75c2e5e46597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                  smiles  cluster_id\n",
              "0           0    CCn1cc(C(=O)NCC2C(=O)N=C(C)C=C2C)cn1          54\n",
              "1           1  CC1=CC(C)=NC(=O)C1CNS(=O)(=O)N(C)CCC#N          54\n",
              "2           2       CC1=CC(C)=NC(=O)C1CNC(=O)NCCC(C)C          54\n",
              "3           3       CSc1nnc(SCC(=O)Nc2cc(C)cc(C)c2)s1          21\n",
              "4           4         CSc1nnc(SCC(=O)Nc2ccnn2C(C)C)s1          21"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7147788f-6f1b-4030-9e42-797cdecff6c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>smiles</th>\n",
              "      <th>cluster_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CCn1cc(C(=O)NCC2C(=O)N=C(C)C=C2C)cn1</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CC1=CC(C)=NC(=O)C1CNS(=O)(=O)N(C)CCC#N</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CC1=CC(C)=NC(=O)C1CNC(=O)NCCC(C)C</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CSc1nnc(SCC(=O)Nc2cc(C)cc(C)c2)s1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CSc1nnc(SCC(=O)Nc2ccnn2C(C)C)s1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7147788f-6f1b-4030-9e42-797cdecff6c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7147788f-6f1b-4030-9e42-797cdecff6c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7147788f-6f1b-4030-9e42-797cdecff6c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBgupbjAPYu7"
      },
      "source": [
        "##Set up notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMwALd1zQBQ3",
        "outputId": "902f65c7-ece7-411b-8c67-f07696e10e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (8.4.0)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
            "Requirement already satisfied: molsets in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from molsets) (4.65.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from molsets) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from molsets) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from molsets) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from molsets) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from molsets) (2.0.1+cu118)\n",
            "Requirement already satisfied: fcd-torch>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from molsets) (1.0.7)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from molsets) (0.12.2)\n",
            "Requirement already satisfied: pomegranate==0.12.0 in /usr/local/lib/python3.10/dist-packages (from molsets) (0.12.0)\n",
            "Requirement already satisfied: joblib>=0.9.0b4 in /usr/local/lib/python3.10/dist-packages (from pomegranate==0.12.0->molsets) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from pomegranate==0.12.0->molsets) (2.6.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pomegranate==0.12.0->molsets) (6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->molsets) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->molsets) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->molsets) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->molsets) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->molsets) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->molsets) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->molsets) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->molsets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->molsets) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->molsets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->molsets) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->molsets) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->molsets) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->molsets) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->molsets) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->molsets) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->molsets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->molsets) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->molsets) (1.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.5)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.27.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.1+pt20cu118)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.17+pt20cu118)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/dist-packages (1.6.1+pt20cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "/content\n",
            "Cloning into 'DiffDock'...\n",
            "remote: Enumerating objects: 301, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 301 (delta 118), reused 108 (delta 98), pack-reused 146\u001b[K\n",
            "Receiving objects: 100% (301/301), 232.39 MiB | 17.90 MiB/s, done.\n",
            "Resolving deltas: 100% (148/148), done.\n",
            "/content/DiffDock\n",
            "Note: switching to 'a6c5275'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at a6c5275 remove debugging raise in the inference file\n",
            "/content/DiffDock\n",
            "Cloning into 'esm'...\n",
            "remote: Enumerating objects: 1511, done.\u001b[K\n",
            "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 1511 (delta 42), reused 126 (delta 36), pack-reused 1360\u001b[K\n",
            "Receiving objects: 100% (1511/1511), 11.78 MiB | 17.90 MiB/s, done.\n",
            "Resolving deltas: 100% (892/892), done.\n",
            "/content/DiffDock/esm\n",
            "Note: switching to 'ca8a710'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at ca8a710 Update version.py (#310)\n",
            "Obtaining file:///content/DiffDock/esm\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fair-esm\n",
            "  Building editable for fair-esm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fair-esm: filename=fair_esm-1.0.3-0.editable-py3-none-any.whl size=12991 sha256=386a04167349131bdfa00c859e0c71d530f49678183d026ea8d4ee6615c83a56\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p1fd8nm6/wheels/bf/8b/04/6b90c35ea3993beffa65ab00888579756ea7088fbba4613e85\n",
            "Successfully built fair-esm\n",
            "Installing collected packages: fair-esm\n",
            "Successfully installed fair-esm-1.0.3\n",
            "/content/DiffDock\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# install necessary packages\n",
        "!pip install rdkit\n",
        "!pip install pandas==1.5.3\n",
        "!pip install molsets\n",
        "!pip install wandb\n",
        "\n",
        "!pip install pyg==0.7.1 --quiet\n",
        "!pip install pyyaml==6.0 --quiet\n",
        "!pip install scipy==1.7.3 --quiet\n",
        "!pip install networkx==2.6.3 --quiet\n",
        "!pip install biopython==1.79 --quiet\n",
        "!pip install rdkit-pypi==2022.03.5 --quiet\n",
        "!pip install e3nn==0.5.0 --quiet\n",
        "!pip install spyrmsd==0.5.2 --quiet\n",
        "!pip install pandas==1.5.3 --quiet\n",
        "!pip install biopandas==0.4.1 --quiet\n",
        "\n",
        "!pip install torch-geometric torch-scatter torch-sparse torch-cluster\\\n",
        " -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "\n",
        " # import necessary packages\n",
        "from rdkit import Chem\n",
        "import shutil\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn.conv import MessagePassing, GatedGraphConv\n",
        "from torch_geometric.nn import global_add_pool\n",
        "from torch_geometric.utils import add_self_loops, dense_to_sparse\n",
        "from torch_geometric.nn.aggr import AttentionalAggregation\n",
        "from torch._C import NoneType\n",
        "from torch.optim import Adam\n",
        "from torch_geometric.data import Data, DataListLoader\n",
        "from torch_geometric.nn import DataParallel as GeometricDataParallel\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import h5py\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, pairwise_distances\n",
        "import os\n",
        "import random\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import pkg_resources\n",
        "pkg_resources.require(\"pandas==1.5.3\")\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import logging\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import QED, Crippen\n",
        "from rdkit.Contrib.SA_Score import sascorer\n",
        "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
        "from rdkit.Chem.Fingerprints import FingerprintMols\n",
        "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity\n",
        "from rdkit.Chem.Scaffolds.MurckoScaffold import MurckoScaffoldSmiles\n",
        "import moses\n",
        "from moses.utils import get_mol\n",
        "\n",
        "if not os.path.exists(\"/content/DiffDock\"):\n",
        "    %cd /content\n",
        "    !git clone https://github.com/gcorso/DiffDock.git\n",
        "    %cd /content/DiffDock\n",
        "    !git checkout a6c5275 # remove/update for more up to date code\n",
        "\n",
        "# clone ESM repository\n",
        "if not os.path.exists(\"/content/DiffDock/esm\"):\n",
        "    %cd /content/DiffDock\n",
        "    !git clone https://github.com/facebookresearch/esm\n",
        "    %cd /content/DiffDock/esm\n",
        "    !git checkout ca8a710\n",
        "    !sudo pip install -e .\n",
        "    %cd /content/DiffDock\n",
        "\n",
        "# set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42dkxj7rRd1z"
      },
      "source": [
        "##Run DiffDock to get top poses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_poses(ligands_csv_path, protein_pdb_path):\n",
        "    data = pd.read_csv(ligands_csv_path)\n",
        "    ligand_files = []\n",
        "\n",
        "    os.environ['HOME'] = 'esm/model_weights'\n",
        "    os.environ['PYTHONPATH'] = f'{os.environ.get(\"PYTHONPATH\", \"\")}:/content/DiffDock/esm'\n",
        "\n",
        "    for i in range(len(data)):  # change 1 to len(data) for processing all ligands\n",
        "        print(str((i / len(data)) * 100)[:5], ' %')\n",
        "        smiles = data['smiles'][i]\n",
        "        rdkit_mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "        if rdkit_mol is not None:\n",
        "            with open('/content/input_protein_ligand.csv', 'w') as out:\n",
        "                out.write('protein_path,ligand\\n')\n",
        "                out.write(f'{protein_pdb_path},{smiles}\\n')\n",
        "\n",
        "            # Clear out old results if running multiple times\n",
        "            shutil.rmtree('/content/DiffDock/results', ignore_errors=True)\n",
        "\n",
        "            # ESM Embedding Preparation\n",
        "            os.chdir('/content/DiffDock')\n",
        "            !python /content/DiffDock/datasets/esm_embedding_preparation.py --protein_ligand_csv /content/input_protein_ligand.csv --out_file /content/DiffDock/data/prepared_for_esm.fasta\n",
        "\n",
        "            # ESM Extraction\n",
        "            !python /content/DiffDock/esm/scripts/extract.py esm2_t33_650M_UR50D /content/DiffDock/data/prepared_for_esm.fasta /content/DiffDock/data/esm2_output --repr_layers 33 --include per_tok --truncation_seq_length 30000\n",
        "\n",
        "            # Inference\n",
        "            !python /content/DiffDock/inference.py --protein_ligand_csv /content/input_protein_ligand.csv --out_dir /content/DiffDock/results/user_predictions_small --inference_steps 20 --samples_per_complex 10 --batch_size 6\n",
        "\n",
        "            # Move results\n",
        "            for root, dirs, files in os.walk('/content/DiffDock/results/user_predictions_small'):\n",
        "                for file in files:\n",
        "                    if file.startswith('rank1_confidence'):\n",
        "                        shutil.move(os.path.join(root, file), os.path.join('/content', 'drive', 'MyDrive', 'Generative_ML', 'diffdock_best_poses', f'complex{i}'))\n",
        "                        ligand_files.append(f'/content/drive/MyDrive/Generative_ML/diffdock_best_poses/complex{i}')\n",
        "\n",
        "    return ligand_files"
      ],
      "metadata": {
        "id": "PeGCZ7P_leGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cfcaA3OR0Wy",
        "outputId": "faaaa1d7-6ac2-4111-c97b-66a43bedf511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0  %\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2570.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2706.\n",
            "  warnings.warn(\n",
            "100% 1/1 [00:00<00:00, 24.23it/s]\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to esm/model_weights/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to esm/model_weights/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n",
            "Transferred model to GPU\n",
            "Read /content/DiffDock/data/prepared_for_esm.fasta with 2 sequences\n",
            "Processing 1 of 1 batches (2 sequences)\n",
            "100% 201/201 [00:40<00:00,  4.99it/s]\n",
            "100% 201/201 [01:00<00:00,  3.33it/s]\n",
            "/content/DiffDock/utils/torus.py:38: RuntimeWarning: invalid value encountered in true_divide\n",
            "  score_ = grad(x, sigma[:, None], N=100) / p_\n",
            "Reading molecules and generating local structures with RDKit\n",
            "100% 1/1 [00:00<00:00, 29.25it/s]\n",
            "Reading language model embeddings.\n",
            "Generating graphs for ligands and proteins\n",
            "loading complexes: 100% 1/1 [00:00<00:00,  3.78it/s]\n",
            "loading data from memory:  data/cache_torsion/limit0_INDEX_maxLigSizeNone_H0_recRad15.0_recMax24_esmEmbeddings3387508103/heterographs.pkl\n",
            "Number of complexes:  1\n",
            "radius protein: mean 35.130279541015625, std 0.0, max 35.130279541015625\n",
            "radius molecule: mean 6.099888324737549, std 0.0, max 6.099888324737549\n",
            "distance protein-mol: mean 39.1522216796875, std 0.0, max 39.1522216796875\n",
            "rmsd matching: mean 0.0, std 0.0, max 0\n",
            "HAPPENING | confidence model uses different type of graphs than the score model. Loading (or creating if not existing) the data for the confidence model now.\n",
            "Reading molecules and generating local structures with RDKit\n",
            "100% 1/1 [00:00<00:00, 24.81it/s]\n",
            "Reading language model embeddings.\n",
            "Generating graphs for ligands and proteins\n",
            "loading complexes: 100% 1/1 [00:00<00:00,  2.26it/s]\n",
            "loading data from memory:  data/cache_torsion_allatoms/limit0_INDEX_maxLigSizeNone_H0_recRad15.0_recMax24_atomRad5_atomMax8_esmEmbeddings3387508103/heterographs.pkl\n",
            "Number of complexes:  1\n",
            "radius protein: mean 35.130279541015625, std 0.0, max 35.130279541015625\n",
            "radius molecule: mean 6.1557817459106445, std 0.0, max 6.1557817459106445\n",
            "distance protein-mol: mean 39.21901321411133, std 0.0, max 39.21901321411133\n",
            "rmsd matching: mean 0.0, std 0.0, max 0\n",
            "/usr/local/lib/python3.10/dist-packages/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
            "  warnings.warn(\"The TorchScript type system doesn't support \"\n",
            "common t schedule [1.   0.95 0.9  0.85 0.8  0.75 0.7  0.65 0.6  0.55 0.5  0.45 0.4  0.35\n",
            " 0.3  0.25 0.2  0.15 0.1  0.05]\n",
            "Size of test dataset:  1\n",
            "1it [00:41, 41.03s/it]\n",
            "Failed for 0 complexes\n",
            "Skipped 0 complexes\n",
            "Results are in /content/DiffDock/results/user_predictions_small\n",
            "0.009  %\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2570.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2706.\n",
            "  warnings.warn(\n",
            "100% 1/1 [00:00<00:00, 27.02it/s]\n",
            "Transferred model to GPU\n",
            "Read /content/DiffDock/data/prepared_for_esm.fasta with 2 sequences\n",
            "Processing 1 of 1 batches (2 sequences)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DiffDock/inference.py\", line 16, in <module>\n",
            "    from datasets.pdbbind import PDBBind\n",
            "  File \"/content/DiffDock/datasets/pdbbind.py\", line 22, in <module>\n",
            "    from utils.utils import read_strings_from_txt\n",
            "  File \"/content/DiffDock/utils/utils.py\", line 14, in <module>\n",
            "    from models.all_atom_score_model import TensorProductScoreModel as AAScoreModel\n",
            "  File \"/content/DiffDock/models/all_atom_score_model.py\", line 9, in <module>\n",
            "    from models.score_model import AtomEncoder, TensorProductConvLayer, GaussianSmearing\n",
            "  File \"/content/DiffDock/models/score_model.py\", line 12, in <module>\n",
            "    from utils import so3, torus\n",
            "  File \"/content/DiffDock/utils/torus.py\", line 71, in <module>\n",
            "    score_norm_ = score(\n",
            "  File \"/content/DiffDock/utils/torus.py\", line 49, in score\n",
            "    sigma = (sigma - np.log(SIGMA_MIN)) / (np.log(SIGMA_MAX) - np.log(SIGMA_MIN)) * SIGMA_N\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "0.019  %\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2570.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2706.\n",
            "  warnings.warn(\n",
            "100% 1/1 [00:00<00:00, 25.75it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DiffDock/esm/scripts/extract.py\", line 137, in <module>\n",
            "    main(args)\n",
            "  File \"/content/DiffDock/esm/scripts/extract.py\", line 64, in main\n",
            "    model, alphabet = pretrained.load_model_and_alphabet(args.model_location)\n",
            "  File \"/content/DiffDock/esm/esm/pretrained.py\", line 28, in load_model_and_alphabet\n",
            "    return load_model_and_alphabet_hub(model_name)\n",
            "  File \"/content/DiffDock/esm/esm/pretrained.py\", line 63, in load_model_and_alphabet_hub\n",
            "    model_data, regression_data = _download_model_and_regression_data(model_name)\n",
            "  File \"/content/DiffDock/esm/esm/pretrained.py\", line 54, in _download_model_and_regression_data\n",
            "    model_data = load_hub_workaround(url)\n",
            "  File \"/content/DiffDock/esm/esm/pretrained.py\", line 33, in load_hub_workaround\n",
            "    data = torch.hub.load_state_dict_from_url(url, progress=False, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/hub.py\", line 750, in load_state_dict_from_url\n",
            "    return torch.load(cached_file, map_location=map_location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 809, in load\n",
            "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1172, in _load\n",
            "    result = unpickler.load()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1142, in persistent_load\n",
            "    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1112, in load_tensor\n",
            "    storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DiffDock/inference.py\", line 10, in <module>\n",
            "    import pandas as pd\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/__init__.py\", line 22, in <module>\n",
            "    from pandas.compat import is_numpy_dev as _is_numpy_dev  # pyright: ignore # noqa:F401\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/compat/__init__.py\", line 22, in <module>\n",
            "    from pandas.compat.pyarrow import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
            "    import pyarrow as pa\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyarrow/__init__.py\", line 65, in <module>\n",
            "    import pyarrow.lib as _lib\n",
            "  File \"<frozen importlib._bootstrap>\", line 404, in parent\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "0.029  %\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2570.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 2706.\n",
            "  warnings.warn(\n",
            "100% 1/1 [00:00<00:00, 24.41it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DiffDock/esm/scripts/extract.py\", line 137, in <module>\n",
            "    main(args)\n",
            "  File \"/content/DiffDock/esm/scripts/extract.py\", line 64, in main\n",
            "    model, alphabet = pretrained.load_model_and_alphabet(args.model_location)\n",
            "  File \"/content/DiffDock/esm/esm/pretrained.py\", line 28, in load_model_and_alphabet\n",
            "    return load_model_and_alphabet_hub(model_name)\n",
            "  File \"/content/DiffDock/esm/esm/pretrained.py\", line 63, in load_model_and_alphabet_hub\n",
            "    model_data, regression_data = _download_model_and_regression_data(model_name)\n",
            "  File \"/content/DiffDock/esm/esm/pretrained.py\", line 54, in _download_model_and_regression_data\n",
            "    model_data = load_hub_workaround(url)\n",
            "  File \"/content/DiffDock/esm/esm/pretrained.py\", line 33, in load_hub_workaround\n",
            "    data = torch.hub.load_state_dict_from_url(url, progress=False, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/hub.py\", line 750, in load_state_dict_from_url\n",
            "    return torch.load(cached_file, map_location=map_location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 809, in load\n",
            "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1172, in _load\n",
            "    result = unpickler.load()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1142, in persistent_load\n",
            "    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1112, in load_tensor\n",
            "    storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# get top DiffDock poses\n",
        "top_diffdock_poses = get_top_poses('/content/drive/MyDrive/Generative_ML/data/molgpt_generated_nocond_06_10_fintetune2.csv',\n",
        "                                   '/content/drive/MyDrive/Generative_ML/data/6o56.pdb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME15L20kCol2"
      },
      "outputs": [],
      "source": [
        "# write list of file paths to txt file\n",
        "with open('/content/drive/MyDrive/Generative_ML/diffdock_poses.txt', 'w') as file:\n",
        "    for path in top_diffdock_poses:\n",
        "        file.write(path + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Active learning based on pseudo protein-ligand binding energy"
      ],
      "metadata": {
        "id": "veWeIgUNtYxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set up notebook"
      ],
      "metadata": {
        "id": "Tamyd6Hstkpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "import condacolab\n",
        "\n",
        "!mamba install pymol-open-source --yes\n",
        "\n",
        "!pip install prolif\n",
        "!pip install rdkit\n",
        "\n",
        "from pymol import cmd\n",
        "import prolif\n",
        "from prolif.plotting.network import LigNetwork\n",
        "from rdkit import Chem\n",
        "from IPython.display import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gjg__oTktYHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1407854-17f9-4b2f-f06e-96acf4eca70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m✨🍰✨ Everything looks OK!\n",
            "\n",
            "                  __    __    __    __\n",
            "                 /  \\  /  \\  /  \\  /  \\\n",
            "                /    \\/    \\/    \\/    \\\n",
            "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
            "              /  / \\   / \\   / \\   / \\  \\____\n",
            "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
            "            / _/                       \\_____/  `\n",
            "            |/\n",
            "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
            "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
            "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
            "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
            "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
            "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
            "\n",
            "        mamba (1.4.1) supported by @QuantStack\n",
            "\n",
            "        GitHub:  https://github.com/mamba-org/mamba\n",
            "        Twitter: https://twitter.com/QuantStack\n",
            "\n",
            "█████████████████████████████████████████████████████████████\n",
            "\n",
            "\n",
            "Looking for: ['pymol-open-source']\n",
            "\n",
            "conda-forge/linux-64                                        Using cache\n",
            "conda-forge/noarch                                          Using cache\n",
            "\n",
            "Pinned packages:\n",
            "  - python 3.10.*\n",
            "  - python 3.10.*\n",
            "  - python_abi 3.10.* *cp310*\n",
            "  - cudatoolkit 11.8.*\n",
            "\n",
            "\n",
            "Transaction\n",
            "\n",
            "  Prefix: /usr/local\n",
            "\n",
            "  All requested packages already installed\n",
            "\n",
            "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25hRequirement already satisfied: prolif in /usr/local/lib/python3.10/site-packages (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from prolif) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/site-packages (from prolif) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/site-packages (from prolif) (1.25.0)\n",
            "Requirement already satisfied: mdanalysis>=2.2.0 in /usr/local/lib/python3.10/site-packages (from prolif) (2.5.0)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.10/site-packages (from prolif) (1.11.1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (1.3.1)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (0.18)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (3.1)\n",
            "Requirement already satisfied: gsd>=1.9.3 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (3.0.1)\n",
            "Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (1.81)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (23.1)\n",
            "Requirement already satisfied: GridDataFormats>=0.4.0 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (3.1.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (3.7.2)\n",
            "Requirement already satisfied: mmtf-python>=1.0.0 in /usr/local/lib/python3.10/site-packages (from mdanalysis>=2.2.0->prolif) (1.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0.0->prolif) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0.0->prolif) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0.0->prolif) (2.8.2)\n",
            "Requirement already satisfied: mrcfile in /usr/local/lib/python3.10/site-packages (from GridDataFormats>=0.4.0->mdanalysis>=2.2.0->prolif) (1.4.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (1.1.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (10.0.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (4.40.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.5.1->mdanalysis>=2.2.0->prolif) (0.11.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/site-packages (from mmtf-python>=1.0.0->mdanalysis>=2.2.0->prolif) (1.0.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->prolif) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: rdkit in /usr/local/lib/python3.10/site-packages (2023.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit) (1.25.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from rdkit) (10.0.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mMounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Count connections"
      ],
      "metadata": {
        "id": "F04vDvgVps1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_scores = {\n",
        "    'Hydrophobic': -2.5,\n",
        "    'HBDonor': -3.5,\n",
        "    'HBAcceptor': -3.5,\n",
        "    'Anionic': -7.5,\n",
        "    'Cationic': -7.5,\n",
        "    'CationPi': -2.5,\n",
        "    'PiCation': -2.5,\n",
        "    'VdWContact': -1.0,\n",
        "    'XBAcceptor': -3.0,\n",
        "    'XBDonor': -3.0,\n",
        "    'FaceToFace': -3.0,\n",
        "    'EdgeToFace': -1.0,\n",
        "    'MetalDonor': -3.0,\n",
        "    'MetalAcceptor': -3.0,\n",
        "}\n",
        "\n",
        "def get_contacts(protein, ligand):\n",
        "  cmd.delete('all')\n",
        "  cmd.load(protein, 'protein')\n",
        "  cmd.h_add('protein')\n",
        "  cmd.remove('sol')\n",
        "  cmd.save('/content/protein.pdb')\n",
        "\n",
        "  prot = prolif.Molecule(Chem.MolFromPDBFile('/content/protein.pdb', removeHs=False))\n",
        "  lig = Chem.SDMolSupplier(ligand, removeHs=False)\n",
        "  lig = prolif.Molecule.from_rdkit(lig[0])\n",
        "\n",
        "  fp = prolif.Fingerprint(interactions=list(interaction_scores.keys()))\n",
        "  fp.run_from_iterable([lig], prot, progress=False)\n",
        "  try:\n",
        "    df = fp.to_dataframe(return_atoms=True)\n",
        "    df_stacked = df.stack(level=[0, 1, 2])\n",
        "    df_reset = df_stacked.to_frame().reset_index()\n",
        "    df_reset.columns = ['Frame', 'ligand', 'protein', 'interaction', 'value']\n",
        "    df_reset['score'] = df_reset['interaction'].apply(lambda x: interaction_scores[x])\n",
        "    return df_reset['score'].sum()\n",
        "  except:\n",
        "    print('Complex has no meaningful protein-ligand connections')\n",
        "    return int(0)"
      ],
      "metadata": {
        "id": "xhu7U2OSps1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "ligand_list = []\n",
        "for i in os.listdir('/content/drive/MyDrive/Generative_ML/best_poses/'):\n",
        "    comp_num = str(i)\n",
        "    for j in os.listdir('/content/drive/MyDrive/Generative_ML/best_poses/' + comp_num):\n",
        "        if j.startswith('index0'):\n",
        "            ligand_list.append('/content/drive/MyDrive/Generative_ML/best_poses/' + comp_num + '/' + j + '/' + 'rank1.sdf')"
      ],
      "metadata": {
        "id": "hkmoW9MvqfrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymol import cmd\n",
        "import prolif\n",
        "from rdkit import Chem\n",
        "count = 0\n",
        "good_ligands = {}\n",
        "for i in ligand_list:\n",
        "    if i.split('/')[6].split('.')[0] not in good_ligands:\n",
        "        score = get_contacts('/content/drive/MyDrive/Generative_ML/data/HNH.pdb', i)\n",
        "        good_ligands[i.split('/')[6].split('.')[0]] = score\n",
        "        count += 1\n",
        "        if int(count%(len(ligand_list)/100)) == 0:\n",
        "            print(int(count/len(ligand_list)*100), ' %')"
      ],
      "metadata": {
        "id": "gzmdwfnjsqDZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "652eb1f9-6cb0-45b0-afe5-f621e6af1344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complex has no meaningful protein-ligand connections\n",
            "Complex has no meaningful protein-ligand connections\n",
            "1  %\n",
            "Complex has no meaningful protein-ligand connections\n",
            "Complex has no meaningful protein-ligand connections\n",
            "Complex has no meaningful protein-ligand connections\n",
            "Complex has no meaningful protein-ligand connections\n",
            "2  %\n",
            "Complex has no meaningful protein-ligand connections\n",
            "Complex has no meaningful protein-ligand connections\n",
            "Complex has no meaningful protein-ligand connections\n",
            "Complex has no meaningful protein-ligand connections\n",
            "3  %\n",
            "Complex has no meaningful protein-ligand connections\n",
            "Complex has no meaningful protein-ligand connections\n",
            "Complex has no meaningful protein-ligand connections\n",
            "4  %\n",
            "Complex has no meaningful protein-ligand connections\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-54e89ac97f96>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mligand_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgood_ligands\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_contacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Generative_ML/data/HNH.pdb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mgood_ligands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b65ce9820386>\u001b[0m in \u001b[0;36mget_contacts\u001b[0;34m(protein, ligand)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mprot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprolif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolecule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolFromPDBFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/protein.pdb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoveHs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mlig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSDMolSupplier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mligand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoveHs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mlig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprolif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolecule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_rdkit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_ligands = {k: v for k, v in sorted(good_ligands.items(), key=lambda item: item[1])}"
      ],
      "metadata": {
        "id": "AkXG7o9H8r_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gaussian_kde\n",
        "import numpy as np\n",
        "\n",
        "data = list(sorted_ligands.values())\n",
        "\n",
        "plt.figure(figsize=(8, 6), dpi=80)\n",
        "\n",
        "plt.hist(data, bins=50, density=True, color='gray', alpha=0.7, edgecolor='black')\n",
        "\n",
        "smoothed_data = np.linspace(min(data), max(data), 1000)\n",
        "kde = gaussian_kde(data)\n",
        "smoothed_line = kde(smoothed_data)\n",
        "\n",
        "plt.plot(smoothed_data, smoothed_line, linewidth=2.5, color='black')\n",
        "\n",
        "plt.xlabel(\"Values\", fontsize=18)\n",
        "plt.ylabel(\"Density\", fontsize=18)\n",
        "\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "\n",
        "plt.title(\"Density Plot of Scores\", fontsize=20)\n",
        "\n",
        "plt.grid(linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "\n",
        "plt.tick_params(axis='both', which='both', direction='in', length=4)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(f'There are {list(sorted_ligands.values()).count(0)} ligands with 0 connections ({np.round(list(sorted_ligands.values()).count(0) / len(sorted_ligands)*100, 1)}%)')\n",
        "print(f'There are {len([value for value in list(sorted_ligands.values()) if value < -10.0])} ligands with scores less than -10.0 ({np.round(len([value for value in list(sorted_ligands.values()) if value < -10.0]) / len(sorted_ligands)*100, 1)}%)')\n",
        "print(f'The mean score for all ligands is {np.round(np.mean(list(sorted_ligands.values())), 1)}')\n",
        "print(f'The lowest score for all ligands is {np.min(list(sorted_ligands.values()))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "JIG6BZpeAYH1",
        "outputId": "84545fdc-f326-44bf-9a79-8fd50d510207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 14 ligands with 0 connections (42.4%)\n",
            "There are 5 ligands with scores less than -10.0 (15.2%)\n",
            "The mean score for all ligands is -4.4\n",
            "The lowest score for all ligands is -18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_ligands = {key: value for key, value in sorted_ligands.items() if value != 0}"
      ],
      "metadata": {
        "id": "WgnUcM4DwKpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good_idx = [k[7:] for k in good_ligands if k.startswith('complex')]"
      ],
      "metadata": {
        "id": "bgLp7SfIEa1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "diffdock_input = pd.read_csv('/content/drive/MyDrive/Generative_ML/current_data/mols_sampled_for_difdock_07_07.csv')"
      ],
      "metadata": {
        "id": "rbHputaPw1Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good_data = diffdock_input.iloc[good_idx]"
      ],
      "metadata": {
        "id": "7IUOuhmAxsVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good_data['score'] = [good_ligands.get(f'complex{complex_number}', 0) for complex_number in good_data.index]"
      ],
      "metadata": {
        "id": "fSiSFTlIE6HM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3a2018-0103-4932-fc29-f4bf1fcfd5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-3e5ec29e2571>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  good_data['score'] = [good_ligands.get(f'complex{complex_number}', 0) for complex_number in good_data.index]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "RjRBxwuKx8jb",
        "outputId": "cdbf96fd-109e-412f-ae58-49bc89d5b1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0                                            smiles  cluster_id  \\\n",
              "3            3                 CSc1nnc(SCC(=O)Nc2cc(C)cc(C)c2)s1          21   \n",
              "29          29     CN(C(=O)COC(=O)CC12CC3CC(CC(C3)C1)C2)c1ccccc1          31   \n",
              "0            0              CCn1cc(C(=O)NCC2C(=O)N=C(C)C=C2C)cn1          54   \n",
              "4            4                   CSc1nnc(SCC(=O)Nc2ccnn2C(C)C)s1          21   \n",
              "27          27        CC1(C)CCC2(C)C(CC3CCC2C(O)C(N2CCOCC2)C3)N1          31   \n",
              "7            7                       CSc1nnc(SCC(=O)N(C)C(C)C)s1          21   \n",
              "13          13                CCN1CCN(C2=NS(=O)(=O)c3ccccc32)CC1          92   \n",
              "18          18                 Nc1ccc2c(c1)N=C(Nc1ccc(F)cc1F)CO2          92   \n",
              "32          32                  C#CCN1CCN(CC=Cc2ccc(Cl)cc2)CC1=O          75   \n",
              "17          17          CCN(C(=O)CCNC1=NS(=O)(=O)c2ccccc21)C1CC1          92   \n",
              "22          22         O=C(c1ccc(S(=O)(=O)NC2CC2)cc1)C1CC2CCC1C2          31   \n",
              "2            2                 CC1=CC(C)=NC(=O)C1CNC(=O)NCCC(C)C          54   \n",
              "11          11                CCNC(=O)N1CCN=C1c1ccc(C(F)(F)F)cc1          92   \n",
              "31          31              C#CCN1CCN(CC(=O)N(C)Cc2cccc(C)c2)CC1          75   \n",
              "25          25          Cc1nnc(NC(=O)C23CC4CC(CC(Cl)(C4)C2)C3)s1          31   \n",
              "28          28        O=C(CNC(=O)CC12CC3CC(CC(C3)C1)C2)NCc1ccco1          31   \n",
              "5            5                  CSc1nnc(SCCCC(=O)Nc2ccc(C)cc2)s1          21   \n",
              "26          26  CC(C)(C)n1ncc(C(=O)NC23CC4CC(CC(C4)C2)C3)c1C1CC1          31   \n",
              "19          19                 CCOC(=O)C1CCN(C2=NCC3=NC=NC32)CC1          92   \n",
              "\n",
              "    score  \n",
              "3   -18.0  \n",
              "29  -14.0  \n",
              "0   -12.5  \n",
              "4   -10.5  \n",
              "27  -10.5  \n",
              "7   -10.0  \n",
              "13   -9.0  \n",
              "18   -8.5  \n",
              "32   -7.5  \n",
              "17   -7.0  \n",
              "22   -6.5  \n",
              "2    -5.5  \n",
              "11   -4.5  \n",
              "31   -4.5  \n",
              "25   -4.0  \n",
              "28   -4.0  \n",
              "5    -3.5  \n",
              "26   -3.5  \n",
              "19   -2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef9a7df9-6899-4b8b-95a9-42be1a73c2cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>smiles</th>\n",
              "      <th>cluster_id</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CSc1nnc(SCC(=O)Nc2cc(C)cc(C)c2)s1</td>\n",
              "      <td>21</td>\n",
              "      <td>-18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>CN(C(=O)COC(=O)CC12CC3CC(CC(C3)C1)C2)c1ccccc1</td>\n",
              "      <td>31</td>\n",
              "      <td>-14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CCn1cc(C(=O)NCC2C(=O)N=C(C)C=C2C)cn1</td>\n",
              "      <td>54</td>\n",
              "      <td>-12.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CSc1nnc(SCC(=O)Nc2ccnn2C(C)C)s1</td>\n",
              "      <td>21</td>\n",
              "      <td>-10.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>CC1(C)CCC2(C)C(CC3CCC2C(O)C(N2CCOCC2)C3)N1</td>\n",
              "      <td>31</td>\n",
              "      <td>-10.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>CSc1nnc(SCC(=O)N(C)C(C)C)s1</td>\n",
              "      <td>21</td>\n",
              "      <td>-10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>CCN1CCN(C2=NS(=O)(=O)c3ccccc32)CC1</td>\n",
              "      <td>92</td>\n",
              "      <td>-9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>Nc1ccc2c(c1)N=C(Nc1ccc(F)cc1F)CO2</td>\n",
              "      <td>92</td>\n",
              "      <td>-8.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>C#CCN1CCN(CC=Cc2ccc(Cl)cc2)CC1=O</td>\n",
              "      <td>75</td>\n",
              "      <td>-7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>CCN(C(=O)CCNC1=NS(=O)(=O)c2ccccc21)C1CC1</td>\n",
              "      <td>92</td>\n",
              "      <td>-7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>O=C(c1ccc(S(=O)(=O)NC2CC2)cc1)C1CC2CCC1C2</td>\n",
              "      <td>31</td>\n",
              "      <td>-6.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CC1=CC(C)=NC(=O)C1CNC(=O)NCCC(C)C</td>\n",
              "      <td>54</td>\n",
              "      <td>-5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>CCNC(=O)N1CCN=C1c1ccc(C(F)(F)F)cc1</td>\n",
              "      <td>92</td>\n",
              "      <td>-4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>C#CCN1CCN(CC(=O)N(C)Cc2cccc(C)c2)CC1</td>\n",
              "      <td>75</td>\n",
              "      <td>-4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>Cc1nnc(NC(=O)C23CC4CC(CC(Cl)(C4)C2)C3)s1</td>\n",
              "      <td>31</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>O=C(CNC(=O)CC12CC3CC(CC(C3)C1)C2)NCc1ccco1</td>\n",
              "      <td>31</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>CSc1nnc(SCCCC(=O)Nc2ccc(C)cc2)s1</td>\n",
              "      <td>21</td>\n",
              "      <td>-3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>CC(C)(C)n1ncc(C(=O)NC23CC4CC(CC(C4)C2)C3)c1C1CC1</td>\n",
              "      <td>31</td>\n",
              "      <td>-3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>CCOC(=O)C1CCN(C2=NCC3=NC=NC32)CC1</td>\n",
              "      <td>92</td>\n",
              "      <td>-2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef9a7df9-6899-4b8b-95a9-42be1a73c2cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef9a7df9-6899-4b8b-95a9-42be1a73c2cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef9a7df9-6899-4b8b-95a9-42be1a73c2cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare training dataset for next round of active learning"
      ],
      "metadata": {
        "id": "oUjA5PGgZbQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_to_scores = {}\n",
        "for index, row in good_data.iterrows():\n",
        "    cluster_to_scores.setdefault(row['cluster_id'], []).append(row['score'])\n",
        "cluster_to_score = {cluster_id: np.mean(scores) for cluster_id, scores in cluster_to_scores.items()}\n",
        "import random\n",
        "cluster_to_score = {k: random.uniform(-20, 0) for k in range(50)}\n",
        "print(cluster_to_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QweC9J9fTYd7",
        "outputId": "13f1c990-c8b4-46b1-a695-b1becf67be3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: -3.5737377362409006, 1: -8.718192248431691, 2: -1.008055413616347, 3: -0.17262907181792642, 4: -12.523850246754067, 5: -7.547771673957747, 6: -7.628253245643318, 7: -14.527801647759148, 8: -11.461913127296198, 9: -6.151128991058384, 10: -5.157594304580595, 11: -4.5162917941753555, 12: -14.443278978981928, 13: -3.300100778045149, 14: -0.06212197988290313, 15: -19.33983402983262, 16: -16.183523634152124, 17: -15.236976243081195, 18: -10.183579128555051, 19: -10.521743173056981, 20: -15.110941716166453, 21: -14.028069644127445, 22: -8.775790816747804, 23: -6.3572715143124565, 24: -1.583702380815165, 25: -6.4849547167075166, 26: -5.087021416627703, 27: -15.135958548287507, 28: -7.832652513644689, 29: -16.014180818241105, 30: -9.57682582787827, 31: -6.973395225398891, 32: -5.925609813801529, 33: -18.46974273617391, 34: -3.393362868448648, 35: -10.754453045853754, 36: -10.360957982345965, 37: -16.34269008463877, 38: -5.823249532349635, 39: -1.071095804441967, 40: -13.175421222580324, 41: -5.302613018323413, 42: -5.080576977894058, 43: -18.412525983742242, 44: -2.147544330211417, 45: -10.704283291067622, 46: -3.37159735944703, 47: -3.44999579730149, 48: -7.780742608265427, 49: -1.2815766834743698}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we need to map the good data back to the original clusters and create a training set for active learning. THen, perform active learning, generate molecules, and repeat process. Finally, generate 2 million molecules to train BERT"
      ],
      "metadata": {
        "id": "TQ9BaRa8GyK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def _preprocess_scores_uniformly(scores, remove_positives=False, lowest_score=1):\n",
        "    \"\"\"\n",
        "        Preprocesses a dictionary of scores by negating and normalizing them.\n",
        "\n",
        "        The function negates all scores and optionally removes positive scores. If the minimum value among the negated scores\n",
        "        is less than zero, it shifts all values by subtracting the minimum value and adding 'lowest_score'. The final step is\n",
        "        to normalize the scores so that their total sum equals to 1.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        scores : dict\n",
        "            A dictionary of scores where the keys are identifiers and the values are their corresponding scores.\n",
        "\n",
        "        remove_positives : bool, optional (default=False)\n",
        "            If True, all positive scores are removed after negation.\n",
        "\n",
        "        lowest_score : int, optional (default=1)\n",
        "            This value is added to all scores if the minimum score is less than zero.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        normalized : dict\n",
        "            The normalized dictionary of scores.\n",
        "\n",
        "    \"\"\"\n",
        "    negated = {k: -v for k, v in scores.items()}\n",
        "    min_value = min(negated.values())\n",
        "    if min_value < 0:\n",
        "        if remove_positives:\n",
        "            negated = {k: v for k, v in negated.items() if v > 0}\n",
        "        else:\n",
        "            negated = {k: v - min_value + lowest_score for k, v in negated.items()}\n",
        "    total = sum(negated.values())\n",
        "    normalized = {k: v / total for k, v in negated.items()}\n",
        "    return normalized\n",
        "\n",
        "def _preprocess_scores_softmax(scores):\n",
        "    negated = {k: -v for k, v in scores.items()}\n",
        "    max_value = max(negated.values())\n",
        "    exponentiate = {k: np.exp(v - max_value) for k, v in negated.items()}\n",
        "    total = sum(exponentiate.values())\n",
        "    softmax = {k: v / total for k, v in exponentiate.items()}\n",
        "    return softmax\n",
        "\n",
        "def balance_cluster_to_n(cluster_to_n, cluster_to_len):\n",
        "    \"\"\"\n",
        "        Balances the target number of samples for each cluster to ensure it doesn't exceed the actual size of the cluster.\n",
        "\n",
        "        The function first calculates the surplus (i.e., the excess of the target number over the actual size) for each cluster.\n",
        "        Then, it distributes the total surplus proportionally among the clusters that have a deficit (i.e., the target number is less than the actual size).\n",
        "        If after this distribution, there's still a deficit (i.e., the sum of target numbers is less than the sum of actual sizes), the function\n",
        "        increases the target number of the largest clusters one by one until the sum of target numbers equals to the sum of actual sizes.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cluster_to_n : dict\n",
        "            A dictionary mapping cluster identifiers to their target number of samples.\n",
        "\n",
        "        cluster_to_len : dict\n",
        "            A dictionary mapping cluster identifiers to the actual size of each cluster.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        balanced : dict\n",
        "            A dictionary mapping cluster identifiers to their balanced target number of samples.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        AssertionError\n",
        "            If the sum of target numbers before and after balancing don't match.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    surplus = {key: cluster_to_n[key] - cluster_to_len[key] for key in cluster_to_n if cluster_to_n[key] > cluster_to_len[key]}\n",
        "    balanced = {k:v for k, v in cluster_to_n.items()}\n",
        "    n_to_cluster = {v: k for k, v in cluster_to_n.items()}\n",
        "\n",
        "    for key in surplus:\n",
        "        balanced[key] = cluster_to_len[key]\n",
        "\n",
        "    total_surplus = sum(surplus.values())\n",
        "    initial_n_sum = sum(n for key, n in cluster_to_n.items() if key not in surplus)\n",
        "\n",
        "    for key in balanced:\n",
        "        if key in surplus: continue\n",
        "        surplus_to_add = total_surplus * cluster_to_n[key] / initial_n_sum\n",
        "        new_n = int(cluster_to_n[key] + surplus_to_add)\n",
        "        balanced[key] = min(new_n, cluster_to_len[key])\n",
        "\n",
        "    deficit = sum(cluster_to_n.values()) - sum(balanced.values())\n",
        "    while deficit > 0:\n",
        "        for initial_n in sorted(n_to_cluster, reverse=True):\n",
        "            if deficit == 0:\n",
        "                break\n",
        "            if (cluster:=n_to_cluster[initial_n]) in surplus: continue\n",
        "            if balanced[cluster] < cluster_to_len[cluster]:\n",
        "                balanced[cluster] += 1\n",
        "                deficit -= 1\n",
        "\n",
        "    assert sum(cluster_to_n.values()) == sum(balanced.values()), f\"Before balancing had {sum(cluster_to_n.values())}, post balancing = {sum(balanced.values())}\"\n",
        "    return balanced\n",
        "\n",
        "def sample_clusters_for_active_learning(cluster_to_scores, n_samples, path_to_clusters, probability_type='softmax', remove_positives=False, lowest_score=1):\n",
        "    \"\"\"\n",
        "        Sample molecules from clusters for active learning purposes, considering previously docked molecules and balancing the sampling among clusters.\n",
        "\n",
        "        This function uses either softmax or uniform probabilities to determine how many molecules to sample from each cluster. The function then samples\n",
        "        the required number of new molecules (i.e., those not present in docked_mols) from each cluster. The sampling is balanced to ensure the target number\n",
        "        doesn't exceed the actual size of the cluster.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cluster_to_scores : dict\n",
        "            A dictionary mapping cluster identifiers to their scores.\n",
        "\n",
        "        n_samples : int\n",
        "            The total number of molecules to sample.\n",
        "\n",
        "        path_to_clusters : str\n",
        "            The path to a pickle file storing a dictionary that maps each cluster to a list of molecules.\n",
        "\n",
        "        probability_type : str, optional (default='softmax')\n",
        "            The type of probability distribution used to determine the number of samples per cluster.\n",
        "            Options are 'softmax' and 'uniform'.\n",
        "\n",
        "        remove_positives : bool, optional (default=False)\n",
        "            Only used when probability_type is 'uniform'. If True, positive scores are removed after negation.\n",
        "\n",
        "        lowest_score : int, optional (default=1)\n",
        "            Only used when probability_type is 'uniform'. This value is added to all scores if the minimum score is less than zero.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        training : list\n",
        "            A list of randomly sampled molecules for active learning.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        KeyError\n",
        "            If an unsupported probability_type is provided.\n",
        "        AssertionError\n",
        "            If the number of sampled molecules doesn't equal to n_samples.\n",
        "\n",
        "    \"\"\"\n",
        "    if probability_type == 'softmax':\n",
        "        probability_function = _preprocess_scores_softmax\n",
        "    elif probability_type == 'uniform':\n",
        "        probability_function = lambda x: _preprocess_scores_uniformly(x, remove_positives, lowest_score)\n",
        "    else:\n",
        "        raise KeyError(\"Only uniform and softmax probabilities are supported\")\n",
        "    cluster_to_mols = pickle.load(open(path_to_clusters, 'rb'))\n",
        "    cluster_to_samples = pickle.load(open(path_to_clusters.split('.')[0] + '_samples.pickle', 'rb'))\n",
        "    docked_mols = {smile for smiles in cluster_to_samples.values() for smile in smiles}\n",
        "    cluster_to_new_mols = {k: [smile for smile in v if smile not in docked_mols] for k, v in cluster_to_mols.items()}\n",
        "\n",
        "    probabilities = probability_function(cluster_to_scores)\n",
        "    cluster_to_n = {k: int(v * n_samples) for k, v in probabilities.items()}\n",
        "    max_cluster_id, max_prob = None, 0\n",
        "    for cluster, prob in probabilities.items():\n",
        "        if prob > max_prob:\n",
        "            max_cluster_id, max_prob = cluster, prob\n",
        "    cluster_to_n[max_cluster_id] += n_samples - sum(cluster_to_n.values())\n",
        "\n",
        "    cluster_to_len = {k: len(v) for k, v in cluster_to_new_mols.items()}\n",
        "    balanced = balance_cluster_to_n(cluster_to_n, cluster_to_len)\n",
        "\n",
        "    training = []\n",
        "    for i, (cluster, n) in enumerate(balanced.items()):\n",
        "        training.extend(random.sample(cluster_to_new_mols[cluster], n))\n",
        "    assert len(training) == n_samples, f\"{len(training)=} != {n_samples=}\"\n",
        "    return training\n",
        "\n",
        "training_sampled = sample_clusters_for_active_learning(cluster_to_score, n_samples=1000, probability_type='uniform', path_to_clusters= '/content/drive/MyDrive/Generative_ML/current_data/cluster_to_samples_07_07.pickle')\n"
      ],
      "metadata": {
        "id": "84XMCXxAQyfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_sampled_and_good_ligands(sampled, good_ligands, good_ligand_multiplier:int, save_path):\n",
        "    # assert isinstance(good_ligand_multiplier, int), \"A multiplier should be an integer\"\n",
        "    keyToData = {}\n",
        "    for mol in sampled:\n",
        "        keyToData.setdefault('smiles', []).append(mol)\n",
        "    for mol in good_ligands:\n",
        "        for _ in range(good_ligand_multiplier):\n",
        "            keyToData.setdefault('smiles', []).append(mol)\n",
        "    pd.DataFrame(keyToData).to_csv(save_path)\n",
        "\n",
        "\n",
        "combine_sampled_and_good_ligands(training_sampled, good_ligands, good_ligand_multiplier=2, save_path='/content/drive/MyDrive/Generative_ML/current_data/active_learning_training.csv')\n",
        "pd.read_csv('/content/drive/MyDrive/Generative_ML/current_data/active_learning_training.csv').shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFY3C94tXbki",
        "outputId": "f2c60b17-8c77-4933-f92f-4200ad9462ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1038, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now train and generate"
      ],
      "metadata": {
        "id": "BkPN4kOAZU6_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CXn_Jqt_76M"
      },
      "source": [
        "#BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJqiexX6AAsv"
      },
      "source": [
        "##Set up notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A23L1dGiAO0V"
      },
      "outputs": [],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# install necessary packages\n",
        "!pip install rdkit\n",
        "!pip install pandas==1.5.3\n",
        "!pip install molsets\n",
        "!pip install wandb\n",
        "\n",
        "# clone Sophia optimizer GitHub repository\n",
        "!git clone https://github.com/Liuhong99/Sophia.git\n",
        "\n",
        "# import necessary packages\n",
        "import numpy as np\n",
        "import h5py\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, pairwise_distances\n",
        "import os\n",
        "import random\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import pkg_resources\n",
        "pkg_resources.require(\"pandas==1.5.3\")\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import logging\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import QED, Crippen\n",
        "from rdkit.Contrib.SA_Score import sascorer\n",
        "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
        "from rdkit.Chem.Fingerprints import FingerprintMols\n",
        "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity\n",
        "from rdkit.Chem.Scaffolds.MurckoScaffold import MurckoScaffoldSmiles\n",
        "import moses\n",
        "from moses.utils import get_mol\n",
        "from Sophia.sophia import SophiaG\n",
        "import yaml\n",
        "\n",
        "# set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gbEP-i0Av6M"
      },
      "source": [
        "##Utils & Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FK7qHr5Axl3"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def sample(model, x, steps, temperature=1.0, prop=None, scaffold=None):\n",
        "    block_size = model.get_block_size() # define size of context window used for input conditioning\n",
        "    model.eval()\n",
        "    for k in range(steps):\n",
        "        x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # limit conditioning input to the most recent block_size elements\n",
        "        logits, _= model(x_cond, prop = prop, scaffold = scaffold) # give input to model and get logits (unnormalized scores or probabilities)\n",
        "        logits = logits[:, -1, :] / temperature # extract the logits for the next token in the sequence\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        ix = torch.multinomial(probs, 1)\n",
        "        x = torch.cat((x, ix), dim=1) # concatenate the chosen token index with the existing sequence\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def fill_mask(model, x, temperature=1.0, prop=None, scaffold=None):\n",
        "    block_size = model.get_block_size()  # Get model's maximum context length\n",
        "    model.eval()\n",
        "\n",
        "    # Check if mask token is present\n",
        "    mask_index = model.config.mask_index  # Assuming 'mask_index' is available in your model's config\n",
        "    while mask_index in x[0]:  # If mask token is present\n",
        "        # Find all mask positions\n",
        "        mask_positions = (x[0] == mask_index).nonzero(as_tuple=True)\n",
        "\n",
        "        for pos in mask_positions:  # Iterate over each mask position\n",
        "            # Limit conditioning input to the most recent block_size elements\n",
        "            x_cond = x if x.size(1) <= block_size else x[:, -block_size:]\n",
        "            # Get token probabilities\n",
        "            logits, _ = model(x_cond, prop=prop, scaffold=scaffold)\n",
        "\n",
        "            # Extract the logits for the masked token position, apply temperature and softmax to get probabilities\n",
        "            logits = logits[0, pos, :] / temperature\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            ix = torch.multinomial(probs, 1)  # Sample token from probability distribution\n",
        "\n",
        "            x[0, pos] = ix  # Replace mask token with sampled token\n",
        "\n",
        "    return x  # Return unmasked tensor\n",
        "\n",
        "def check_novelty(gen_smiles, train_smiles):\n",
        "    if len(gen_smiles) == 0:\n",
        "        novel_ratio = 0\n",
        "    else:\n",
        "        duplicates = [1 for mol in gen_smiles if mol in train_smiles]\n",
        "        novel = len(gen_smiles) - sum(duplicates)\n",
        "        novel_ratio = novel*100/len(gen_smiles)\n",
        "    return novel_ratio\n",
        "\n",
        "def canonic_smiles(smiles_or_mol):\n",
        "    mol = get_mol(smiles_or_mol)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    return Chem.MolToSmiles(mol)\n",
        "\n",
        "class SMILESDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data=None, content=None, block_size=None, prop=None, scaffold=None, scaffold_maxlen=None, len_data=None, mask_prob=0.15):\n",
        "        if content is None:\n",
        "            self.desc_only = True\n",
        "            return\n",
        "        self.desc_only = False\n",
        "        self.chars = sorted(list(set(content)))\n",
        "        data_size, vocab_size = len(content), len(self.chars)\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.stoi = {ch:i for i,ch in enumerate(self.chars)}\n",
        "        self.itos = {i:ch for i,ch in enumerate(self.chars)}\n",
        "        self.max_len = block_size\n",
        "        self.data = data\n",
        "        self.prop = prop\n",
        "        self.sca = scaffold\n",
        "        self.scaf_max_len = scaffold_maxlen\n",
        "        self.len_data = len_data\n",
        "        self.mask_prob = mask_prob\n",
        "\n",
        "        # add X token to vocabulary\n",
        "        self.stoi['X'] = len(self.stoi)\n",
        "        self.itos[len(self.itos)] = 'X'\n",
        "        self.vocab_size = len(self.stoi)\n",
        "\n",
        "    def export_desc_attributes(self, export_path):\n",
        "        attr_dict = {\n",
        "            \"desc_only\": self.desc_only,\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"max_len\": self.max_len,\n",
        "            \"stoi\": self.stoi,\n",
        "            \"itos\": self.itos,\n",
        "            \"scaf_max_len\": self.scaf_max_len,\n",
        "            \"len_data\": self.len_data\n",
        "        }\n",
        "        with open(export_path, 'w') as f:\n",
        "            yaml.dump(attr_dict, f)\n",
        "\n",
        "    def load_desc_attributes(self, load_path):\n",
        "        with open(load_path, 'r') as f:\n",
        "            attr_dict = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "        self.__dict__.update(attr_dict)\n",
        "\n",
        "    def __len__(self):\n",
        "        assert not self.desc_only, \"Dataset is not initialized\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        assert not self.desc_only, \"Dataset is not initialized\"\n",
        "        smiles, prop, scaffold = self.data[idx].strip(), self.prop[idx], self.sca[idx]\n",
        "        if scaffold:\n",
        "          scaffold=scaffold.strip()\n",
        "        pattern =  \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]|X)\"\n",
        "        regex = re.compile(pattern)\n",
        "\n",
        "        #tokenize input string\n",
        "        tokens_arr=regex.findall(smiles)\n",
        "\n",
        "        #Save ground truth encodings before token masking\n",
        "        smiles_true = smiles+str('<')*(self.max_len - len(tokens_arr))\n",
        "        if len(tokens_arr) > self.max_len:\n",
        "            smiles_true = smiles[:self.max_len]\n",
        "        dix_true=[self.stoi[s] for s in regex.findall(smiles_true)]\n",
        "\n",
        "\n",
        "\n",
        "        # randomly replace tokens\n",
        "        mask_idx = [] #True indicates that the corresponding position will be ignored for computing loss\n",
        "        for s in range(len(tokens_arr)):\n",
        "          if random.random() < .15:\n",
        "            mask_idx.append(False)\n",
        "            num = random.random()\n",
        "            if num >= .2: # 80%\n",
        "                tokens_arr[s]='X'\n",
        "            elif num >= 0.1: # 10%\n",
        "                tokens_arr[s] = self.chars[int(random.random()*len(self.chars))]\n",
        "          else:\n",
        "            mask_idx.append(True)\n",
        "\n",
        "        #pad the mask appropriately\n",
        "        while len(mask_idx)<self.max_len:\n",
        "            mask_idx.append(True)\n",
        "\n",
        "        assert len(mask_idx)==self.max_len\n",
        "        smiles=''.join(tokens_arr)\n",
        "\n",
        "        smiles += str('<')*(self.max_len - len(regex.findall(smiles)))\n",
        "        if len(regex.findall(smiles)) > self.max_len:\n",
        "            smiles = smiles[:self.max_len]\n",
        "\n",
        "        assert len(''.join(regex.findall(smiles)))==len(smiles)\n",
        "        smiles=regex.findall(smiles)\n",
        "\n",
        "\n",
        "        dix =  [self.stoi[s] for s in smiles]\n",
        "        if scaffold:\n",
        "          scaffold += str('<')*(self.scaf_max_len - len(regex.findall(scaffold)))\n",
        "          if len(regex.findall(scaffold)) > self.scaf_max_len:\n",
        "              scaffold = scaffold[:self.scaf_max_len]\n",
        "          scaffold=regex.findall(scaffold)\n",
        "          sca_dix = [self.stoi[s] for s in scaffold]\n",
        "          sca_tensor = torch.tensor(sca_dix, dtype=torch.long)\n",
        "        else:\n",
        "          sca_tensor=torch.tensor(scaffold,dtype=torch.bool)\n",
        "        x = torch.tensor(dix, dtype=torch.long)\n",
        "        y = torch.tensor(dix_true, dtype=torch.long)\n",
        "        prop = torch.tensor([prop], dtype=torch.float)\n",
        "        return x, y, prop, sca_tensor, torch.tensor(mask_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXLdZWy9A5Tk"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLo8qZ7yA4SF"
      },
      "outputs": [],
      "source": [
        "class GPTConfig:\n",
        "    def __init__(self, vocab_size=None, block_size=None, mask_index=None, **kwargs):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.block_size = block_size\n",
        "        self.mask_index = mask_index\n",
        "        for k,v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "    def export_attributes(self, export_path):\n",
        "        with open(export_path, 'w') as f:\n",
        "            yaml.dump(vars(self), f)\n",
        "\n",
        "    def load_attributes(self, load_path):\n",
        "        with open(load_path, 'r') as f:\n",
        "            config_dict = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "        self.__dict__.update(config_dict)\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embed % config.n_head == 0\n",
        "        self.config = config\n",
        "\n",
        "        self.query = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n",
        "        self.key = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n",
        "        self.value = nn.Linear(config.n_embed, config.n_embed, bias=config.att_bias)\n",
        "\n",
        "        self.attn_drop = nn.Dropout(config.att_drop_rate)\n",
        "        self.resid_drop = nn.Dropout(config.att_drop_rate)\n",
        "\n",
        "        self.proj = nn.Linear(config.n_embed, config.n_embed)\n",
        "        self.n_head = config.n_head\n",
        "\n",
        "        num = int(bool(config.num_props)) + int(config.scaffold_maxlen)\n",
        "        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size + num, config.block_size + num))\n",
        "                                .view(1, 1, config.block_size + num, config.block_size + num))\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        B, T, C = x.size()\n",
        "        # apply attention functions to get tensors with dimensions (B, n_head, T, head_size)\n",
        "        q = self.query(x).view(B, T, self.n_head, C // self.n_head)\n",
        "        k = self.key(x).view(B, T, self.n_head, C // self.n_head)\n",
        "        v = self.value(x).view(B, T, self.n_head, C // self.n_head)\n",
        "        if self.config.do_flash:\n",
        "            q = q.transpose(1, 2)\n",
        "            k = k.transpose(1, 2)\n",
        "            v = v.transpose(1, 2)\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, dropout_p=self.config.att_drop_rate if self.training else 0, is_causal=self.config.is_causal)\n",
        "            y = y.transpose(1, 2)\n",
        "        else:\n",
        "            # (B h T s) @ (B h s T) -> (B h T T)\n",
        "            att = torch.einsum('bths,bihs->bhti', q, k) / math.sqrt(k.size(-1))\n",
        "            att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            # (B h T T) @ (B h T s) -> (B h T s)\n",
        "            y = torch.einsum('bhtq,bqhs->bths', att, v)\n",
        "            self.att_weights = att\n",
        "        self.attended = y\n",
        "        y = y.contiguous().view(B, T, C)\n",
        "        y = self.resid_drop(self.proj(y))\n",
        "        self.out = y\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(config.n_embed)\n",
        "        self.ln2 = nn.LayerNorm(config.n_embed)\n",
        "        self.attn = SelfAttention(config)\n",
        "        self.mlp = nn.Sequential(nn.Linear(config.n_embed, config.ff_mult*config.n_embed), nn.GELU() if config.doGELU else nn.ReLU(),\n",
        "            nn.Linear(config.ff_mult*config.n_embed, config.n_embed), nn.Dropout(config.att_drop_rate))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.attn(self.ln1(x))\n",
        "        x = x + y # perform a residual connection by summing input and attention output\n",
        "        x = x + self.mlp(self.ln2(x)) # apply layer normalization and then MLP, create a residual connection with input\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embed)\n",
        "        self.type_emb = nn.Embedding(2, config.n_embed)\n",
        "        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embed))\n",
        "        # if conditioning on at least 1 property:\n",
        "        if config.num_props:\n",
        "            # initialize property linear layer, map property vector to embedding dimension\n",
        "            self.prop_nn = nn.Linear(config.num_props, config.n_embed)\n",
        "\n",
        "        self.drop = nn.Dropout(config.gpt_drop_rate)\n",
        "        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(config.n_embed)\n",
        "        self.head = nn.Linear(config.n_embed, config.vocab_size, bias=config.gpt_bias)\n",
        "        self.block_size = config.block_size # define the context size\n",
        "        self.apply(self._init_weights) # initialize weights and apply to all relevant modules in the model\n",
        "\n",
        "    def get_block_size(self):\n",
        "        return self.block_size\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        decay, no_decay = set(), set()\n",
        "        no_decay = set()\n",
        "\n",
        "        whitelist_weight_modules = (torch.nn.Linear)\n",
        "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
        "        # for named module of the model:\n",
        "        for mn, m in self.named_modules():\n",
        "            # for named parameter of each module:\n",
        "            for pn, p in m.named_parameters():\n",
        "                # construct full parameter name by concatenating module name and parameter name, separated by a dot\n",
        "                fpn = '%s.%s' % (mn, pn) if mn else pn\n",
        "                if pn.endswith('bias') or ('bias' in pn):\n",
        "                    no_decay.add(fpn)\n",
        "                elif (pn.endswith('weight') or ('weight' in pn)) and isinstance(m, whitelist_weight_modules):\n",
        "                    decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
        "                    no_decay.add(fpn)\n",
        "        no_decay.add('pos_emb')\n",
        "        param_dict = {pn:p for pn, p in self.named_parameters()}\n",
        "        assert len(decay & no_decay) == 0\n",
        "        # assert that all parameters from both sets have been correctly separated\n",
        "        assert len(param_dict.keys() - (decay | no_decay)) == 0\n",
        "        optim_groups = [{\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
        "                        {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0}]\n",
        "        optimizer = SophiaG(optim_groups, lr=train_config.learning_rate, betas=train_config.betas, rho=train_config.rho, weight_decay=train_config.weight_decay)\n",
        "        return optimizer\n",
        "\n",
        "    def forward(self, idx, targets=None, prop=None, scaffold=None):\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.block_size\n",
        "        if self.config.num_props:\n",
        "            assert prop.size(-1) == self.config.num_props, f\"number of properties {prop.size(-1)=} doesn't match the expected size {self.config.num_props=}\"\n",
        "        token_embeddings = self.tok_emb(idx)\n",
        "        position_embeddings = self.pos_emb[:, :t, :]\n",
        "        type_embeddings = self.type_emb(torch.ones((b,t), dtype=torch.long, device=idx.device))\n",
        "        x = self.drop(token_embeddings + position_embeddings + type_embeddings)\n",
        "        # Condition on properties\n",
        "        if self.config.num_props:\n",
        "            type_embd = self.type_emb(torch.zeros((b, 1), dtype=torch.long, device=idx.device))\n",
        "            if prop.ndim == 2:\n",
        "                p = self.prop_nn(prop.unsqueeze(1))\n",
        "            else:\n",
        "                p = self.prop_nn(prop)\n",
        "            p += type_embd\n",
        "            x = torch.cat([p, x], 1)\n",
        "        # Condition on scaffold\n",
        "        if self.config.scaffold:\n",
        "            type_embd = self.type_emb(torch.zeros((b, 1), dtype = torch.long, device = idx.device))\n",
        "            scaffold_embeds = self.tok_emb(scaffold)\n",
        "            scaffold_embeds += type_embd\n",
        "            x = torch.cat([scaffold_embeds, x], 1)\n",
        "\n",
        "        # Transformer blocks\n",
        "        for layer in self.blocks:\n",
        "            x = layer(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "\n",
        "        if self.config.num_props and self.config.scaffold:\n",
        "            num = int(bool(self.config.num_props)) + int(self.config.scaffold_maxlen)\n",
        "        elif self.config.num_props:\n",
        "            num = int(bool(self.config.num_props))\n",
        "        elif self.config.scaffold:\n",
        "            num = int(self.config.scaffold_maxlen)\n",
        "        else:\n",
        "            num = 0\n",
        "        # Slice the logits tensor along the second dimension to exclude the first num elements\n",
        "        logits = logits[:, num:, :]\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jia_2uzBQOp"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It9Ei0OYBSey"
      },
      "outputs": [],
      "source": [
        "class TrainerConfig:\n",
        "    epochs = 10\n",
        "    batch_size = 64\n",
        "    learning_rate = 3e-4\n",
        "    betas = (0.965, 0.99) #(0.9, 0.95)\n",
        "    rho = 0.04 # For SophiaG\n",
        "    weight_decay = 0.1\n",
        "\n",
        "    lr_decay = False\n",
        "    warmup_tokens = 375e6 # number of warm-up tokens for learning rate decay\n",
        "    final_tokens = 260e9 # number of tokens at which the learning rate decays to 10% of the original\n",
        "    num_workers = 0 # number of worker processes to use for loading data\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        for k,v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "def loss_function(logits, y, mask_idx):\n",
        "    loss=nn.CrossEntropyLoss(ignore_index=-1)\n",
        "    y[mask_idx]=-1\n",
        "    return loss(logits.view(-1,logits.size(-1)),y.view(-1))\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, train_dataset, test_dataset, config, stoi, itos):\n",
        "        self.model = model\n",
        "        self.train_dataset = train_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.config = config\n",
        "        self.stoi = stoi\n",
        "        self.itos = itos\n",
        "        self.model = self.model.to(config.device)\n",
        "\n",
        "    def train(self, wandb):\n",
        "        model, config = self.model, self.config\n",
        "        optimizer = model.configure_optimizers(config)\n",
        "        scaler = GradScaler() # define variable used for gradient scaling in mixed-precision training\n",
        "        self.tokens = 0 # initialize a counter used for learning rate decay\n",
        "\n",
        "        def run_epoch(split):\n",
        "            is_train = split == 'train'\n",
        "            model.train(is_train)\n",
        "            data = self.train_dataset if is_train else self.test_dataset\n",
        "            loader = DataLoader(data, shuffle=True, pin_memory=True, batch_size=config.batch_size, num_workers=config.num_workers)\n",
        "            losses = []\n",
        "            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n",
        "            # for batch index, batch in progress bar:\n",
        "            for it, (x, y, p, scaffold, mask_idx) in pbar:\n",
        "                # move the input data tensor, target data tensor, property tensor, and scaffold tensor to GPU\n",
        "                x, y, p, scaffold , mask_idx = x.to(config.device), y.to(config.device), p.to(config.device), scaffold.to(config.device), mask_idx.to(config.device)\n",
        "                # allow model to use lower-precision computations for improved memory usage\n",
        "                if config.device == 'cuda':\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        with torch.set_grad_enabled(is_train):\n",
        "                            logits= model(x, y, p, scaffold)\n",
        "                            loss = loss_function(logits, y, mask_idx)\n",
        "                            loss = loss.mean()\n",
        "                            losses.append(loss.item())\n",
        "                else:\n",
        "                    with torch.cpu.amp.autocast():\n",
        "                        with torch.set_grad_enabled(is_train):\n",
        "                            logits = model(x, y, p, scaffold)\n",
        "                            loss = loss_function(x, y, mask_idx)\n",
        "                            loss = loss.mean()\n",
        "                            losses.append(loss.item())\n",
        "\n",
        "                if is_train:\n",
        "                    model.zero_grad()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(optimizer) # unscale the gradients of the optimizer's parameters to their original values\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip gradients of model parameters to prevent them from exploding, setting maximum gradient norm to be 1.0\n",
        "                    scaler.step(optimizer) # update the optimizer's parameters based on calculated gradients\n",
        "                    scaler.update() # update the scale factor of the gradient scaler\n",
        "                    if config.lr_decay:\n",
        "                        self.tokens += (y >= 0).sum() # increment the number of processed tokens by the count of valid tokens (not padding or special tokens)\n",
        "                        if self.tokens < config.warmup_tokens:\n",
        "                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens)) # perform a linear warm-up\n",
        "                        else:\n",
        "                            # calculate the progress of training in terms of the number of tokens processed\n",
        "                            progress = float(self.tokens - config.warmup_tokens) / float(max(1, config.final_tokens - config.warmup_tokens))\n",
        "                            # calculate the scaling factor for the learning rate (between 0.1 and 1.0)\n",
        "                            # to gradually reduce learning rate as training progresses\n",
        "                            lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "                        lr = config.learning_rate * lr_mult # multiply the base learning rate by the scaling factor to obtain the updated learning rate\n",
        "                        for param_group in optimizer.param_groups:\n",
        "                            param_group['lr'] = lr\n",
        "                    else:\n",
        "                        lr = config.learning_rate\n",
        "                    # log training progress using Weights & Biases\n",
        "                    if wandb is not None:\n",
        "                        wandb.log({'step_train_loss': loss, 'train_step': it + epoch*len(loader), 'learning_rate': lr})\n",
        "                    # update the description of the progress bar with epoch, iteration, and training loss\n",
        "                    pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n",
        "            return float(np.mean(losses))\n",
        "\n",
        "\n",
        "        # initialize best loss as infinity\n",
        "        best_loss = float('inf')\n",
        "        for epoch in range(config.epochs):\n",
        "            print(f'{epoch=}')\n",
        "            train_loss = run_epoch('train')\n",
        "            if self.test_dataset is not None:\n",
        "                test_loss = run_epoch('test')\n",
        "            if wandb is not None:\n",
        "                wandb.log({'epoch_valid_loss': test_loss, 'epoch_train_loss': train_loss, 'epoch': epoch + 1})\n",
        "            good_model = self.test_dataset is None or test_loss < best_loss\n",
        "            if good_model:\n",
        "                best_loss = test_loss\n",
        "                torch.save(self.model.state_dict(), self.config.ckpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gthVEc2ZBX2u"
      },
      "outputs": [],
      "source": [
        "def load_data(train_config_dict):\n",
        "    if (cut:=train_config_dict[\"slice_data\"]):\n",
        "        train_data = pd.read_csv(train_config_dict[\"train_path\"])[:cut]\n",
        "        val_data = pd.read_csv(train_config_dict[\"val_path\"])[:cut]\n",
        "    else:\n",
        "        train_data = pd.read_csv(train_config_dict[\"train_path\"])\n",
        "        val_data = pd.read_csv(train_config_dict[\"val_path\"])\n",
        "\n",
        "    smiles = train_data['smiles']\n",
        "    vsmiles = val_data['smiles']\n",
        "\n",
        "    prop = train_data[train_config_dict[\"props\"]].values.tolist()\n",
        "    vprop = val_data[train_config_dict[\"props\"]].values.tolist()\n",
        "\n",
        "    scaffold = train_data['scaffold_smiles']\n",
        "    vscaffold = val_data['scaffold_smiles']\n",
        "\n",
        "    # define a regular expression that matches molecular tokens in SMILES strings\n",
        "    pattern = \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]|X)\"\n",
        "    # compile pattern into a regular expression object that can be used for matching operations\n",
        "    regex = re.compile(pattern)\n",
        "\n",
        "    context = {'<'}\n",
        "\n",
        "    max_len, scaffold_max_len = 0, 0\n",
        "    for iterator in (smiles.values, vsmiles.values):\n",
        "        for i in iterator:\n",
        "            chars = regex.findall(i.strip())\n",
        "            max_len = max(max_len, len(chars))\n",
        "            for char in chars:\n",
        "                context.add(char)\n",
        "    for iterator in (scaffold.values, vscaffold.values):\n",
        "        for i in iterator:\n",
        "            chars = regex.findall(i.strip())\n",
        "            scaffold_max_len = max(scaffold_max_len, len(chars))\n",
        "            for char in chars:\n",
        "                context.add(char)\n",
        "    print(max_len)\n",
        "    context = sorted(list(context))\n",
        "\n",
        "    smiles = [i + str('<')*(max_len - len(regex.findall(i.strip()))) for i in smiles]\n",
        "    vsmiles = [i + str('<')*(max_len - len(regex.findall(i.strip()))) for i in vsmiles]\n",
        "    scaffold = [i + str('<')*(scaffold_max_len - len(regex.findall(i.strip()))) for i in scaffold]\n",
        "    vscaffold = [i + str('<')*(scaffold_max_len - len(regex.findall(i.strip()))) for i in vscaffold]\n",
        "\n",
        "    # if not conditioning on scaffolds: define 'scaffold' as a list of length SMILES string filled with 'False' values\n",
        "    scaffold=[False]*len(smiles) if not train_config_dict[\"use_scaf\"] else scaffold\n",
        "    train_dataset = SMILESDataset(smiles, context, max_len, prop=prop, scaffold=scaffold, scaffold_maxlen=scaffold_max_len, len_data=len(train_data), mask_prob=0.15)\n",
        "    valid_dataset = SMILESDataset(vsmiles, context, max_len, prop=vprop, scaffold=vscaffold, scaffold_maxlen=scaffold_max_len, len_data=len(val_data), mask_prob=0.15)\n",
        "    train_dataset.export_desc_attributes(train_config_dict[\"desc_path\"])\n",
        "    return train_dataset, valid_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWAIfqxj9to1"
      },
      "outputs": [],
      "source": [
        "def pretrain_BERT(train_dataset, valid_dataset, model_config_dict, train_config_dict):\n",
        "  \"\"\"\n",
        "  OUTPUTS:\n",
        "  1) checkpoint of trained model parameters\n",
        "  2) Weights & Biases logged run\n",
        "  \"\"\"\n",
        "\n",
        "  mask_index = train_dataset.stoi['X']\n",
        "  mconf = GPTConfig(train_dataset.vocab_size, train_dataset.max_len, mask_index=mask_index, num_props=len(train_config_dict[\"props\"]), scaffold=train_config_dict[\"use_scaf\"], scaffold_maxlen=train_dataset.scaf_max_len, **model_config_dict)\n",
        "  model = GPT(mconf).to(model_config_dict[\"device\"])\n",
        "\n",
        "  if train_config_dict['load_cpt'] != None:\n",
        "    model.load_state_dict(torch.load(train_config_dict['load_cpt']))\n",
        "  torch.compile(model)\n",
        "\n",
        "  tconf = TrainerConfig(warmup_tokens=0.1*train_dataset.len_data*train_dataset.max_len, final_tokens=train_config_dict[\"epochs\"]*train_dataset.len_data*train_dataset.max_len, block_size=train_dataset.max_len, **train_config_dict)\n",
        "  trainer = Trainer(model, train_dataset, valid_dataset, tconf, train_dataset.stoi, train_dataset.itos)\n",
        "\n",
        "  %env WANDB_EXECUTABLE=python3\n",
        "  wandb.init(project=\"mol_transformer\", name=train_config_dict[\"wandb_runname\"])\n",
        "  trainer.train(wandb=wandb)\n",
        "  return model, tconf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eApgFW7e9vd6"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "BASE = '/content/drive/MyDrive/Generative_ML/'\n",
        "\n",
        "model_config_dict = {\n",
        "    \"device\": DEVICE,\n",
        "    \"att_bias\": False,\n",
        "    \"gpt_bias\": True,\n",
        "    \"att_drop_rate\": 0.1,\n",
        "    \"gpt_drop_rate\": 0.1,\n",
        "    \"n_layer\": 8,\n",
        "    \"n_head\": 8,\n",
        "    \"n_embed\": 256,\n",
        "    \"ff_mult\": 4, # multiplier for FF inside multihead,\n",
        "    \"doGELU\": True, # else ReLU\n",
        "    \"attention_times\": [],\n",
        "    \"do_flash\": True,\n",
        "    \"is_causal\": False\n",
        "}\n",
        "\n",
        "train_config_dict = {\n",
        "    \"desc_path\": BASE + 'checkpoints/descriptors_10k.yaml',\n",
        "    \"train_path\": BASE + 'data/MOSES_processed_train.csv',\n",
        "    \"val_path\": BASE + 'data/MOSES_processed_val.csv',\n",
        "    \"slice_data\": False,\n",
        "    \"ckpt_path\": BASE + 'checkpoints/7-03_all_mask.pt',\n",
        "    \"wandb_runname\": \"7_03_all_mask\",\n",
        "    \"use_scaf\": False,\n",
        "    \"props\": [],\n",
        "    \"device\": DEVICE,\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 512,\n",
        "    \"lr_decay\": True,\n",
        "    \"num_workers\": 0,\n",
        "    \"load_cpt\": None\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk6icEUs9xFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c321786f-2171-47f3-a73c-48e0f5015aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset = load_data(train_config_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to train BERT model\n",
        "model, tconf = pretrain_BERT(\n",
        "                train_dataset = train_dataset,\n",
        "                valid_dataset = val_dataset,\n",
        "                model_config_dict = model_config_dict,\n",
        "                train_config_dict = train_config_dict\n",
        "        )\n",
        "\n",
        "#GK wandb API Key: c99c9a01523f93287716691fa3360b1f4566e115\n",
        "#RB wandb API Key: 4d3d628c6b5a4b3554c7a89ea50df8a4a6be0f85"
      ],
      "metadata": {
        "id": "gg3xxdXyRLZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DjaK3DzoSLB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywY37VNWSLS9"
      },
      "source": [
        "##Generation & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChKsmt1qSLS9"
      },
      "outputs": [],
      "source": [
        "def generate_SMILES(model_config_dict, inference_config_dict):\n",
        "  props = inference_config_dict[\"props\"]\n",
        "  scaffold = inference_config_dict[\"scaffold\"]\n",
        "\n",
        "  # define a regular expression that matches molecular tokens in SMILES strings\n",
        "  pattern = \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]|X)\"\n",
        "  regex = re.compile(pattern)\n",
        "\n",
        "  dataset = SMILESDataset()\n",
        "  dataset.load_desc_attributes(inference_config_dict['desc_path'])\n",
        "  use_scaf = False if scaffold is None else True\n",
        "\n",
        "  mconf = GPTConfig(dataset.vocab_size, dataset.max_len, num_props=len(props), scaffold=use_scaf, scaffold_maxlen=dataset.scaf_max_len, **model_config_dict)\n",
        "  model = GPT(mconf).to(model_config_dict['device'])\n",
        "  torch.compile(model)\n",
        "\n",
        "  # load parameters into the model\n",
        "  model.load_state_dict(torch.load(inference_config_dict[\"model_params\"], map_location=torch.device(model_config_dict['device'])))\n",
        "  block_size = model.get_block_size() #inference_config_dict[\"block_size\"]\n",
        "  assert block_size == dataset.max_len, \"Warning: model block size and dataset block size are different\"\n",
        "  # calculate number of generation iterations from total number of SMILES to generate and batch size\n",
        "  gen_iter = math.ceil(inference_config_dict[\"gen_size\"] / inference_config_dict[\"batch_size\"])\n",
        "  stoi = dataset.stoi # define dictionary to map strings to integers\n",
        "  itos = dataset.itos # define dictionary to map integers to strings\n",
        "  # is a scaffold is defined for conditioning:\n",
        "  if scaffold is not None:\n",
        "      # pad '<' to end of scaffold string to achieve maximum scaffold length\n",
        "      scaffold += str('<')*(dataset.scaf_max_len - len(regex.findall(scaffold)))\n",
        "      # convert the scaffold SMILES to a tensor of integers and repeat along the batch dimension, move to GPU\n",
        "      scaffold=torch.tensor([stoi[s] for s in regex.findall(scaffold)])[None,...].repeat(inference_config_dict[\"batch_size\"], 1).to(model_config_dict['device'])\n",
        "\n",
        "  if props is None:\n",
        "    p = None\n",
        "  elif len(props) == 1:\n",
        "    # create a tensor for conditioning with a single property value\n",
        "    p = torch.tensor([[props[0]]]).repeat(inference_config_dict[\"batch_size\"], 1).to(model_config_dict['device'])\n",
        "  else:\n",
        "    # create a tensor for conditioning with multiple property values\n",
        "    p = torch.tensor([props]).repeat(inference_config_dict[\"batch_size\"], 1).unsqueeze(1).to(model_config_dict['device'])\n",
        "\n",
        "  molecules = []\n",
        "  for i in tqdm(range(gen_iter)):\n",
        "          # create an input tensor by converting 'context' to a tensor of token indices,\n",
        "          # repeat this batch times along the batch dimension\n",
        "          x = torch.tensor([stoi[s] for s in regex.findall(inference_config_dict[\"context\"])], dtype=torch.long)[None,...].repeat(inference_config_dict[\"batch_size\"], 1).to(model_config_dict['device'])\n",
        "\n",
        "          if ['X'] in inference_config_dict['context']:\n",
        "            # call sample function to generate molecules conditioned on the input\n",
        "            y = fill_mask(model, x, block_size, temperature=inference_config_dict[\"temp\"], prop=p, scaffold=scaffold)\n",
        "          else:\n",
        "            y = sample(model, x, block_size, temperature=inference_config_dict[\"temp\"], prop=p, scaffold=scaffold)\n",
        "\n",
        "          # for each generated molecule:\n",
        "          for gen_mol in y:\n",
        "                  # convert generated molecule from list of integers to list of strings and concatenate to one string\n",
        "                  completion = ''.join([itos[int(i)] for i in gen_mol])\n",
        "                  # remove padding tokens\n",
        "                  completion = completion.replace('<', '')\n",
        "                  # convert the string representation of the molecule to an rdkit Mol object\n",
        "                  mol = get_mol(completion)\n",
        "                  # if an rdkit Mol object was created:\n",
        "                  if mol:\n",
        "                          # append the Mol object to the list\n",
        "                          molecules.append(mol)\n",
        "  # create dataframe where first column contains rdkit Mols and second column contins SMILES\n",
        "  results = pd.DataFrame([{'molecule' : i, 'smiles': Chem.MolToSmiles(i)} for i in molecules])\n",
        "  # iterate over each SMILES and ensure that equivalent molecules have same SMILES\n",
        "  canon_smiles = [canonic_smiles(s) for s in results['smiles']]\n",
        "  # create set of unique SMILES strings\n",
        "  unique_smiles = list(set(canon_smiles))\n",
        "  data = pd.read_csv(inference_config_dict[\"train_data\"]) # load training data\n",
        "  novel_ratio = check_novelty(unique_smiles, set(data['smiles'])) # calculate novelty ratio from generated SMILES and training SMILES\n",
        "  results['qed'] = results['molecule'].apply(lambda x: QED.qed(x)) # quantitative estimate of drug-likeliness (QED)\n",
        "  results['sas'] = results['molecule'].apply(lambda x: sascorer.calculateScore(x)) #synthetic accessibility score (SAS)\n",
        "  results['logp'] = results['molecule'].apply(lambda x: Crippen.MolLogP(x)) #(measure of hydrophobicity)\n",
        "  results['tpsa'] = results['molecule'].apply(lambda x: CalcTPSA(x)) #topological polar surface area (TPSA)\n",
        "  results['validity'] = np.round(len(results)/(inference_config_dict[\"batch_size\"]*gen_iter), 3)\n",
        "  results['unique'] = np.round(len(unique_smiles)/len(results), 3)\n",
        "  results['novelty'] = np.round(novel_ratio/100, 3)\n",
        "  # save the dataframe as a csv file\n",
        "  results.to_csv(inference_config_dict[\"save_path\"], index = False)\n",
        "  # print all evaluation metrics using function from moses package\n",
        "  print(moses.get_all_metrics(list(results['smiles'].values), device=model_config_dict['device']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N-mabNHSLS-"
      },
      "outputs": [],
      "source": [
        "inference_config_dict = {\n",
        "    # \"model_params\": train_config_dict[\"ckpt_path\"],\n",
        "    \"model_params\": BASE + 'checkpoints/test_6_21.pt',\n",
        "    \"train_data\": train_config_dict[\"train_path\"],\n",
        "    # \"desc_path\": model_config_dict[\"desc_path\"],\n",
        "    \"desc_path\": BASE + 'checkpoints/descriptors_200k.yaml',\n",
        "    \"save_path\": BASE + 'data/test_06_21_t.csv',\n",
        "    \"batch_size\": 1,\n",
        "    \"gen_size\": 10,\n",
        "    \"temp\": 1,\n",
        "    \"context\": \"C1CCXCCC1\",\n",
        "    \"scaffold\": None,\n",
        "    \"props\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5DqRGAxSLS-"
      },
      "outputs": [],
      "source": [
        "# run function to generate SMILES strings\n",
        "generate_SMILES(\n",
        "              model_config_dict = model_config_dict,\n",
        "              inference_config_dict = inference_config_dict\n",
        "              )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jzRj6bGQpUaM",
        "7pfZIi6qpUaQ",
        "iTFNFFNGpUaR",
        "zBgupbjAPYu7",
        "4CXn_Jqt_76M",
        "EJqiexX6AAsv",
        "0gbEP-i0Av6M",
        "VXLdZWy9A5Tk",
        "6Jia_2uzBQOp",
        "ywY37VNWSLS9"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}