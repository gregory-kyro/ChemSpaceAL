{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from pprint import pprint as pp\n",
    "import yaml\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "BASE = '/Users/morgunov/batista/Summer/pipeline/'\n",
    "REGEX_PATTERN = \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|@@|\\?|>|!|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "regex = re.compile(REGEX_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.title_size = 20\n",
    "        self.axis_title_size = 14\n",
    "        self.tick_font_size = 12\n",
    "        self.text_color=\"#333333\"\n",
    "        self.background = \"white\"\n",
    "        self.grid_color = \"#e2e2e2\"\n",
    "        self.line_color = \"#000000\"\n",
    "        self.font_family = 'Helvetica'\n",
    "        self.show_xgrid = False\n",
    "        self.show_ygrid = False\n",
    "        self.width = 600\n",
    "        self.height = 400\n",
    "        self.title = ''\n",
    "        self.xaxis_title = ''\n",
    "        self.yaxis_title = ''\n",
    "    \n",
    "    def update_parameters(self, params):\n",
    "        for key, val in params.items():\n",
    "            setattr(self, key, val)\n",
    "        \n",
    "\n",
    "    def style_figure(self, figure):\n",
    "        figure.update_layout({\n",
    "            'margin': {'t': 50, 'b': 50, 'l': 50, 'r': 50},\n",
    "            'plot_bgcolor': self.background,\n",
    "            'paper_bgcolor': self.background,\n",
    "            'title': {\n",
    "                'text': self.title,\n",
    "                'font': {\n",
    "                    'size': self.title_size,\n",
    "                    'color': self.text_color,\n",
    "                    'family': self.font_family\n",
    "                },\n",
    "            },\n",
    "            'height': self.height,  # Set fixed size ratio 3:4\n",
    "            'width': self.width, \n",
    "            'font': {\n",
    "                'family': self.font_family,\n",
    "                'size': self.tick_font_size,\n",
    "                'color': self.text_color\n",
    "            },\n",
    "            'legend': {\n",
    "                'font': {\n",
    "                    'family': self.font_family,\n",
    "                    'size': self.tick_font_size,\n",
    "                    'color': self.text_color\n",
    "                },\n",
    "            },\n",
    "        })\n",
    "\n",
    "        # Setting the title size and color and grid for both x and y axes\n",
    "        figure.update_xaxes(\n",
    "            title=self.xaxis_title,\n",
    "            title_font={'size': self.axis_title_size, 'color': self.text_color, 'family': self.font_family},\n",
    "            tickfont={'size': self.tick_font_size, 'color': self.text_color, 'family': self.font_family},\n",
    "            showgrid=self.show_xgrid,\n",
    "            gridwidth=1,\n",
    "            gridcolor=self.grid_color,\n",
    "            linecolor=self.line_color,  # make x axis line visible\n",
    "            linewidth=2\n",
    "        )\n",
    "\n",
    "        figure.update_yaxes(\n",
    "            title=self.yaxis_title,\n",
    "            title_standoff=0,\n",
    "            title_font={'size': self.axis_title_size, 'color': self.text_color, 'family': self.font_family},\n",
    "            tickfont={'size': self.tick_font_size, 'color': self.text_color, 'family': self.font_family},\n",
    "            showgrid=self.show_ygrid,\n",
    "            gridwidth=1,\n",
    "            gridcolor=self.grid_color,\n",
    "            linecolor=self.line_color,  # make y axis line visible\n",
    "            linewidth=2\n",
    "        )\n",
    "        return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "\n",
    "    def __init__(self, base_path, data_path, remove_isotopes=False, remove_invalides=True, remove_non_bio_friendly=False, token_len_cutoff=None, token_freq_cutoff=None):\n",
    "        self.base_path = base_path\n",
    "        self.data_path = data_path\n",
    "        self.vocab = set()\n",
    "        self.max_block_size = 0\n",
    "        self.block_sizes = []\n",
    "        self.token_to_freq = {}\n",
    "        self.remove_isotopes = remove_isotopes\n",
    "        self.remove_invalides = remove_invalides\n",
    "        self.remove_non_bio_friendly = remove_non_bio_friendly\n",
    "        self.plot_suffix = ''\n",
    "        self.token_len_cutoff = token_len_cutoff\n",
    "        self.token_freq_cutoff = token_freq_cutoff\n",
    "        if self.remove_isotopes:\n",
    "            with open(self.base_path + 'processed_data/isotope_exceptions.yaml', 'r') as f:\n",
    "                self.isotope_exceptions = set(yaml.safe_load(f))\n",
    "            self.plot_suffix += '_no_isotopes'\n",
    "        if self.remove_invalides:\n",
    "            self.invalid_smiles = pickle.load(open(self.base_path + 'processed_data/invalid_smiles.pkl', 'rb'))\n",
    "            self.plot_suffix += '_no_invalides'\n",
    "        if self.remove_non_bio_friendly:\n",
    "            with open(self.base_path + 'processed_data/non_bio_friendly_exceptions.yaml', 'r') as f:\n",
    "                self.non_bio_friendly_exceptions = set(yaml.safe_load(f))\n",
    "            self.plot_suffix += '_no_nonbio_friendly'\n",
    "\n",
    "    def load_and_analyze(self):\n",
    "        self.df = pd.read_csv(self.base_path + 'raw_data/' + self.data_path + '.csv')\n",
    "        \n",
    "        processed_smiles = set()\n",
    "        smile_crumbles = []\n",
    "\n",
    "        pbar_desc = 'Analyzing ' + self.data_path\n",
    "        if self.remove_isotopes:\n",
    "            pbar_desc += ' (no isotopes)'\n",
    "            self.smiles_with_isotopes = set()\n",
    "        if self.remove_invalides:\n",
    "            pbar_desc += ' (no invalides)'\n",
    "        if self.remove_non_bio_friendly:\n",
    "            pbar_desc += ' (no non bio friendly)'\n",
    "            self.smiles_with_non_bio_friendly = set()\n",
    "\n",
    "        pbar = tqdm(self.df['smiles'].values, total=len(self.df['smiles'].values), desc=pbar_desc)\n",
    "        for smile in pbar:\n",
    "            tokens = regex.findall(smile.strip())\n",
    "\n",
    "            if self.remove_isotopes and any([token in self.isotope_exceptions for token in tokens]):\n",
    "                self.smiles_with_isotopes.add(smile)\n",
    "                continue\n",
    "            if self.remove_non_bio_friendly and any([token in self.non_bio_friendly_exceptions for token in tokens]):\n",
    "                self.smiles_with_non_bio_friendly.add(smile)\n",
    "                continue\n",
    "            if self.remove_invalides and smile in self.invalid_smiles:\n",
    "                continue\n",
    "            if self.token_len_cutoff is not None and len(tokens) > self.token_len_cutoff:\n",
    "                continue\n",
    "\n",
    "            processed_smiles.add(smile)\n",
    "            for token in tokens:\n",
    "                self.vocab.add(token)\n",
    "                if token not in self.token_to_freq:\n",
    "                    self.token_to_freq[token] = 0\n",
    "                self.token_to_freq[token] += 1\n",
    "\n",
    "            self.max_block_size = max(self.max_block_size, len(tokens))\n",
    "            self.block_sizes.append(len(tokens))\n",
    "        \n",
    "        if self.remove_isotopes:\n",
    "            pickle.dump(self.smiles_with_isotopes, open(self.base_path + 'processed_data/smiles_with_isotopes.pkl', 'wb'))\n",
    "        if self.remove_non_bio_friendly:\n",
    "            pickle.dump(self.smiles_with_non_bio_friendly, open(self.base_path + 'processed_data/smiles_with_non_bio_friendly.pkl', 'wb'))\n",
    "        pickle.dump(processed_smiles, open(self.base_path + 'processed_data/processed_smiles_' + self.data_path + '.pkl', 'wb'))\n",
    "        self.processed_smiles = processed_smiles\n",
    "        if self.token_freq_cutoff is not None:\n",
    "            self._remove_rare_tokens()\n",
    "\n",
    "    def _remove_rare_tokens(self):\n",
    "        new_smiles = set()\n",
    "        self.max_block_size = 0\n",
    "        self.vocab = set()\n",
    "\n",
    "        pbar = tqdm(self.processed_smiles, total=len(self.processed_smiles), desc=f\"Removing rare tokens\")\n",
    "        for smile in pbar:\n",
    "            tokens = regex.findall(smile.strip())\n",
    "            if any([self.token_to_freq[token] < self.token_freq_cutoff for token in tokens]): continue\n",
    "            new_smiles.add(smile)\n",
    "            for token in tokens:\n",
    "                self.vocab.add(token)\n",
    "            self.max_block_size = max(self.max_block_size, len(tokens))\n",
    "        \n",
    "        pickle.dump(new_smiles, open(self.base_path + 'processed_data/processed_smiles_' + self.data_path + '_no_rare_tokens.pkl', 'wb'))\n",
    "\n",
    "    def plot_distribution(self, block_sizes):\n",
    "        graph = Graph()\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Histogram(x=block_sizes, name=self.data_path, histnorm='probability density'))\n",
    "        fig.update_layout(barmode='overlay', xaxis=dict(dtick=20))\n",
    "        fig.update_traces(opacity=0.75)\n",
    "        percentiles = [25, 50, 75, 95, 99, 99.9, 99.99]\n",
    "        for i, percentile in enumerate(percentiles):\n",
    "            val = np.percentile(block_sizes, percentile)\n",
    "            y_coord = 0.5 if i < len(percentiles) / 2 else 0\n",
    "            y_anno = -40 * (1 + i % 5) #-30 if i % 2 == 0 else -50 #-10 if i < len(percentiles) / 2 else -30\n",
    "            fig.add_annotation(x=val, y=0, text=f'{percentile} percentile<br>{val:.0f} blocks',\n",
    "                showarrow=True, arrowhead=1, ax=-10, ay=y_anno)\n",
    "        stats_text = f\"Total smiles: {len(block_sizes)}<br>Vocab Size: {len(self.vocab)}<br>Max Block Size: {self.max_block_size}\"\n",
    "        if self.remove_isotopes:\n",
    "            isotope_fraction = len(self.smiles_with_isotopes) / len(self.df[\"smiles\"])\n",
    "            stats_text += f\"<br># excluded (isotope-containing): {len(self.smiles_with_isotopes)} or {isotope_fraction:.2%}\"\n",
    "        if self.remove_non_bio_friendly:\n",
    "            non_bio_friendly_fraction = len(self.smiles_with_non_bio_friendly) / len(self.df[\"smiles\"])\n",
    "            stats_text += f\"<br># excluded (non bio friendly): {len(self.smiles_with_non_bio_friendly)} or {non_bio_friendly_fraction:.2%}\"\n",
    "        if self.remove_invalides:\n",
    "            invalid_fraction = len(self.invalid_smiles) / len(self.df[\"smiles\"])\n",
    "            stats_text += f\"<br># excluded (invalid): {len(self.invalid_smiles)} or {invalid_fraction:.2%}\"\n",
    "        fig.add_annotation(x=0.75, y=1, text=stats_text,\n",
    "                            showarrow=False, xref='paper', yref='paper', xanchor='left', yanchor='top', font=dict(size=12))\n",
    "        graph.update_parameters({'title': f'Block size distribution for {self.data_path} partition. Isotopes removed: {self.remove_isotopes}',\n",
    "                                'xaxis_title': 'Block size', 'yaxis_title': 'Probability density',\n",
    "                                'width': 1280, 'height': 720, 'show_xgrid': True})\n",
    "        graph.style_figure(fig)\n",
    "        fig.write_html(self.base_path + f'plots/block_size_distribution_{self.data_path}{self.plot_suffix}.html', include_plotlyjs='cdn')\n",
    "\n",
    "    def plot_token_frequencies(self, top_n=20):\n",
    "        sorted_token_freq = dict(sorted(self.token_to_freq.items(), key=lambda item: item[1], reverse=True))\n",
    "        sorted_token_freq = dict(list(sorted_token_freq.items())[:top_n])\n",
    "        \n",
    "        graph = Graph()\n",
    "        fig = go.Figure(data=[\n",
    "            go.Bar(\n",
    "                x=list(sorted_token_freq.keys()), \n",
    "                y=list(sorted_token_freq.values()), \n",
    "                name=self.data_path)\n",
    "            ])\n",
    "        graph.update_parameters({'title': f'Top {top_n} character frequencies for {self.data_path} partition. Isotopes removed: {self.remove_isotopes}',\n",
    "                                'xaxis_title': 'Token', 'yaxis_title': 'Frequency',\n",
    "                                'width': 1280, 'height': 720})\n",
    "\n",
    "        graph.style_figure(fig)\n",
    "        fig.write_html(self.base_path + f'plots/token_frequencies_{self.data_path}{self.plot_suffix}.html', include_plotlyjs='cdn')\n",
    "    \n",
    "    def export_vocab(self):\n",
    "        with open(self.base_path + f'vocab_{self.data_path}.txt', 'w') as f:\n",
    "            for token in self.vocab:\n",
    "                f.write(token + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing moses_and_binding (no isotopes) (no invalides) (no non bio friendly): 100%|██████████| 2895566/2895566 [00:30<00:00, 93516.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(44, 130)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(remove_isotopes=True, remove_invalides=True, remove_non_bio_friendly=True, token_len_cutoff=None, token_freq_cutoff=None)\n",
    "binding_db = Dataset(BASE, 'moses_and_binding', **config)\n",
    "binding_db.load_and_analyze()\n",
    "len(binding_db.vocab), binding_db.max_block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': 31151990,\n",
       " 'C': 21416624,\n",
       " '(': 12305744,\n",
       " ')': 12305744,\n",
       " '1': 9910896,\n",
       " 'O': 6934241,\n",
       " '2': 5810532,\n",
       " 'N': 4916586,\n",
       " '=': 4629659,\n",
       " 'n': 4381610,\n",
       " '3': 1963472,\n",
       " 'F': 1364125,\n",
       " '-': 898082,\n",
       " 'S': 590858,\n",
       " 'Cl': 511539,\n",
       " 's': 437893,\n",
       " '[C@H]': 429608,\n",
       " '[nH]': 411651,\n",
       " 'o': 397557,\n",
       " '[C@@H]': 395138,\n",
       " '4': 359984,\n",
       " '#': 261454,\n",
       " '\\\\': 132287,\n",
       " 'Br': 100460,\n",
       " '5': 47774,\n",
       " '[C@]': 47130,\n",
       " '[C@@]': 43568,\n",
       " '[O-]': 33362,\n",
       " '/': 30583,\n",
       " '[N+]': 27785,\n",
       " 'P': 17401,\n",
       " '.': 9663,\n",
       " '6': 6030,\n",
       " 'I': 5902,\n",
       " '[n+]': 5363,\n",
       " 'B': 2549,\n",
       " '[S+]': 1468,\n",
       " '[C-]': 1237,\n",
       " '[N-]': 1235,\n",
       " '[Si]': 1165,\n",
       " '[Na+]': 1164,\n",
       " '[NH3+]': 1080,\n",
       " '7': 684,\n",
       " '[H]': 251}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the token_to_freq dictionary by frequency in reversed order\n",
    "sorted_token_freq = dict(sorted(binding_db.token_to_freq.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_token_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_set = pickle.load(open(BASE + 'processed_data/processed_smiles_bindingDB_07_11_no_rare_tokens.pkl', 'rb'))\n",
    "moses_train_set = set(pd.read_csv(BASE + 'raw_data/train.csv.gz', compression='gzip')['SMILES'].tolist())\n",
    "moses_test_set = set(pd.read_csv(BASE + 'raw_data/test.csv.gz', compression='gzip')['SMILES'].tolist())\n",
    "moses_and_binding = binding_set | moses_train_set | moses_test_set\n",
    "pd.DataFrame({'smiles': list(moses_and_binding)}).to_csv(BASE + 'processed_data/moses_and_binding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(remove_isotopes=True, remove_invalides=True, remove_non_bio_friendly=True, cutoff=130)\n",
    "train_data = Dataset(BASE, 'train', **config)\n",
    "train_data.load_and_analyze()\n",
    "val_data = Dataset(BASE, 'val', **config)\n",
    "val_data.load_and_analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_crumbles_train = pickle.load(open(BASE + 'processed_data/smiles_crumbles_train.pkl', 'rb'))\n",
    "smile_crumbles_val = pickle.load(open(BASE + 'processed_data/smiles_crumbles_val.pkl', 'rb'))\n",
    "print(len(smile_crumbles_train), len(smile_crumbles_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_partition(fname, validation_fraction=0.05):\n",
    "    all_mols = pickle.load(open(BASE + f'processed_data/{fname}.pkl', 'rb'))\n",
    "    all_mols_list = list(all_mols)\n",
    "    validation_index = int((1-validation_fraction)*len(all_mols))\n",
    "    train_mols = all_mols_list[:validation_index]\n",
    "    val_mols = all_mols_list[validation_index:]\n",
    "    print(f\"{validation_index=}\")\n",
    "    pd.DataFrame({'smiles': train_mols}).to_csv(BASE + f'processed_data/{fname}_train.csv.gz', compression='gzip')\n",
    "    pd.DataFrame({'smiles': val_mols}).to_csv(BASE + f'processed_data/{fname}_val.csv.gz', compression='gzip')\n",
    "\n",
    "create_train_val_partition('processed_smiles_moses_and_binding_no_rare_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    dict(remove_isotopes=False, remove_invalides=False, remove_non_bio_friendly=False),\n",
    "    dict(remove_isotopes=False, remove_invalides=True, remove_non_bio_friendly=False),\n",
    "    dict(remove_isotopes=True, remove_invalides=True, remove_non_bio_friendly=False),\n",
    "    dict(remove_isotopes=True, remove_invalides=True, remove_non_bio_friendly=True),\n",
    "]\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    train_data = Dataset(BASE, 'train', **config)\n",
    "    train_data.load_and_analyze()\n",
    "    train_data.plot_distribution(train_data.block_sizes)\n",
    "    train_data.plot_token_frequencies(top_n=None)\n",
    "    val_data = Dataset(BASE, 'val', **config)\n",
    "    val_data.load_and_analyze()\n",
    "    val_data.plot_distribution(val_data.block_sizes)\n",
    "    val_data.plot_token_frequencies(top_n=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
